<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Presto使用OpenLDAP进行登录认证</title>
      <link href="/2020/06/04/Presto%E4%BD%BF%E7%94%A8OpenLDAP%E8%BF%9B%E8%A1%8C%E7%99%BB%E5%BD%95%E8%AE%A4%E8%AF%81/"/>
      <url>/2020/06/04/Presto%E4%BD%BF%E7%94%A8OpenLDAP%E8%BF%9B%E8%A1%8C%E7%99%BB%E5%BD%95%E8%AE%A4%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<p>presto对接OpenLDAP只支持ldaps，需要OpenLDAP开启SSL，本文将首先介绍OpenLDAP如何开启SSL。</p><h2 id="OpenLDAP开启SSL"><a href="#OpenLDAP开启SSL" class="headerlink" title="OpenLDAP开启SSL"></a>OpenLDAP开启SSL</h2><p>OpenLDAP开启SSL需要生成LDAP证书，有两种证书生成方式：</p><ol><li>自签名证书。该方式较为简单，LDAP客户端需要进行设置不进行证书校验；</li><li>CA签名证书，可以使用内部CA或外部CA签名证书。需要将给LDAP证书进行签名的CA证书放置在<code>/etc/openldap/cacerts</code>中，使得LDAP客户端能够对证书进行校验。</li></ol><p>两种方式任选一种即可。</p><h3 id="自签名证书"><a href="#自签名证书" class="headerlink" title="自签名证书"></a>自签名证书</h3><p>在<code>/etc/openldap/certs/</code>目录中创建LDAP server自签名证书：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl req -new -x509 -nodes -out /etc/openldap/certs/ldap.crt -keyout /etc/openldap/certs/ldap.key -days 1460</span><br></pre></td></tr></table></figure><p>填写信息中比较重要的是Common Name，需要填写安装OpenLDAP的主机的hostname，其他信息可以不填写：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Country Name (2 letter code) [XX]: CN</span><br><span class="line">State or Province Name (full name) []:</span><br><span class="line">Locality Name (eg, city) [Default City]:</span><br><span class="line">Organization Name (eg, company) [Default Company Ltd]:</span><br><span class="line">Organizational Unit Name (eg, section) []:</span><br><span class="line">Common Name (eg, your name or your server<span class="string">'s hostname) []: localhost</span></span><br><span class="line"><span class="string">Email Address []:</span></span><br></pre></td></tr></table></figure><p>创建完成后，在<code>/etc/openldap/certs</code>目录下会产生<code>ldap.key</code>和<code>ldap.crt</code>，修改这两个文件的属主：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chown ldap:ldap /etc/openldap/certs/ldap.*</span><br></pre></td></tr></table></figure><p>之后，我们通过ldif文件修改配置的方式修改OpenLDAP中关于证书信息的配置项，新建<code>certs.ldif</code>文件，内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dn: cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">replace: olcTLSCertificateFile</span><br><span class="line">olcTLSCertificateFile: /etc/openldap/certs/ldap.crt</span><br><span class="line">-</span><br><span class="line">replace: olcTLSCertificateKeyFile</span><br><span class="line">olcTLSCertificateKeyFile: /etc/openldap/certs/ldap.key</span><br></pre></td></tr></table></figure><p>在修改配置前，我们先看一下原有配置的内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">slapcat -b <span class="string">"cn=config"</span> | egrep <span class="string">"olcTLSCertificateKeyFile|olcTLSCertificateFile"</span></span><br></pre></td></tr></table></figure><p>使用<code>certs.ldif</code>修改配置的命令为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ldapmodify -Y EXTERNAL  -H ldapi:/// -f certs.ldif</span><br></pre></td></tr></table></figure><p>修改完成后可以使用上述检查配置的命令检查一下修改是否生效了。</p><h3 id="CA签名证书"><a href="#CA签名证书" class="headerlink" title="CA签名证书"></a>CA签名证书</h3><p>在<code>/etc/pki/CA</code>目录中创建<code>serial</code>和<code>index.txt</code>文件用于记录生成证书过程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/pki/CA</span><br><span class="line"><span class="built_in">echo</span> 0001 &gt; serial</span><br><span class="line">touch index.txt</span><br></pre></td></tr></table></figure><h4 id="1-生成CA所使用的密钥"><a href="#1-生成CA所使用的密钥" class="headerlink" title="1. 生成CA所使用的密钥"></a>1. 生成CA所使用的密钥</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -aes256 -out /etc/pki/CA/private/ca.key.pem</span><br></pre></td></tr></table></figure><p>输入秘钥的密码。</p><h4 id="2-创建CA的证书文件"><a href="#2-创建CA的证书文件" class="headerlink" title="2. 创建CA的证书文件"></a>2. 创建CA的证书文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl req -new -x509 -days 3650 -key /etc/pki/CA/private/ca.key.pem -extensions v3_ca -out /etc/pki/CA/certs/ca.cert.pem</span><br></pre></td></tr></table></figure><p>创建证书需要输入一些信息，这其中比较重要的是Common Name，需要填写安装OpenLDAP的主机的hostname，其他信息可以不写。</p><blockquote><p>注意：CN（Common Name）和主机名必须要匹配</p></blockquote><h4 id="3-创建ldap-server使用的秘钥"><a href="#3-创建ldap-server使用的秘钥" class="headerlink" title="3. 创建ldap server使用的秘钥"></a>3. 创建ldap server使用的秘钥</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out /etc/pki/CA/private/ldap.key</span><br></pre></td></tr></table></figure><p>输入秘钥的密码。</p><h4 id="4-创建ldap-server的证书文件"><a href="#4-创建ldap-server的证书文件" class="headerlink" title="4. 创建ldap server的证书文件"></a>4. 创建ldap server的证书文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl req -new -key /etc/pki/CA/private/ldap.key -out /etc/pki/CA/certs/ldap.csr</span><br></pre></td></tr></table></figure><p>输入信息，CN填入OpenLDAP安装主机的hostname，其他可以不写。</p><h4 id="5-使用CA对ldap-server的证书进行签名"><a href="#5-使用CA对ldap-server的证书进行签名" class="headerlink" title="5. 使用CA对ldap server的证书进行签名"></a>5. 使用CA对ldap server的证书进行签名</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl ca -keyfile /etc/pki/CA/private/ca.key.pem -cert /etc/pki/CA/certs/ca.cert.pem -<span class="keyword">in</span> /etc/pki/CA/certs/ldap.csr -out /etc/pki/CA/certs/ldap.crt</span><br></pre></td></tr></table></figure><p>这时候已经完成了ldap server证书由我们创建的CA进行签名的过程，此时<code>index.txt</code>文件中的内容应该已经发生了变化，使用<code>cat /etc/pki/CA/index.txt</code>进行查看。我们也可以使用<code>openssl</code>来验证ldap server证书是否被CA正确签名：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl verify -CAfile /etc/pki/CA/certs/ca.cert.pem /etc/pki/CA/certs/ldap.crt</span><br></pre></td></tr></table></figure><p>我们需要将证书、秘钥文件拷贝到<code>/etc/openldap/certs</code>目录中，将CA证书放到<code>/etc/openldap/cacerts/</code>目录中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cp -v /etc/pki/CA/certs/* /etc/openldap/certs/</span><br><span class="line">cp -v /etc/pki/CA/private/ldap.key /etc/openldap/certs/</span><br><span class="line">mkdir /etc/openldap/cacerts/</span><br><span class="line">cp -v /etc/pki/CA/certs/ca.cert.pem /etc/openldap/cacerts/</span><br></pre></td></tr></table></figure><p>修改目录属主：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chown -R ldap:ldap /etc/openldap/certs</span><br><span class="line">chown -R ldap:ldap /etc/openldap/cacerts</span><br></pre></td></tr></table></figure><h4 id="6-修改OpenLDAP配置生效CA签名证书"><a href="#6-修改OpenLDAP配置生效CA签名证书" class="headerlink" title="6. 修改OpenLDAP配置生效CA签名证书"></a>6. 修改OpenLDAP配置生效CA签名证书</h4><p>新建<code>certs.ldif</code>文件，其内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">dn: cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">replace: olcTLSCertificateFile</span><br><span class="line">olcTLSCertificateFile: /etc/openldap/certs/ldap.crt</span><br><span class="line">-</span><br><span class="line">replace: olcTLSCertificateKeyFile</span><br><span class="line">olcTLSCertificateKeyFile: /etc/openldap/certs/ldap.key</span><br><span class="line">-</span><br><span class="line">add: olcTLSCACertificateFile</span><br><span class="line">olcTLSCACertificateFile: /etc/openldap/cacerts/ca.cert.pem</span><br></pre></td></tr></table></figure><p>执行如下命令进行修改：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ldapmodify -Y EXTERNAL -H ldapi:// -f certs.ldif</span><br></pre></td></tr></table></figure><p>使用如下命令确保生效：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">slapcat -b <span class="string">"cn=config"</span> | egrep <span class="string">"olcTLSCertificateFile|olcTLSCertificateKeyFile|olcTLSCACertificateFile"</span></span><br></pre></td></tr></table></figure><h3 id="配置OpenLDAP开启SSL监听"><a href="#配置OpenLDAP开启SSL监听" class="headerlink" title="配置OpenLDAP开启SSL监听"></a>配置OpenLDAP开启SSL监听</h3><p>修改配置文件<code>/etc/sysconfig/slapd</code>，添加<code>ldaps</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SLAPD_URLS=<span class="string">"ldapi:/// ldap:/// ldaps:///"</span></span><br></pre></td></tr></table></figure><p>修改<code>/etc/openldap/certs</code>中的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#TLS_CACERTDIR /etc/openldap/certs</span><br><span class="line">TLS_REQCERT never</span><br></pre></td></tr></table></figure><p>重启OpenLDAP：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart slapd</span><br></pre></td></tr></table></figure><p>重启完成后，首先检查ldaps所使用的636端口是否已经启动：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -nlp | grep 636</span><br></pre></td></tr></table></figure><p>可以使用如下命令来测试ldaps连接：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ldapwhoami -x -H ldaps://&lt;ldap_server&gt;:636</span><br></pre></td></tr></table></figure><p>如果能够成功显示anonymous，说明成功通过SSL连上了OpenLDAP server，同时OpenLDAP server是支持匿名访问的（老版本Presto连接ldap需要ldap开启匿名访问）。</p><p>也可以使用如下简单认证的方式来验证ldaps连接是否正确（该方法不能测试匿名连接，如果上面方法失败，但是这个方法成功，说明ldaps连接没问题，但是匿名访问不被允许，若Presto版本对接ldap必须使用匿名访问，则需要配置OpenLDAP ACL或删除disallow匿名访问的配置）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ldapwhoami -x -w <span class="string">"&lt;passwd&gt;"</span> -D &lt;user_dn&gt; -H ldaps://&lt;ldap_server&gt;:636</span><br></pre></td></tr></table></figure><h2 id="配置Presto支持LDAP认证"><a href="#配置Presto支持LDAP认证" class="headerlink" title="配置Presto支持LDAP认证"></a>配置Presto支持LDAP认证</h2><p>Presto支持LDAP认证，客户端必须以HTTPS的方式访问presto server。开启LDAP认证只需要对presto coordinator进行配置使其支持SSL/TLS，presto worker不需要进行修改，只有客户端和presto coordinator之间的连接需要认证。</p><h3 id="生成presto-server秘钥"><a href="#生成presto-server秘钥" class="headerlink" title="生成presto server秘钥"></a>生成presto server秘钥</h3><p>配置presto coordinator支持SSL/TLS，需要生成presto server的秘钥（keystore）文件。</p><h4 id="1-生成presto-server私钥："><a href="#1-生成presto-server私钥：" class="headerlink" title="1. 生成presto server私钥："></a>1. 生成presto server私钥：</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keytool -genkey -v -keystore presto-private.keystore -<span class="built_in">alias</span> presto-private -keyalg RSA -dname <span class="string">"CN=&lt;hostname&gt;, OU=, O=, L=, ST=, C=CN"</span> -validity 20000 -keypass &lt;passwd&gt; -storepass &lt;passwd&gt;</span><br></pre></td></tr></table></figure><p>这里CN（Common Name）必须填写presto server所在主机的hostname，其他的可以不需要填写。</p><h4 id="2-导出证书文件"><a href="#2-导出证书文件" class="headerlink" title="2. 导出证书文件"></a>2. 导出证书文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keytool -<span class="built_in">export</span> -<span class="built_in">alias</span> presto-private -keystore presto-private.keystore -file presto-public.cer -storepass &lt;passwd&gt;</span><br></pre></td></tr></table></figure><h4 id="3-由证书文件生成公钥给客户端使用"><a href="#3-由证书文件生成公钥给客户端使用" class="headerlink" title="3. 由证书文件生成公钥给客户端使用"></a>3. 由证书文件生成公钥给客户端使用</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keytool -import -<span class="built_in">alias</span> presto-public -file presto-public.cer -keystore presto.keystore -storepass &lt;passwd&gt;</span><br></pre></td></tr></table></figure><p>此处<code>&lt;passwd&gt;</code>可与私钥不同，后续客户端登录时需要显示输入该密码</p><h3 id="修改Presto-coordinator配置"><a href="#修改Presto-coordinator配置" class="headerlink" title="修改Presto coordinator配置"></a>修改Presto coordinator配置</h3><p>修改<code>etc/config.properties</code>文件，添加如下配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">http-server.authentication.type=PASSWORD</span><br><span class="line">http-server.https.enabled=<span class="literal">true</span></span><br><span class="line">http-server.https.port=8443</span><br><span class="line"></span><br><span class="line">http-server.https.keystore.path=&lt;private_keystore_path&gt;</span><br><span class="line">http-server.https.keystore.key=&lt;keystore_passwd&gt;</span><br></pre></td></tr></table></figure><p>修改<code>etc/password-authenticator.properties</code>文件，添加如下配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">password-authenticator.name=ldap</span><br><span class="line">ldap.url=ldaps://&lt;ldap_server&gt;:636</span><br><span class="line">ldap.user-bind-pattern=uid=<span class="variable">$&#123;USER&#125;</span>,dc=example,dc=com</span><br></pre></td></tr></table></figure><p><code>ldap.user-bind-pattern</code>需要填写登录用户如何映射到ldap的dn，其中<code>${USER}</code>表示登录的用户名，即presto cli登录时<code>--username</code>参数填写的内容。</p><p>配置完成后需要重启Presto coordinator使配置生效，之后便可以使用客户端登录，进行ldap认证了。</p><h3 id="Presto-cli登录配置"><a href="#Presto-cli登录配置" class="headerlink" title="Presto cli登录配置"></a>Presto cli登录配置</h3><p>使用如下命令连接presto server，相比没有ldap认证时候需要填写keystore、user、password等内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">presto --server https://&lt;presto_server&gt;:&lt;https_port&gt; --keystore-path &lt;public_keystore_path&gt; --keystore-password &lt;public_keystore_passwd&gt; --catalog hive --user &lt;ldap_username&gt; --password</span><br></pre></td></tr></table></figure><p>输入密码之后将可以进入presto命令行。若密码输入错误，也可以进入presto命令行，但是执行presto命令会出现认证失败的报错。输入正确的ldap用户名和密码，执行<code>show schemas;</code>，若能正确输出结果说明配置正确。</p>]]></content>
      
      
      
        <tags>
            
            <tag> LDAP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS7上安装Kerberos KDC</title>
      <link href="/2020/04/24/CentOS7%E4%B8%8A%E5%AE%89%E8%A3%85Kerberos-KDC/"/>
      <url>/2020/04/24/CentOS7%E4%B8%8A%E5%AE%89%E8%A3%85Kerberos-KDC/</url>
      
        <content type="html"><![CDATA[<h3 id="yum安装软件"><a href="#yum安装软件" class="headerlink" title="yum安装软件"></a>yum安装软件</h3><p>首先通过yum安装kerberos所需要的软件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y krb5-server krb5-workstation pam_krb5</span><br></pre></td></tr></table></figure><h3 id="修改服务端配置"><a href="#修改服务端配置" class="headerlink" title="修改服务端配置"></a>修改服务端配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /var/kerberos/krb5kdc</span><br></pre></td></tr></table></figure><p>我们需要修改该目录下的两个配置文件：</p><ul><li>kdc.conf</li><li>kadm5.acl</li></ul><p>假设我们的realm为KDC.COM，修改<code>kadm5.acl</code>为如下内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/admin@KDC.COM     *</span><br></pre></td></tr></table></figure><p>修改<code>kdc.conf</code>为如下内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[kdcdefaults]</span><br><span class="line"> kdc_ports = 88</span><br><span class="line"> kdc_tcp_ports = 88</span><br><span class="line"></span><br><span class="line">[realms]</span><br><span class="line"> KDC.COM = &#123;</span><br><span class="line">  <span class="comment">#master_key_type = aes256-cts</span></span><br><span class="line">  max_renewable_life = 7d</span><br><span class="line">  acl_file = /var/kerberos/krb5kdc/kadm5.acl</span><br><span class="line">  dict_file = /usr/share/dict/words</span><br><span class="line">  admin_keytab = /var/kerberos/krb5kdc/kadm5.keytab</span><br><span class="line">  supported_enctypes = aes256-cts:normal aes128-cts:normal des3-hmac-sha1:normal arcfour-hmac:normal camellia256-cts:normal camellia128-cts:normal des-hmac-sha1:normal des-cbc-md5:normal des-cbc-crc:normal</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h3 id="修改客户端配置"><a href="#修改客户端配置" class="headerlink" title="修改客户端配置"></a>修改客户端配置</h3><p>我们用作KDC服务的服务器也将会是一个Kerberos客户端，我们需要修改客户端配置文件<code>/etc/krb5.conf</code>，文件内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Configuration snippets may be placed in this directory as well</span></span><br><span class="line">includedir /etc/krb5.conf.d/</span><br><span class="line"></span><br><span class="line">[logging]</span><br><span class="line"> default = FILE:/var/<span class="built_in">log</span>/krb5libs.log</span><br><span class="line"> kdc = FILE:/var/<span class="built_in">log</span>/krb5kdc.log</span><br><span class="line"> admin_server = FILE:/var/<span class="built_in">log</span>/kadmind.log</span><br><span class="line"></span><br><span class="line">[libdefaults]</span><br><span class="line"> dns_lookup_realm = <span class="literal">false</span></span><br><span class="line"> ticket_lifetime = 24h</span><br><span class="line"> renew_lifetime = 7d</span><br><span class="line"> forwardable = <span class="literal">true</span></span><br><span class="line"> rdns = <span class="literal">false</span></span><br><span class="line"> pkinit_anchors = /etc/pki/tls/certs/ca-bundle.crt</span><br><span class="line"> default_realm = KDC.COM</span><br><span class="line"> default_ccache_name = KEYRING:persistent:%&#123;uid&#125;</span><br><span class="line"> default_tgs_enctypes = aes128-cts arcfour-hmac-md5 des-cbc-crc des-cbc-md5 des-hmac-sha1 aes256-cts</span><br><span class="line"> default_tkt_enctypes = aes128-cts arcfour-hmac-md5 des-cbc-crc des-cbc-md5 des-hmac-sha1 aes256-cts</span><br><span class="line"> permitted_enctypes = aes256-cts-hmac-sha1-96 des3-cbc-sha1 arcfour-hmac-md5 des-cbc-crc des-cbc-md5 des-cbc-md4</span><br><span class="line"> allow_weak_crypto = yes</span><br><span class="line"></span><br><span class="line">[realms]</span><br><span class="line"> KDC.COM = &#123;</span><br><span class="line">  kdc = kdc.hostname</span><br><span class="line">  admin_server = kdc.hostname</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">[domain_realm]</span><br><span class="line"> .kdc.com = KDC.COM</span><br><span class="line"> kdc.com = KDC.COM</span><br></pre></td></tr></table></figure><h3 id="创建KDC数据库"><a href="#创建KDC数据库" class="headerlink" title="创建KDC数据库"></a>创建KDC数据库</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kdb5_util create -s -r KDC.COM</span><br></pre></td></tr></table></figure><h3 id="开启Kerberos"><a href="#开启Kerberos" class="headerlink" title="开启Kerberos"></a>开启Kerberos</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start krb5kdc kadmin</span><br><span class="line">systemctl <span class="built_in">enable</span> krb5kdc kadmin</span><br></pre></td></tr></table></figure><p>接下来需要创建kadmin的管理员账号：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kadmin.local</span><br><span class="line">kadmin.local: addprinc root/admin</span><br><span class="line">kadmin.local: quit</span><br></pre></td></tr></table></figure><h3 id="修改SSH客户端配置"><a href="#修改SSH客户端配置" class="headerlink" title="修改SSH客户端配置"></a>修改SSH客户端配置</h3><p>修改<code>/etc/ssh/ssh_config</code>，添加如下配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GSSAPIAuthentication yes</span><br><span class="line">GSSAPIDelegateCredentials yes</span><br></pre></td></tr></table></figure><p>执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">authconfig  --enablekrb5 --update</span><br><span class="line">systemctl reload sshd</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> kerberos </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS 7安装Facebook folly库</title>
      <link href="/2019/04/26/CentOS-7%E5%AE%89%E8%A3%85Facebook-folly%E5%BA%93/"/>
      <url>/2019/04/26/CentOS-7%E5%AE%89%E8%A3%85Facebook-folly%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<p>folly是Facebook提出的一个基于C++14的C++组件库，包含有非常多具有实用性和效率性的数据结构。其github地址为： <a href="https://github.com/facebook/folly" target="_blank" rel="noopener">https://github.com/facebook/folly</a> 。在其README当中提供了在ubuntu和MacOS中的安装教程，没有CentOS中的安装教程，并且在CentOS当中安装会遇到很多问题，本文对在CentOS 7系统中安装folly库进行了过程记录。</p><p>最新的folly需要gcc的版本高于5.1，但是CentOS 7中的gcc版本为4.8，直接升级安装gcc非常麻烦，并且可能会对其他项目使用的gcc造成影响，以采用我另一篇博客中提及的方法切换到高版本的gcc： </p><p><a href="http://joey771.cn/2018/04/16/linux/CentOS%E5%AE%89%E8%A3%85%E9%AB%98%E7%89%88%E6%9C%ACgcc/">http://joey771.cn/2018/04/16/linux/CentOS%E5%AE%89%E8%A3%85%E9%AB%98%E7%89%88%E6%9C%ACgcc/</a> </p><p>从官网提供的ubuntu安装教程中可以看出，其依赖于boost-devel、glog-devel、gflags-devel、double-conversion等库，有些库可以通过yum来进行安装，有些则需要通过源码编译安装。首先是可以使用yum安装的库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install boost-devel \</span><br><span class="line">double-conversion-devel \</span><br><span class="line">libevent-devel \</span><br><span class="line">openssl-devel \</span><br><span class="line">lz4-devel \</span><br><span class="line">xz-devel \</span><br><span class="line">snappy-devel \</span><br><span class="line">zlib-devel \</span><br><span class="line">jemalloc-devel \</span><br><span class="line">libtool \</span><br><span class="line">scons</span><br></pre></td></tr></table></figure><p>编译安装gflags、glog</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/schuhschuh/gflags.git</span><br><span class="line">mkdir gflags/build</span><br><span class="line"><span class="built_in">cd</span> gflags/build</span><br><span class="line">cmake -DGFLAGS_NAMESPACE=google -DBUILD_SHARED_LIBS=on ..</span><br><span class="line">make -j 8</span><br><span class="line">sudo make install</span><br><span class="line"></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/google/glog.git</span><br><span class="line"><span class="built_in">cd</span> glog</span><br><span class="line">autoreconf -ivf</span><br><span class="line">./configure --with-gflags=/usr/<span class="built_in">local</span>/lib</span><br><span class="line">make -j 8</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure><p>编译安装folly</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/facebook/folly.git</span><br><span class="line"><span class="built_in">cd</span> folly</span><br><span class="line">mkdir _build &amp;&amp; <span class="built_in">cd</span> _build</span><br><span class="line">cmake ..</span><br><span class="line">make -j 8</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>苹果电脑U盘安装新版MacOS</title>
      <link href="/2019/04/11/%E8%8B%B9%E6%9E%9C%E7%94%B5%E8%84%91U%E7%9B%98%E5%AE%89%E8%A3%85%E6%96%B0%E7%89%88MacOS/"/>
      <url>/2019/04/11/%E8%8B%B9%E6%9E%9C%E7%94%B5%E8%84%91U%E7%9B%98%E5%AE%89%E8%A3%85%E6%96%B0%E7%89%88MacOS/</url>
      
        <content type="html"><![CDATA[<p>最近拿到了一台2012年中的MacBook Air，其系统版本非常老，还是10.7，需要对其系统进行升级。一开时以为直接用系统更新就能升级上去，但是第一次更新就遇到了“不能存储更新”的问题，无法升级，试了好几次都在最后快下完的时候报这个错误。查资料说是因为系统版本太老了，要手动下载组合更新包才能升级。</p><p>在<a href="https://support.apple.com/zh_CN/downloads/macos" target="_blank" rel="noopener">https://support.apple.com/zh_CN/downloads/macos</a> 上可以找到所有MacOS的组合更新包，一直往下拉找到10.7.5的组合更新包，下下来以后直接安装非常容易就安装上去了。接下来继续检查更新，更新了一些软件内容，之后就提示所有内容已经是最新的了，但是这时候系统版本还是10.7.5，已经无法再往上升级了，于是去下了10.8版本最早的组合更新包10.8.2，点击安装确提示只能支持10.8的系统。</p><p>查了资料才知道，当时10.8发布的时候从10.7.5升上去是要19美元的，人民币好像120多，之后苹果系统都是免费的了。App Store里面10.8的升级早就下架了，已经无法以正常的更新途径来更新系统了，只能自己制作U盘启动盘来更新这个系统。首先查了一下各个版本的MacOS对老机型的兼容性。</p><ul><li>10.11 OS X El Capitan <a href="https://support.apple.com/zh-cn/HT206886" target="_blank" rel="noopener">https://support.apple.com/zh-cn/HT206886</a></li><li>10.12 macOS Sierra <a href="https://support.apple.com/zh-cn/HT208202" target="_blank" rel="noopener">https://support.apple.com/zh-cn/HT208202</a></li><li>10.13 macOS High Sierra <a href="https://support.apple.com/zh-cn/HT208969" target="_blank" rel="noopener">https://support.apple.com/zh-cn/HT208969</a></li><li>10.14 macOS Mojave <a href="https://support.apple.com/zh-cn/HT201475" target="_blank" rel="noopener">https://support.apple.com/zh-cn/HT201475</a></li></ul><p>看了一下，这些系统都是支持这台MacBook Air的，最新的10.14应该是这台电脑最高能升的系统了，以后再有新系统的更新估计就上不去了。我决定直接升级到10.11，于是找了一个10.11.6的系统镜像dmg文件，下了半天才下好，打开的时候却说什么“校验和”有问题，后来查了一下直接打开的时候点跳过就可以了，里面有一个<code>Install OS X El Capitan.app</code>，把它随便拖到一个文件夹里面。</p><p>之后准备一个8G以上的U盘插入电脑，打开磁盘工具，点击左上角的显示，选择显示所有设备。找到自己的U盘，点最外层的设备，选择抹掉，分区类型选GUID，格式选Mac OS扩展（日志式），取一个名字叫OSX。格式化完毕之后，输入以下命令来进行启动盘制作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /Users/joey/Downloads/xxx.app/Contents/Resources/createinstallmedia --volume /Volumes/OSX --applicationpath /Users/joey/Downloads/xxx.app --nointeraction</span><br></pre></td></tr></table></figure><p>我是把app文件拖到了Downloads目录下的，这里xxx就代表了这个app文件的名字，其他版本的MacOS制作U盘启动盘的命令都是一样的，这个过程持续的时间比较长。做好之后重启电脑，按住option键，选择U盘启动，之后的过程很简单，一步一步点就行了。但是到最后还是安装失败了，报了一个错“应用程序副本不能验证 它在下载过程中可能已遭破坏或篡改”。这个问题很多人都说在安装的时候在终端里通过date修改时间就可以解决，我试了一下没办法解决这个问题。但是我看了一下，遇到这个问题的大多数都是安装10.11以及之前版本的MacOS的，那时候系统还不叫MacOS，叫OSX。估计OSX有个时间上的验证机制，于是放弃安装10.11，毕竟这台电脑还可以装10.12，10.13和10.14，估计就不会有这个问题了。重新制作启动盘，流程和上面一样，然后就顺利安装上去了。</p><p>接下来就是用boot camp安装win10双系统，又遇到了奇葩问题，用boot camp做了启动盘之后一直会出现无法引导的问题，可以用efi引导进去安装，但是会遇到分区表类型无法兼容efi的问题，删除分区和格式化都没法解决，找到一个比较挫的方法是先在Mac系统里把BOOTCAMP的分区格式化成Mac OS扩展（日志式），然后安装windows的时候删除那个分区即可安装上去，但是这样那个分区在Mac系统中就不受boot camp控制了，删除windows系统还原分区的时候比较麻烦。查了很久，一个帖子恰好也是这一款MacBook Air，也出现了一样的问题，被我查到了<a href="https://www.cnblogs.com/pinganzi/p/10354296.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinganzi/p/10354296.html</a> ，他的第一个问题我没遇到，第二个问题和我一样，于是我换了一个USB2.0的U盘，马上就解决问题了，但是安装win10的时候会说需要先格式化成NTFS，直接点格式化就可以安装了。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Mac </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>修改Microsoft Offince加载项加载行为</title>
      <link href="/2019/04/09/%E4%BF%AE%E6%94%B9Microsoft-Offince%E5%8A%A0%E8%BD%BD%E9%A1%B9%E5%8A%A0%E8%BD%BD%E8%A1%8C%E4%B8%BA/"/>
      <url>/2019/04/09/%E4%BF%AE%E6%94%B9Microsoft-Offince%E5%8A%A0%E8%BD%BD%E9%A1%B9%E5%8A%A0%E8%BD%BD%E8%A1%8C%E4%B8%BA/</url>
      
        <content type="html"><![CDATA[<p>最近在写论文时，需要将word文档导出为pdf文档。将word导出为pdf之前一直使用的是另存为的方法，也可以使用打印选择Adobe PDF来生成pdf文件，但是这两种方法都有一定的局限性。打印的方法生成pdf不能选择添加书签，但是能控制输出文件的清晰度，调到比较高时，能生成非常清晰的pdf文件。word2016中已经可以使用另存为来导出pdf，并且在选项当中也可以设置是否导出书签，但是输出的pdf文件的清晰度调整选项不够多，输出的pdf中图片会被压缩，变得模糊。<br>实际上，安装了Adobe Acrobat的word当中有一个Acrobat的加载项菜单，里面的首选项菜单可以很详细地配置导出的pdf文件的一些参数，可以选择高质量打印，并且将其中的图片的压缩和采样全都关掉，并且可以设置输出的清晰度以及书签等等。但是这个加载项在生成pdf结束后，会导致word崩溃，出来一个提示问我是否要禁用该加载项，一时手滑点到了是，结果这个加载项就被禁用了。禁用之后也好办，可以在word的选项-加载项-转到里面勾选Adobe PDFMaker加载项进行加载。但是这个加载项原本是随word启动自动加载的，现在变成了每次都要去选项里面设置加载，非常麻烦，并且选项里面并没有菜单可以选择让这个加载项自动加载。这里便需要修改注册表来实现随word启动自动加载，注册表的位置为:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HKEY_CURRENT_USER\Software\Microsoft\Office\Word\Addins\PDFMaker.OfficeAddin</span><br></pre></td></tr></table></figure><p>进去之后发现有一个LoadBehavior的键的值现在是0，我观察到Addins里面还有有道词典的加载项，这个加载项是会随word自动启动的，其LoadBehavior的值为3，于是将PDFMaker.OfficeAddin中LoadBehavior的值也改为3便能自动随word启动了，大功告成。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>linux命令行安装MATLAB</title>
      <link href="/2019/01/18/linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%AE%89%E8%A3%85MATLAB/"/>
      <url>/2019/01/18/linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%AE%89%E8%A3%85MATLAB/</url>
      
        <content type="html"><![CDATA[<p>登录MATLAB的MathWorks，选择右上角的我的账户，点击许可证右侧的许可证管理，进入后选择安装和激活，之后选择“激活并获取许可证文件”，选择激活计算机，填入相关信息。其中主机ID即为电脑用于上外网的网卡的MAC地址，可以使用<code>ipconfig</code>进行查看，计算机登录名就是当前登录用户的用户名，不知道的话可以使用<code>whoami</code>指令进行查看。填写完成后会生成一个序列号，和一个lisence.lic文件，将文件上传至安装MATLAB的服务器上并记录激活序列号。</p><p>下载包含所有产品的完整MATLAB安装包，官网下载的只是一个100MB多的一个网络安装器，安装过程中才会下载需要的产品，这对于命令行安装是不适用的，命令行安装必须使用完整的离线安装包。之后需要填写silent安装模式下的安装配置文件，具体模板如下：</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br></pre></td><td class="code"><pre><span class="line">##################################################################</span><br><span class="line">##</span><br><span class="line">## Use this file to specify parameters required by the installer at runtime.</span><br><span class="line">##</span><br><span class="line">## Instructions for using this file.</span><br><span class="line">##</span><br><span class="line">## 1. Create a copy of this template file and fill in the required</span><br><span class="line">##    information.</span><br><span class="line">##</span><br><span class="line">## 2. Uncomment only those lines that start with a single &apos;#&apos;</span><br><span class="line">##    and set the desired values. All allowed values for the</span><br><span class="line">##    parameters are defined in the comments section for each</span><br><span class="line">##    parameter.</span><br><span class="line">##</span><br><span class="line">## 3. Launch the installer from the command line, using the -inputFile option</span><br><span class="line">##    to specify the name of your installer initialization file.</span><br><span class="line">##</span><br><span class="line">##    (Windows) setup.exe -inputFile &lt;file_name&gt;</span><br><span class="line">##    (Mac/Unix) install -inputFile &lt;file_name&gt;</span><br><span class="line">##</span><br><span class="line">## NOTE:</span><br><span class="line">##    If you want to run the activation application in silent</span><br><span class="line">##    mode immediately after the installer completes, you must create</span><br><span class="line">##    an activation initialization file and specify its name as the</span><br><span class="line">##    value of the activationPropertiesFile= option. You can also</span><br><span class="line">##    pass the name of the activation initialization file to the</span><br><span class="line">##    installer using the -activationPropertiesFile command line</span><br><span class="line">##    option.</span><br><span class="line">##</span><br><span class="line">##################################################################</span><br><span class="line">##</span><br><span class="line">##</span><br><span class="line">## SPECIFY INSTALLATION FOLDER</span><br><span class="line">##</span><br><span class="line">## Example:</span><br><span class="line">##        (Windows) destinationFolder=C:\Program Files\MATLAB\RXXXX</span><br><span class="line">##        (Unix) destinationFolder=/usr/local/RXXXX</span><br><span class="line">##        (Mac) destinationFolder=/Applications</span><br><span class="line">##</span><br><span class="line">## Set the desired value for destinationFolder and</span><br><span class="line">## uncomment the line.</span><br><span class="line"></span><br><span class="line"># destinationFolder=</span><br><span class="line"></span><br><span class="line">##</span><br><span class="line">## SPECIFY FILE INSTALLATION KEY</span><br><span class="line">##</span><br><span class="line">## Example: fileInstallationKey=xxxxx-xxxxx-xxxxx-xxxxx.....</span><br><span class="line">##</span><br><span class="line">## Set the desired value for fileInstallationKey and</span><br><span class="line">## uncomment the line.</span><br><span class="line">##</span><br><span class="line"># fileInstallationKey=</span><br><span class="line"></span><br><span class="line">##</span><br><span class="line">## ACCEPT LICENSE AGREEMENT</span><br><span class="line">##</span><br><span class="line">## You must agree to the license agreement to install MathWorks products.</span><br><span class="line">## The license agreement can be found in the license_agreement.txt file at the</span><br><span class="line">## root level of the installation DVD.</span><br><span class="line">##</span><br><span class="line">## Example: agreeToLicense=yes</span><br><span class="line">##</span><br><span class="line">## Set agreeToLicense value to yes or no and</span><br><span class="line">## uncomment the line.</span><br><span class="line"></span><br><span class="line"># agreeToLicense=</span><br><span class="line"></span><br><span class="line">##</span><br><span class="line">## SPECIFY OUTPUT LOG</span><br><span class="line">##</span><br><span class="line">## Specify full path of file into which you want the results of the</span><br><span class="line">## installation to be recorded.</span><br><span class="line">##</span><br><span class="line">## Example:</span><br><span class="line">##            (Windows) outputFile=C:\TEMP\mathworks_&lt;user_name&gt;.log</span><br><span class="line">##            (Unix/Mac) outputFile=/tmp/mathworks_&lt;user_name&gt;.log</span><br><span class="line">##</span><br><span class="line">## Set the desired value for outputFile and</span><br><span class="line">## uncomment the line.</span><br><span class="line"></span><br><span class="line"># outputFile=</span><br><span class="line"></span><br><span class="line">## SPECIFY INSTALLER MODE</span><br><span class="line">##</span><br><span class="line">## interactive: Run the installer GUI, waiting for user input on all</span><br><span class="line">##              dialog boxes.</span><br><span class="line">##</span><br><span class="line">## silent:      Run the installer without displaying the GUI.</span><br><span class="line">##</span><br><span class="line">## automated:   Run the installer GUI, displaying all dialog boxes, but only</span><br><span class="line">##              waiting for user input on dialogs that are missing required</span><br><span class="line">##              input.</span><br><span class="line">##</span><br><span class="line">## Set mode value to either interactive, silent, or automated and</span><br><span class="line">## uncomment the line.</span><br><span class="line"></span><br><span class="line"># mode=</span><br><span class="line"></span><br><span class="line">## SPECIFY LENGTH OF TIME DIALOG BOXES ARE DISPLAYED</span><br><span class="line">##</span><br><span class="line">## Specify how long the installer dialog boxes are displayed, in milliseconds.</span><br><span class="line">##</span><br><span class="line">## NOTE: Use this value only if you set the installer mode to automated.</span><br><span class="line">##</span><br><span class="line">## By default, the dialog boxes display on the screen for one second.</span><br><span class="line">##</span><br><span class="line">## Example: (To specify a value of 1 second.) automatedModeTimeout=1000</span><br><span class="line">##</span><br><span class="line">## Set the desired value for automatedModeTimeout and</span><br><span class="line">## uncomment the line.</span><br><span class="line"></span><br><span class="line"># automatedModeTimeout=</span><br><span class="line"></span><br><span class="line">## SPECIFY ACTIVATION PROPERTIES FILE (For non-network license types only)</span><br><span class="line">##</span><br><span class="line">## Enter the path to an existing file that contains properties to configure</span><br><span class="line">## the activation process.</span><br><span class="line"></span><br><span class="line"># activationPropertiesFile=</span><br><span class="line"></span><br><span class="line">########## Begin: Options for Network License Types #########</span><br><span class="line">##</span><br><span class="line">## SPECIFY PATH TO LICENSE FILE (Required for network license types only)</span><br><span class="line">##</span><br><span class="line">## This value is required when installing either the License Manager or when</span><br><span class="line">## installing as a Network End-User</span><br><span class="line">## Example:</span><br><span class="line">##            (Windows) licensePath=C:\TEMP\license.dat</span><br><span class="line">##            (Unix) licensePath=/tmp/license.dat</span><br><span class="line">## Set the desired value for licensePath and</span><br><span class="line">## uncomment the line.</span><br><span class="line"></span><br><span class="line"># licensePath=</span><br><span class="line"></span><br><span class="line">## CHOOSE TO INSTALL LICENSE MANAGER (For network license types only)</span><br><span class="line">##</span><br><span class="line">## Installs license manager files to disk.</span><br><span class="line">##</span><br><span class="line">## NOTE: You only need to install the license manager files</span><br><span class="line">## on your license server.</span><br><span class="line">##</span><br><span class="line">## Set lmgrFiles value to true or false and</span><br><span class="line">## uncomment the line.</span><br><span class="line"></span><br><span class="line"># lmgrFiles=</span><br><span class="line"></span><br><span class="line">## INSTALL LICENSE MANAGER AS A SERVICE (For network license types only)</span><br><span class="line">##</span><br><span class="line">## Configure the license manager as a service on Windows.</span><br><span class="line">##</span><br><span class="line">## NOTE: Not applicable for Unix or Mac.</span><br><span class="line">##</span><br><span class="line">## NOTE: The lmgr_files option (set in previous step) must also be set to true.</span><br><span class="line">##</span><br><span class="line">## Set lmgrService value to true or false and</span><br><span class="line">## uncomment the line.</span><br><span class="line"></span><br><span class="line"># lmgrService=</span><br><span class="line"></span><br><span class="line">########## End: Options for Network License Types #########</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">################# Begin - Windows Only Options ################</span><br><span class="line">##</span><br><span class="line">## CHOOSE TO SET FILE ASSOCIATIONS</span><br><span class="line">##</span><br><span class="line">## Set to true if you want the installer to associate file types used by MathWorks</span><br><span class="line">## products to this version of MATLAB, or false if you do not want the installer to</span><br><span class="line">## associate MathWorks file types with this version of MATLAB.</span><br><span class="line">##</span><br><span class="line">## Default value is true.</span><br><span class="line">##</span><br><span class="line">## Set setFileAssoc value to true or false and</span><br><span class="line">## uncomment the line.</span><br><span class="line"></span><br><span class="line"># setFileAssoc=</span><br><span class="line"></span><br><span class="line">##</span><br><span class="line">## CHOOSE TO CREATE WINDOWS DESKTOP SHORTCUT</span><br><span class="line">##</span><br><span class="line">## Set to true if you would like the installer to create a desktop shortcut icon</span><br><span class="line">## when MATLAB is installed or false if you don&apos;t want the shortcut created.</span><br><span class="line">##</span><br><span class="line">## Set desktopShortcut value to true or false and</span><br><span class="line">## uncomment the line.</span><br><span class="line"></span><br><span class="line"># desktopShortcut=</span><br><span class="line"></span><br><span class="line">## CHOOSE TO ADD SHORTCUT TO WINDOWS START MENU</span><br><span class="line">##</span><br><span class="line">## Set to true if you would like the installer to create a Start Menu shortcut</span><br><span class="line">## icon when MATLAB is installed or false if you don&apos;t want the shortcut created.</span><br><span class="line">##</span><br><span class="line">## Set startMenuShortcut value to true or false and</span><br><span class="line">## uncomment the line.</span><br><span class="line"></span><br><span class="line"># startMenuShortcut=</span><br><span class="line"></span><br><span class="line">## CREATE a MATLAB Startup Accelerator task</span><br><span class="line">##</span><br><span class="line">## The MATLAB Startup Accelerator installer creates a</span><br><span class="line">## system task to preload MATLAB into the system&apos;s cache</span><br><span class="line">## for faster startup.</span><br><span class="line">##</span><br><span class="line">## NOTE: By default, a MATLAB Startup Accelerator task will</span><br><span class="line">## automatically be created.</span><br><span class="line">##</span><br><span class="line">## If you want a MATLAB Startup Accelerator task to be created,</span><br><span class="line">## do not edit this section.</span><br><span class="line">##</span><br><span class="line">## Set createAccelTask value to false if you do not want to</span><br><span class="line">## create an Accelerator task and uncomment the line.</span><br><span class="line"></span><br><span class="line"># createAccelTask=</span><br><span class="line"></span><br><span class="line">## Enable Login Named User  licensing</span><br><span class="line">##</span><br><span class="line">## Set to Yes to enable use of a Login Named User license for all users of this MATLAB installation</span><br><span class="line">## Users must log in to their MathWorks Account when MATLAB starts.</span><br><span class="line">##</span><br><span class="line">## Example: enableLNU=yes</span><br><span class="line">##</span><br><span class="line">## NOTE: This flag is valid in silent installations only.</span><br><span class="line"></span><br><span class="line"># enableLNU=yes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">################ End - Windows Only Options ################</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## SPECIFY PRODUCTS YOU WANT TO INSTALL</span><br><span class="line">##</span><br><span class="line">## By default, the installer installs all the products and</span><br><span class="line">## documentation for which you are licensed. Products you are not licensed for</span><br><span class="line">## are not installed, even if they are listed here.</span><br><span class="line">##</span><br><span class="line">## Note:</span><br><span class="line">## 1. To automatically install all your licensed products, do not edit</span><br><span class="line">##    any lines in this section.</span><br><span class="line">##</span><br><span class="line">## 2. To install a specific product or a subset of products for</span><br><span class="line">##    which you are licensed, uncomment the line for the product(s) you want</span><br><span class="line">##    to install.</span><br><span class="line"></span><br><span class="line">#product.5G_Toolbox</span><br><span class="line">#product.Aerospace_Blockset</span><br><span class="line">#product.Aerospace_Toolbox</span><br><span class="line">#product.Antenna_Toolbox</span><br><span class="line">#product.Audio_System_Toolbox</span><br><span class="line">#product.Automated_Driving_System_Toolbox</span><br><span class="line">#product.Bioinformatics_Toolbox</span><br><span class="line">#product.Communications_Toolbox</span><br><span class="line">#product.Computer_Vision_System_Toolbox</span><br><span class="line">#product.Control_System_Toolbox</span><br><span class="line">#product.Curve_Fitting_Toolbox</span><br><span class="line">#product.DO_Qualification_Kit</span><br><span class="line">#product.DSP_System_Toolbox</span><br><span class="line">#product.Data_Acquisition_Toolbox</span><br><span class="line">#product.Database_Toolbox</span><br><span class="line">#product.Datafeed_Toolbox</span><br><span class="line">#product.Deep_Learning_Toolbox</span><br><span class="line">#product.Econometrics_Toolbox</span><br><span class="line">#product.Embedded_Coder</span><br><span class="line">#product.Filter_Design_HDL_Coder</span><br><span class="line">#product.Financial_Instruments_Toolbox</span><br><span class="line">#product.Financial_Toolbox</span><br><span class="line">#product.Fixed_Point_Designer</span><br><span class="line">#product.Fuzzy_Logic_Toolbox</span><br><span class="line">#product.GPU_Coder</span><br><span class="line">#product.Global_Optimization_Toolbox</span><br><span class="line">#product.HDL_Coder</span><br><span class="line">#product.HDL_Verifier</span><br><span class="line">#product.IEC_Certification_Kit</span><br><span class="line">#product.Image_Acquisition_Toolbox</span><br><span class="line">#product.Image_Processing_Toolbox</span><br><span class="line">#product.Instrument_Control_Toolbox</span><br><span class="line">#product.LTE_HDL_Toolbox</span><br><span class="line">#product.LTE_Toolbox</span><br><span class="line">#product.MATLAB</span><br><span class="line">#product.MATLAB_Coder</span><br><span class="line">#product.MATLAB_Compiler</span><br><span class="line">#product.MATLAB_Compiler_SDK</span><br><span class="line">#product.MATLAB_Distributed_Computing_Server</span><br><span class="line">#product.MATLAB_Production_Server</span><br><span class="line">#product.MATLAB_Report_Generator</span><br><span class="line">#product.Mapping_Toolbox</span><br><span class="line">#product.Model_Predictive_Control_Toolbox</span><br><span class="line">#product.Model_Based_Calibration_Toolbox</span><br><span class="line">#product.OPC_Toolbox</span><br><span class="line">#product.Optimization_Toolbox</span><br><span class="line">#product.Parallel_Computing_Toolbox</span><br><span class="line">#product.Partial_Differential_Equation_Toolbox</span><br><span class="line">#product.Phased_Array_System_Toolbox</span><br><span class="line">#product.Polyspace_Bug_Finder</span><br><span class="line">#product.Polyspace_Code_Prover</span><br><span class="line">#product.Powertrain_Blockset</span><br><span class="line">#product.Predictive_Maintenance_Toolbox</span><br><span class="line">#product.RF_Blockset</span><br><span class="line">#product.RF_Toolbox</span><br><span class="line">#product.Risk_Management_Toolbox</span><br><span class="line">#product.Robotics_System_Toolbox</span><br><span class="line">#product.Robust_Control_Toolbox</span><br><span class="line">#product.Sensor_Fusion_and_Tracking_Toolbox</span><br><span class="line">#product.Signal_Processing_Toolbox</span><br><span class="line">#product.SimBiology</span><br><span class="line">#product.SimEvents</span><br><span class="line">#product.Simscape</span><br><span class="line">#product.Simscape_Driveline</span><br><span class="line">#product.Simscape_Electrical</span><br><span class="line">#product.Simscape_Fluids</span><br><span class="line">#product.Simscape_Multibody</span><br><span class="line">#product.Simulink</span><br><span class="line">#product.Simulink_3D_Animation</span><br><span class="line">#product.Simulink_Check</span><br><span class="line">#product.Simulink_Code_Inspector</span><br><span class="line">#product.Simulink_Coder</span><br><span class="line">#product.Simulink_Control_Design</span><br><span class="line">#product.Simulink_Coverage</span><br><span class="line">#product.Simulink_Design_Optimization</span><br><span class="line">#product.Simulink_Design_Verifier</span><br><span class="line">#product.Simulink_Desktop_Real_Time</span><br><span class="line">#product.Simulink_PLC_Coder</span><br><span class="line">#product.Simulink_Real_Time</span><br><span class="line">#product.Simulink_Report_Generator</span><br><span class="line">#product.Simulink_Requirements</span><br><span class="line">#product.Simulink_Test</span><br><span class="line">#product.Spreadsheet_Link</span><br><span class="line">#product.Stateflow</span><br><span class="line">#product.Statistics_and_Machine_Learning_Toolbox</span><br><span class="line">#product.Symbolic_Math_Toolbox</span><br><span class="line">#product.System_Identification_Toolbox</span><br><span class="line">#product.Text_Analytics_Toolbox</span><br><span class="line">#product.Trading_Toolbox</span><br><span class="line">#product.Vehicle_Dynamics_Blockset</span><br><span class="line">#product.Vehicle_Network_Toolbox</span><br><span class="line">#product.Vision_HDL_Toolbox</span><br><span class="line">#product.WLAN_Toolbox</span><br><span class="line">#product.Wavelet_Toolbox</span><br></pre></td></tr></table></figure><p>我们需要填写的内容主要有：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">destinationFolder=/usr/local/RXXXX</span><br><span class="line">fileInstallationKey=xxxxx-xxxxx-xxxxx-xxxxx.....</span><br><span class="line">agreeToLicense=yes</span><br><span class="line">mode=silent</span><br><span class="line">licensePath=/tmp/license.lic</span><br></pre></td></tr></table></figure><p>该配置文件需要指定安装路径（不指定的话安装路径默认为/usr/local/MATLAB），同意协议，安装模式为silent，激活序列号，证书文件路径，最后可以指定需要安装的产品，按照模板中的内容将对应产品前的注释取消即可，若不知道需要哪些产品，不添加任何产品则会安装所有的产品。之后解压离线安装包，这里需要注意的是，离线安装包解压后里面很多可执行文件的权限会没有执行权限，直接安装的话会很快结束，无法正常安装，由于不方便将所有可执行文件都找出来添加执行权限，这里需要暴力使用<code>chmod -R 777 MATLAB_dir</code>将安装包解压文件夹下的所有文件的权限都变为777，这样才能正确安装，之后使用如下指令进行安装（installer_input.txt为之前写的配置文件的路径）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./install.sh -inputFile installer_input.txt</span><br></pre></td></tr></table></figure><p>安装完成后，还需要将license.lic文件移动到安装目录下的license目录当中完成激活。<br>之后可能会遇到libXt.so.6找不到的问题，该库文件是用于支持x11的，按道理说以命令行方式运行是不需要x11的，但是还是会报错，解决方法便是安装缺失的这个库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install libxt6</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>ubuntu安装OpenCL运行及编译环境</title>
      <link href="/2019/01/18/ubuntu%E5%AE%89%E8%A3%85OpenCL%E8%BF%90%E8%A1%8C%E5%8F%8A%E7%BC%96%E8%AF%91%E7%8E%AF%E5%A2%83/"/>
      <url>/2019/01/18/ubuntu%E5%AE%89%E8%A3%85OpenCL%E8%BF%90%E8%A1%8C%E5%8F%8A%E7%BC%96%E8%AF%91%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<p>最近需要运行一个基于OpenCL开发的软件，服务器上的NVIDIA 1080Ti和Intel CPU都支持OpenCL，安装OpenCL之前可以安装一个clinfo的软件可以看到服务器上目前支持的OpenCL设备。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install clinfo</span><br></pre></td></tr></table></figure><p>一般安装NVIDIA的驱动的时候就会有选项选择是否安装OpenCL的驱动，若没有选择那个选项，clinfo是看不到有NVIDIA的cl设备的，接下来安装的几个软件一般也会将没有选择OpenCL的NVIDIA缺失的库作为依赖安装上，使得基于NVIDIA的cl设备能够正常使用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install ocl-icd-libopencl1</span><br><span class="line">sudo apt install opencl-headers</span><br></pre></td></tr></table></figure><p>若需要在服务器上编译或者调试OpenCL程序，还需要安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install ocl-icd-opencl-dev</span><br></pre></td></tr></table></figure><p>要使得CPU也支持运行OpenCL程序，需要去intel官网下载opencl-sdk，地址是:</p><p><a href="http://software.intel.com/en-us/vcsource/tools/opencl-sdk" target="_blank" rel="noopener">http://software.intel.com/en-us/vcsource/tools/opencl-sdk</a> </p><p>选择runtime版本进行下载，目前最新的适合ubuntu的地址是： </p><p><a href="http://registrationcenter-download.intel.com/akdlm/irc_nas/vcp/12526/opencl_runtime_16.1.2_x64_rh_6.4.0.37.tgz" target="_blank" rel="noopener">http://registrationcenter-download.intel.com/akdlm/irc_nas/vcp/12526/opencl_runtime_16.1.2_x64_rh_6.4.0.37.tgz</a> </p><p>适合CentOS的地址是： </p><p><a href="http://registrationcenter-download.intel.com/akdlm/irc_nas/vcp/13454/opencl_runtime_16.1.2_x64_rh_6.4.0.37.tgz" target="_blank" rel="noopener">http://registrationcenter-download.intel.com/akdlm/irc_nas/vcp/13454/opencl_runtime_16.1.2_x64_rh_6.4.0.37.tgz</a> </p><p>安装前需要先安装<code>lsb-core</code>，sdk依赖于这个库，版本必须大于4.0</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install lsb-core</span><br></pre></td></tr></table></figure><p>CentOS系统为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install redhat-lsb-core</span><br></pre></td></tr></table></figure><p>之后<code>sudo ./install</code>，检查操作系统版本时会提出ubuntu not support，这里可以忽略，这里说的只是不提供支持，而不是不能够使用，intel官方回复说对centos系统提供较好的支持，但ubuntu也是能使用的。</p><blockquote><p>1) The OpenCL™ implemenations themselves provided at the link are supported. Intel® CPU Runtime for OpenCL™ Applications on Ubuntu* OS is supported. This support is distinct from the 2017 SDK support.</p></blockquote><blockquote><p>2) The 2017 SDK is supported on CentOS<em>. It is expected compatible with Ubuntu</em> OS.</p></blockquote><blockquote><p>The semantic difference is that for supported there is an immediate paid path to get priority support and an intent to create service level agreements for CentOS* only. ‘supported’ is an overloaded word in the software industry… Hopefully the installer messaging will be more clear in the upcoming 2019 SDK.</p></blockquote><p>具体可以看 <a href="https://software.intel.com/en-us/forums/opencl/topic/785262" target="_blank" rel="noopener">https://software.intel.com/en-us/forums/opencl/topic/785262</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux初始化及挂载数据盘</title>
      <link href="/2018/12/12/linux/Linux%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%8A%E6%8C%82%E8%BD%BD%E6%95%B0%E6%8D%AE%E7%9B%98/"/>
      <url>/2018/12/12/linux/Linux%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%8A%E6%8C%82%E8%BD%BD%E6%95%B0%E6%8D%AE%E7%9B%98/</url>
      
        <content type="html"><![CDATA[<h2 id="磁盘分区形式"><a href="#磁盘分区形式" class="headerlink" title="磁盘分区形式"></a>磁盘分区形式</h2><p>常用的磁盘分区形式如下表所示，并且针对Linux操作系统，不同的磁盘分区形式需要选择不同的分区工具。</p><table><thead><tr><th>磁盘分区形式</th><th align="center">支持最大磁盘容量</th><th align="left">支持分区数量</th><th align="left">Linux分区工具</th></tr></thead><tbody><tr><td>主启动记录分区（MBR）</td><td align="center">2TB</td><td align="left"><li>4个主分区</li><li>3个主分区和1个扩展分区</li><br>说明：<br>MBR分区包含主分区和扩展分<br>区，其中扩展分区里面可以包<br>含若干个逻辑分区。以创建六<br>个分区为例，以下两种分区情<br>况供参考：<br><li>3个主分区，一个扩展分区，<br>其中扩展分区包含3个逻辑分<br>区。</li><li>1个主分区，1个扩展分区，<br>其中扩展分区中包含5个逻辑<br>分区。</li></td><td align="left">以下两种工具均可以使用：<br><li>fdisk工具</li><li>parted工具</li></td></tr><tr><td>全局分区表<br>(GPT, Guid Partition Table)</td><td align="center">18EB<br>(1EB=1048576TB)</td><td align="left">不限制分区数量<br>说明：<br>GPT格式下没有主分区、扩展分区以及逻辑分区之分</td><td align="left">parted工具</td></tr></tbody></table><blockquote><p>注意事项：<br>MBR格式分区最大支持的容量是2TB，如果硬盘的容量大于2TB，则必须选择GPT的分区形式，并且使用parted进行分区。当磁盘已经投入使用后，此时切换磁盘分区形式时，磁盘上的原有数据将会被清除，因此请在磁盘初始化时谨慎选择磁盘分区形式。</p></blockquote><h2 id="使用fdisk工具初始化磁盘（只支持小于2TB的硬盘）"><a href="#使用fdisk工具初始化磁盘（只支持小于2TB的硬盘）" class="headerlink" title="使用fdisk工具初始化磁盘（只支持小于2TB的硬盘）"></a>使用fdisk工具初始化磁盘（只支持小于2TB的硬盘）</h2><ol><li><p><code>fdisk -l</code>查看新增数据盘的信息，一般可以看到例如<code>/dev/sdb</code>这样的新增盘，主要依据是根据显示的信息中显示的硬盘大小以及是否有分区。<br> 一般会显示如下信息（以下信息为分区后的情况，若新硬盘会看到一个没有分区的磁盘）：</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">磁盘 /dev/sda：1000.2 GB, 1000204886016 字节，1953525168 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line">磁盘标签类型：dos</span><br><span class="line">磁盘标识符：0x000c5dbf</span><br><span class="line"></span><br><span class="line">   设备 Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1            2048   125001727    62499840   82  Linux swap / Solaris</span><br><span class="line">/dev/sda2   *   125001728  1953523711   914260992   83  Linux</span><br><span class="line"></span><br><span class="line">磁盘 /dev/sdb：6001.2 GB, 6001175126016 字节，11721045168 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line">磁盘标签类型：gpt</span><br><span class="line">Disk identifier: E9D9D767-8701-4230-BFAC-07F103EBB35A</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">\<span class="comment">#         Start          End    Size  Type            Name</span></span><br><span class="line"> 1         2048  11721043967    5.5T  Microsoft basic data</span><br></pre></td></tr></table></figure></li><li><p><code>fdisk 新增数据盘</code>，例如<code>fdisk /dev/sdb</code></p></li><li><p>输入n，按Enter开始新建分区，这里n代表new</p></li><li><p>接下来会让我们选择p还是e，p代表主要分区，e代表延伸分区，对于新增加的硬盘一般选择p</p></li><li><p>选择分区号，对于新增硬盘，一般选择1</p></li><li><p>选择初始磁柱编号，新增硬盘选择默认的2048即可</p></li><li><p>选择截止磁柱区域，选择默认的最大的磁柱区域即可，表示只建立一个分区，这个分区使用了硬盘的所有容量</p></li><li><p>输入p，可以看到我们已经新建好的硬盘分区为<code>/dev/sdb1</code></p></li><li><p>输入w，按Enter将分区结果写入分区表</p></li><li><p>执行<code>partprobe</code>将新的分区表变更同步至操作系统</p></li></ol><h2 id="使用parted工具初始化磁盘（可以支持大于2TB的硬盘）"><a href="#使用parted工具初始化磁盘（可以支持大于2TB的硬盘）" class="headerlink" title="使用parted工具初始化磁盘（可以支持大于2TB的硬盘）"></a>使用parted工具初始化磁盘（可以支持大于2TB的硬盘）</h2><ol><li><p><code>lsblk</code>查看新增数据盘信息，和上一个介绍的工具的<code>fdisk -l</code>的效果是一样的，可以看到例如<code>/dev/sdb</code>这样的新增盘，并且这种方式显示出来的结果更加直观一点，冗余的信息比较少。<br> 一般会显示如下信息（以下信息为分区后的情况，若新硬盘会看到一个没有分区的磁盘）：</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">NAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sda      8:16   0 931.5G  0 disk</span><br><span class="line">├─sda1   8:17   0  59.6G  0 part</span><br><span class="line">└─sda2   8:18   0 871.9G  0 part /</span><br><span class="line">sdb      8:0    0   5.5T  0 disk</span><br><span class="line">└─sdb1   8:1    0   5.5T  0 part /mnt/data</span><br></pre></td></tr></table></figure></li><li><p><code>parted 新增数据盘</code>，例如<code>parted /dev/sdb</code></p></li><li><p>输入p，按Enter查看当前磁盘的分区形式</p></li><li><p>输入以下命令，设置磁盘分区形式。<code>mklabel 磁盘分区形式</code>，这里磁盘分区形式可以选择GPT和MBR，当然，大于2TB的硬盘只能选择GPT</p></li><li><p>输入<code>unit s</code>，按Enter，设置磁盘的计量单位为磁柱</p></li><li><p>以为整个磁盘创建一个分区为例，输入<code>mkparted data 2048s 100%</code>，按Enter。这里data为分区名称，2048s表示初始磁柱位置，100%表示从初始磁柱位置开始，占用100%的磁盘容量进行新建分区</p></li><li><p>输入q，按Enter，退出parted</p></li></ol><h2 id="格式化数据盘及挂载数据盘"><a href="#格式化数据盘及挂载数据盘" class="headerlink" title="格式化数据盘及挂载数据盘"></a>格式化数据盘及挂载数据盘</h2><p>数据盘分区好之后是不能直接挂载的，会显示unknown filesystem，需要进行格式化指定一个磁盘文件格式，以ext4格式为例，使用如下指令进行格式化:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkfs -t ext4 /dev/sdb1</span><br></pre></td></tr></table></figure><p>之后便可以新建一个文件夹，例如<code>/mnt/data</code>将新硬盘挂载到该文件夹下，输入如下指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount /dev/sdb1 /mnt/data</span><br></pre></td></tr></table></figure><p>这样做只能即使生效，重启后需要重新输入指令进行挂载，十分不方便，可以将磁盘挂载写入到<code>/etc/fstab</code>文件当中，这样就可以省去每次开机挂载的繁琐操作。首先使用<code>blkid /dev/sdb1</code>来查看新增分区的UUID号是多少，复制UUID，编辑<code>/etc/fstab</code>文件，在末尾加入一行:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UUID=1851e23f-1c57-40ab-86bb-5fc5fc606ffa /mnt/data      ext4 defaults     0   2</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ansible教程之file模块的使用</title>
      <link href="/2018/11/13/ansible%E6%95%99%E7%A8%8B%E4%B9%8Bfile%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/2018/11/13/ansible%E6%95%99%E7%A8%8B%E4%B9%8Bfile%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p>ansible是一个自动化运维非常重要的工具，对于做大数据开发的人来说，ansible是一个管理集群的利器，我们可以用它来在集群中批量执行一些指令，而不需要对服务器一台一台进行操作。ansible的功能非常多，但是对于我来说一般只用来在集群中批量执行一些命令，例如批量安装软件、批量删除文件、批量新建文件夹等，具体详细的功能可以参考这个中文文档 <a href="http://www.ansible.com.cn/docs/" target="_blank" rel="noopener">ansible中文权威指南</a>。</p><h3 id="用ansible对集群中文件进行管理"><a href="#用ansible对集群中文件进行管理" class="headerlink" title="用ansible对集群中文件进行管理"></a>用ansible对集群中文件进行管理</h3><p>有时候我们可能需要在集群中批量删除某些文件，例如有时候spark slave节点上的work文件夹中的无用文件太多，又没有被自动清除，我们可以使用如下ansible指令来对文件夹中的文件进行批量删除：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible spark -m shell -a &quot;rm -rf /usr/local/spark/work/*&quot;</span><br></pre></td></tr></table></figure><p>这样做确实能正确将work文件夹中的内容都删除掉，但是会收到一个警告信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[WARNING]: Consider using the file module with state=absent rather than running rm.  If you need to use command because file is insufficient you can add warn=False to this command task or set command_warnings=False in ansible.cfg to get</span><br><span class="line">rid of this message.</span><br></pre></td></tr></table></figure><p>其实，这里<code>-m</code>后面接的参数就是使用的module，这里用了ansible的shell模块在每台机器上运行shell command进行删除操作，warning中也告诉了我们，ansible中有一个file模块可以用来做文件处理的操作。</p><h3 id="file模块"><a href="#file模块" class="headerlink" title="file模块"></a>file模块</h3><p>file模块的功能非常多，官方文档是这样描述的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sets attributes of files, symlinks, and directories, or removes files/symlinks/directories. Many other modules support the same options as the `file&apos; module - including [copy], [template], and [assemble].</span><br></pre></td></tr></table></figure><p>我们可以使用<code>ansible-doc file</code>来查看file模块的详细使用文档（精简版可以使用<code>ansible-doc -s file</code>），这里举几个常用的例子来介绍file模块的使用。</p><h4 id="file模块删除文件或目录"><a href="#file模块删除文件或目录" class="headerlink" title="file模块删除文件或目录"></a>file模块删除文件或目录</h4><p>正如前面所说的删除文件的方法，用file模块的使用方法是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ ansible spark -m file -a &quot;path=/usr/local/spark/work/* state=absent&quot;</span><br><span class="line">dell-r730-2 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false,</span><br><span class="line">    &quot;path&quot;: &quot;/usr/local/spark/work/*&quot;,</span><br><span class="line">    &quot;state&quot;: &quot;absent&quot;</span><br><span class="line">&#125;</span><br><span class="line">dell-r730-4 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false,</span><br><span class="line">    &quot;path&quot;: &quot;/usr/local/spark/work/*&quot;,</span><br><span class="line">    &quot;state&quot;: &quot;absent&quot;</span><br><span class="line">&#125;</span><br><span class="line">dell-r730-3 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false,</span><br><span class="line">    &quot;path&quot;: &quot;/usr/local/spark/work/*&quot;,</span><br><span class="line">    &quot;state&quot;: &quot;absent&quot;</span><br><span class="line">&#125;</span><br><span class="line">dell-r730-1 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false,</span><br><span class="line">    &quot;path&quot;: &quot;/usr/local/spark/work/*&quot;,</span><br><span class="line">    &quot;state&quot;: &quot;absent&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样就能达到将<code>/usr/local/spark/work</code>目录中的<code>app-xxx</code>目录删除的目的，这里<code>-m</code>参数后面指定了使用file模块，<code>-a</code>参数后面为模块的参数，指定了文件或目录的路径<code>path</code>，以及状态<code>state=absent</code>，表示将指定的path进行删除处理。</p><h4 id="file模块新建一个文件或目录"><a href="#file模块新建一个文件或目录" class="headerlink" title="file模块新建一个文件或目录"></a>file模块新建一个文件或目录</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible spark -m file -a &quot;path=/usr/local/spark/conf/slaves state=touch&quot;</span><br></pre></td></tr></table></figure><p>这里<code>state=touch</code>表示新建文件，而<code>state=directory</code>则表示新建目录。这里也可以是用<code>mode</code>来指定创建的文件或目录的权限<code>mode=&#39;u=rw,g=r,o=r&#39;</code>或者<code>mode=0755</code></p><h4 id="file模块递归设置文件的属主或属组"><a href="#file模块递归设置文件的属主或属组" class="headerlink" title="file模块递归设置文件的属主或属组"></a>file模块递归设置文件的属主或属组</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible spark -m file -a &quot;path=/usr/local/spark owner=spark group=spark recurse=yes&quot;</span><br></pre></td></tr></table></figure><p><code>owner</code>设置属主，<code>group</code>设置属组，<code>recurse</code>设置是否对目录进行递归进行设置。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac上制作Linux的U盘启动盘</title>
      <link href="/2018/10/31/Mac%E4%B8%8A%E5%88%B6%E4%BD%9CLinux%E7%9A%84U%E7%9B%98%E5%90%AF%E5%8A%A8%E7%9B%98/"/>
      <url>/2018/10/31/Mac%E4%B8%8A%E5%88%B6%E4%BD%9CLinux%E7%9A%84U%E7%9B%98%E5%90%AF%E5%8A%A8%E7%9B%98/</url>
      
        <content type="html"><![CDATA[<p>在windows上制作Linux的U盘启动盘非常容易，有很多工具，比如软碟通UltralISO、deepin深度启动盘制作工具等，只要正确使用这些工具就能很容易地制作一个U盘启动盘。</p><p>换了Mac电脑后，有时候要给服务器装Linux操作系统，还是找一台windows电脑来制作U盘启动盘，十分不方便。其实用Mac也能很容易地制作U盘启动盘，并且不需要借助什么工具，用dd命令就能完成U盘启动盘的制作。</p><h4 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h4><ol><li><p>插入U盘，使用diskutil指令来查看U盘的挂载点</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ diskutil list</span><br></pre></td></tr></table></figure><p> 系统输出类似如下的内容</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># joey @ joey-Mac in ~ [9:45:27]</span></span><br><span class="line">$ diskutil list</span><br><span class="line">/dev/disk0 (internal):</span><br><span class="line">   <span class="comment">#:                       TYPE NAME                    SIZE       IDENTIFIER</span></span><br><span class="line">   0:      GUID_partition_scheme                         24.0 GB    disk0</span><br><span class="line">   1:                        EFI EFI                     314.6 MB   disk0s1</span><br><span class="line">   2:                 Apple_APFS                         23.6 GB    disk0s2</span><br><span class="line"></span><br><span class="line">/dev/disk1 (internal, physical):</span><br><span class="line">   <span class="comment">#:                       TYPE NAME                    SIZE       IDENTIFIER</span></span><br><span class="line">   0:      GUID_partition_scheme                        *1.0 TB     disk1</span><br><span class="line">   1:                        EFI EFI                     209.7 MB   disk1s1</span><br><span class="line">   2:                 Apple_APFS Container disk2         900.7 GB   disk1s2</span><br><span class="line">   3:       Microsoft Basic Data BOOTCAMP                99.3 GB    disk1s3</span><br><span class="line"></span><br><span class="line">/dev/disk2 (synthesized):</span><br><span class="line">   <span class="comment">#:                       TYPE NAME                    SIZE       IDENTIFIER</span></span><br><span class="line">   0:      APFS Container Scheme -                      +900.7 GB   disk2</span><br><span class="line">                                 Physical Store disk1s2</span><br><span class="line">   1:                APFS Volume CoreStorage Fusion      576.8 GB   disk2s1</span><br><span class="line">   2:                APFS Volume Preboot                 44.0 MB    disk2s2</span><br><span class="line">   3:                APFS Volume Recovery                512.4 MB   disk2s3</span><br><span class="line">   4:                APFS Volume VM                      6.4 GB     disk2s4</span><br><span class="line"></span><br><span class="line">/dev/disk3 (external, physical):</span><br><span class="line">   <span class="comment">#:                       TYPE NAME                    SIZE       IDENTIFIER</span></span><br><span class="line">   0:     FDisk_partition_scheme                        *15.7 GB    disk3</span><br><span class="line">   1:               Windows_NTFS joey                    15.7 GB    disk3s1</span><br></pre></td></tr></table></figure><p> 可以看到，我的U盘大小是16GB，对应上面输出的挂载点应该是位于<code>/dev/disk3</code></p></li><li><p>在写入系统镜像前，首先需要umount这个U盘，使用如下指令</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ diskutil unmountDisk /dev/disk3</span><br></pre></td></tr></table></figure><p> 会输出如下内容表示正确unmount</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># joey @ joey-Mac in ~ [9:45:34]</span></span><br><span class="line">$ diskutil unmountDisk /dev/disk3</span><br><span class="line">Unmount of all volumes on disk3 was successful</span><br></pre></td></tr></table></figure><p> 此时，Mac的Finder中已经看不到之前挂载上的U盘了，但是使用<code>diskutil list</code>命令还是能够看到U盘的信息</p></li><li><p>使用dd指令写入Linux系统镜像到U盘 </p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo dd <span class="keyword">if</span>=/Users/joey/Downloads/CentOS-7-x86_64-DVD-1804.iso of=/dev/disk3 bs=1M</span><br></pre></td></tr></table></figure><p> 这里有一点需要注意，有些教程可能写的<code>bs=1m</code>，这里如果你的电脑装了GNU Coreutils，就是那个让<code>ls</code>能够彩色化输出的软件，这里用1m就会报错，报错内容为<code>dd: invalid number: ‘1m’</code>，这里把m大写就能很容易解决这个问题，但是究竟是什么原因造成1m不行的我也不是很清楚，只知道一个解决的办法。</p><p> 之后会输出如下，表示写入完成，大概要等几分钟</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># joey @ joey-Mac in ~ [9:49:37] C:1</span></span><br><span class="line">$ sudo dd <span class="keyword">if</span>=/Users/joey/Downloads/CentOS-7-x86_64-DVD-1804.iso of=/dev/disk3 bs=1M</span><br><span class="line">Password:</span><br><span class="line">4263+0 records <span class="keyword">in</span></span><br><span class="line">4263+0 records out</span><br><span class="line">4470079488 bytes (4.5 GB, 4.2 GiB) copied, 446.25 s, 10.0 MB/s</span><br></pre></td></tr></table></figure><p> 经过如上几个步骤，用Mac制作的U盘启动盘就制作完成了。</p></li></ol><h4 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h4><p>U盘制作启动盘之后U盘的可能无法被Mac系统读取了，会报一个错误，可见空间也会变的很小，这时候可以重新格式化U盘来进行恢复</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>sed中\1的用法</title>
      <link href="/2018/10/29/sed%E4%B8%AD%E5%8F%8D%E6%96%9C%E6%9D%A01%E7%9A%84%E7%94%A8%E6%B3%95/"/>
      <url>/2018/10/29/sed%E4%B8%AD%E5%8F%8D%E6%96%9C%E6%9D%A01%E7%9A%84%E7%94%A8%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>最近在看别人写的shell脚本时看到这样一个sed指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i.bak -e<span class="string">'s/\(LOBJS=.*\)/\1 bwtindex.o rle.o rope.o bwt.o is.o/g'</span> bwa/Makefile</span><br></pre></td></tr></table></figure><p>这里面使用了<code>sed &#39;s/要被取代的字符串/新的字符串/g&#39; file</code>的方式来对文本中指定的字符串进行全局替换，这里g代表的是global，之前面试又被问到过sed全局如何替换，当时就是忘记了最后应该要加<code>/g</code>，在这个命令中，新的字符串的内容中有一个<code>\1</code>之前从来没有遇到过，不知道具体的作用是什么，于是就去查找了一些资料进行学习。</p><p>在sed中，要被匹配的字符串可以用正则匹配来进行模式匹配，而用括号括起来的一个正则匹配串可以称为一个模式，而<code>\1-9</code>就是用来指代第一个、第二个、……、第九个模式在匹配到的字符串中的内容。在sed中一共可以记录9个模式，在某些需要保留原有字符串的一部分并添加一部分内容的时候就会很有用。</p><p>举个例子：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> abc123 | sed <span class="string">'s/\([a-z]*\)\([0-9]&#123;3&#125;\)/\2\1/g'</span></span><br></pre></td></tr></table></figure><p>这个例子的输出就是<code>123abc</code>，先来看下正则匹配的内容，一共有2个位于括号中的模式，第一个模式匹配的是出现次数任意多的小写字母，第二个模式匹配的是出现三次的数字，模式都用括号括起来，但是括号要使用反斜杠进行转义。在这个正则匹配中，<code>\1</code>代表的就是第一个模式匹配的内容，即abc,<code>\2</code>代表的是第二个模式匹配的内容，即123，然后替换成什么内容呢？就是交换这两个匹配的模式，把<code>\2</code>放到<code>\1</code>前面，就是123在前面，abc在后面，变成了123abc，就是这样简单，这是一个简单的交换匹配到的内容的例子，我们还可以在模式中插入内容，举例子来说：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> abc123 | sed <span class="string">'s/\([a-z]*\)\([0-9]&#123;3&#125;\)/\1xx\2/g'</span></span><br></pre></td></tr></table></figure><p>这个例子的输出就是在abc和123之间插入了两个字母xx，最终的结果是abcxx123，知道C当中的printf函数的同学可以把这里的<code>\1\2</code>理解成两个占位符，具体的内容由前面匹配到的模式的内容来进行填充，按照正则匹配中的顺序进行记录，最多记录9个。</p><p>这里在说一点题外话，<code>sed -i</code>我们知道是直接在原文件中进行修改，但是<code>-i</code>后面其实是可以加参数的，在最上面那个例子里面就是加了<code>.bak</code>作为<code>-i</code>的参数，这里的意思是，直接在原文件进行修改，但是将原文件保存为<code>filename.bak</code>，即在最后加上<code>.bak</code>进行备份。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gradle中添加C/C++代码编译打包流程</title>
      <link href="/2018/10/29/Gradle%E4%B8%AD%E6%B7%BB%E5%8A%A0C-C-%E4%BB%A3%E7%A0%81%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85%E6%B5%81%E7%A8%8B/"/>
      <url>/2018/10/29/Gradle%E4%B8%AD%E6%B7%BB%E5%8A%A0C-C-%E4%BB%A3%E7%A0%81%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>写过JNI代码的同学应该都有遇到过这样的问题，我们可以很方便的使用Maven、Gradle等工具将我们写好的Java代码打包成一个jar包进行发布，但是当我们的代码当中包含有C/C++的代码时，我们可能需要额外再去运行一次make指令去编译C/C++的代码，并将编译出的库和jar包一起发布（在大多数情况下so文件和jar包是分开的）。实际上，我们可以使用Gradle在打包的同时自动编译我们的C/C++代码，同时将so文件打包到jar包之中，这样在运行jar包时不需要指定<code>java.library.path</code>也能正确读取到so文件，并且发布时只有一个文件，更为方便。</p><h4 id="Exec-Task"><a href="#Exec-Task" class="headerlink" title="Exec Task"></a>Exec Task</h4><p>我们知道，Gradle的执行过程可以分为很多的Task进行，要实现Gradle自动编译C/C++代码我们需要首先了解一下Exec Task。Exec Task是用来执行一个命令行语句的，例如：</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">task</span> stopTomcat(type: Exec) &#123;</span><br><span class="line">workingDir <span class="string">'../tomcat/bin'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//on windows:</span></span><br><span class="line">commandLine <span class="string">'cmd'</span>, <span class="string">'/c'</span>, <span class="string">'stop.bat'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//on linux:</span></span><br><span class="line">commandLine <span class="string">'./stop.sh'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//store the output instead of printing to the console:</span></span><br><span class="line">standardOutput = <span class="keyword">new</span> ByteArrayOutputStream()</span><br><span class="line"></span><br><span class="line"><span class="comment">//extension method stopTomcat.output() can be used to obtain the output:</span></span><br><span class="line">ext.output = &#123;</span><br><span class="line"><span class="keyword">return</span> standardOutput.toString()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>具体有关这个Task的详细说明可以看这个：<a href="https://docs.gradle.org/current/dsl/org.gradle.api.tasks.Exec.html" target="_blank" rel="noopener">https://docs.gradle.org/current/dsl/org.gradle.api.tasks.Exec.html</a></p><h4 id="使用Exec-Task来编译C-C-代码"><a href="#使用Exec-Task来编译C-C-代码" class="headerlink" title="使用Exec Task来编译C/C++代码"></a>使用Exec Task来编译C/C++代码</h4><p>当然，Exec Task用来编译C/C++代码使用的是make指令，如果使用的是cmake，也可以先执行cmake再执行make，无非是多加几个Exec Task。这里具体的写法如下：</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">String cpath = <span class="string">"native"</span></span><br><span class="line">String libname = <span class="string">"libpairhmm"</span></span><br><span class="line"><span class="keyword">task</span> buildLib(type: Exec) &#123;</span><br><span class="line">workingDir <span class="string">"$cpath"</span></span><br><span class="line">outputs.files <span class="string">"$cpath/libpairhmm*"</span></span><br><span class="line">outputs.dir <span class="string">"$cpath/pairhmm"</span></span><br><span class="line">commandLine <span class="string">"make all"</span></span><br><span class="line">String home = System.properties.<span class="string">"java.home"</span></span><br><span class="line"><span class="comment">//strip the trailing jre</span></span><br><span class="line">String corrected = home.endsWith(<span class="string">"jre"</span>) ? home.substring(<span class="number">0</span>, home.length() - <span class="number">4</span>) : home</span><br><span class="line">environment JAVA_HOME : corrected</span><br><span class="line"><span class="keyword">doFirst</span> &#123; <span class="keyword">println</span> <span class="string">"using $home -&gt; $corrected as JAVA_HOME"</span> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">clean &#123;</span><br><span class="line"><span class="keyword">delete</span> <span class="string">"$cpath/pairhmm"</span></span><br><span class="line"><span class="keyword">delete</span> <span class="string">"$cpath/$libname*"</span></span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">fileTree</span>(<span class="string">"$cpath"</span>) &#123; <span class="keyword">include</span> <span class="string">"$libname*"</span>, <span class="string">"*.o"</span> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">processResources &#123;</span><br><span class="line">dependsOn buildLib</span><br><span class="line"><span class="keyword">from</span> cpath</span><br><span class="line"><span class="keyword">include</span> <span class="string">"$libname*"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里buildLib这个task就是一个Exec Task，其中定义的流程就是执行make all指令来编译C/C++代码，clean的作用就是清除编译产生的lib文件和o文件（在调用gradle clean的时候调用清除工作），processResources即处理资源文件，其作用就是将编译产生的库文件拷贝到jar包当中。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>远程调试Spark程序</title>
      <link href="/2018/10/26/spark/%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95Spark%E7%A8%8B%E5%BA%8F/"/>
      <url>/2018/10/26/spark/%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95Spark%E7%A8%8B%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<p>我们在写Spark程序的时候免不了要对我们的代码进行debug，在代码当中打上断点来查看程序执行过程中各个变量的变化情况。我一般使用Intellij IDEA来写Spark程序，可以直接在其中以local的方式运行Spark程序，也可以在其中打上断点进行调试，但这样做有一些问题：</p><ol><li>我们只能对Spark driver端的程序进行打断点debug；</li><li>Spark很多代码都是惰性执行的，很多代码都需要有action才能触发，在这之前打断点没有意义，真正的Task执行逻辑位于Executor当中；</li><li>对于某些运算量比较大或者内存消耗比较多的程序来说，本地电脑不能运行；</li><li>这样只能观察代码在local模式下运行的是否正确，无法对在集群中运行的代码进行调试。</li></ol><p>之前所说的几点问题我在之前一般采用比较低效率的方式来进行debug，即在代码当中加入一些log信息，利用log信息来调试代码，这样当Spark程序在集群中运行时，可以在web UI的Executor的stdout和stderr中查看我们留下的log信息。这样做可以解决一些问题，但是十分低效，debug的信息需要添加改动时都需要重新编译程序，并且打印log信息的方式并不能很完整地观察到所有变量的变化情况。但这样做确实解决了一些问题，比如我们可以对Executor真正执行Task逻辑的代码进行调试，也无需考虑惰性执行的过程，Spark的所有RDD的transform的行为都会反映到每个Executor执行的stdout和stderr信息当中；这些代码都可以在服务器集群当中运行进行调试，不用担心本地电脑性能不够的问题，本地电脑只需要打开浏览器查看Spark的web UI即可，或者使用终端来查看一些信息；可以在集群当中调试代码，不需要局限于local模式下。</p><p>但我始终认为这样的debug方式是低效的，并且不是一个正常的程序员应该有的debug方式，之前有想过肯定有具体的方法来解决这样的调试问题，Intellij IDEA当中功能非常多，肯定有这样的功能来解决这个问题。近期又要写一些Spark程序，并且输入数据非常大，计算量也很大，我在本地电脑上根本没办法debug，于是想到了去查找一些资料来解决远程调试Spark程序的问题。其实Intellij IDEA或者Eclipse这样的IED都会有remote debug这样的功能，以Intellij IDEA为例，在Run-Edit Configurations菜单中我们可以添加一个Remote的Configurations，这就是Intellij IDEA为我们提供的远程调试的功能。这里对Spark程序的调试主要分两种——Driver程序调试和Executor程序调试。</p><h4 id="Driver程序调试"><a href="#Driver程序调试" class="headerlink" title="Driver程序调试"></a>Driver程序调试</h4><p>Driver程序在远程进行调试时，需要在spark-submit的参数中增加一个配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--conf spark.driver.extraJavaOptions=-agentlib:jdwp=transport=dt_socket,server=y,<span class="built_in">suspend</span>=y,address=5005</span><br></pre></td></tr></table></figure><a id="more"></a><p>或</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--driver-java-options -agentlib:jdwp=transport=dt_socket,server=y,<span class="built_in">suspend</span>=y,address=5005</span><br></pre></td></tr></table></figure><p>我们队这个参数进行一些说明，首先spark.driver.exetraJavaOptions这个参数允许我们在Spark的driver程序在运行时传入一些额外的Java参数，<code>agentlib:jdwp</code>是Java Debug Wire Protocol选项，是一个远程调试的协议，后面紧跟的是以逗号进行分隔的子选项：</p><ul><li><code>transport</code>定义了远程Debugger及Debuggee之间数据传输协议，可以选择socket和shared memory的方式，一般情况下都是选择socket的方式，即选项的值选择dt_socket</li><li><code>server</code>运行Java程序的进程是否作为服务端与客户端(Debugger)进行通信，通常情况下远程调试都需要有一个服务端和一个客户端，若运行Java程序端为服务端，则调试端为客户端，在调试driver程序时，选择Java程序为服务端，监听远端Debugger的连接，因此值为y(yes)</li><li><code>suspend</code>是否暂停执行直至有客户端(Debugger)成功连接到服务端，调试driver程序时将这个值设置为y(yes)使得driver程序会在刚启动时就暂停住，指到有远端Debugger客户端连接上来才继续执行，确保远端Debugger能在程序开始执行时已经连接完毕</li><li><code>address</code>监听的端口，即服务端socket监听的端口，可以设置为任意可用的没有被占用的端口号，只要确保客户端能够通过这个端口与服务端进行连接即可</li></ul><p>进行了如上设置之后，在我们允许spark-submit指令之后，我们一般能够看到Spark程序暂停住了，并且会显示如下这样一句话：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Listening <span class="keyword">for</span> transport dt_socket at address: 5005</span><br></pre></td></tr></table></figure><p>这时候，我们的Spark程序已经做好准备在等待远程Debugger客户端连接了(一般称之为attach)，接下来就在Intellij IDEA中打开之前所说的那个菜单，点击“+”添加一个新的run/debug configuration，这里选择的是Remote类型，Debugger mode选择Attach to remote JVM，接下来填入Host和port并选择moudle classpath，之后使用这个配置点击debug按钮便可以进行远程调试了。</p><h4 id="Executor程序调试"><a href="#Executor程序调试" class="headerlink" title="Executor程序调试"></a>Executor程序调试</h4><p>一般来说，我们进行Spark程序调试最主要的就是要对Task当中的执行逻辑进行调试，因为Executor中执行的才是真正的并行任务，也是程序最主要的部分。对Executor进行调试时我们一般将允许Java进程的服务器作为客户端，将Debugger所在的机器作为服务端，也就是在调试机器上启动一个socket服务器对指定端口进行监听，而Executor上运行的程序作为客户端与之进行连接。为什么不采用之前的那种模式呢？因为我们需要保证Executor上的程序一开始执行就与Debugger进行了连接，若采用之前的模式，就需要将Executor进行暂停，而Executor暂停会使得driver程序误认为其出现了故障，会不断的重启Executor，无法正常进行调试。一般情况下要这样进行调试需要将Executor设置为只有一个，因为多个Executor同时连接Debugger的服务端会出现问题，若一定要进行集群调试，则在指定Worker启动的时候加入参数，而不是在spark-submit的时候加入参数，首先说下参数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--conf spark.executor.extraJavaOptions=-agentlib:jdwp=transport=dt_socket,server=n,address=10.0.0.171:5005,<span class="built_in">suspend</span>=n</span><br></pre></td></tr></table></figure><p>参数的具体意思不用多加说明，主要是address这里要写入具体的Debugger的地址以及端口号，如果要指定一个Worker上启动一个Executor来进行调试，可以在使用手动的方式启动该Worker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-class -agentlib:jdwp=transport=dt_socket,server=n,address=10.0.0.171:5005,<span class="built_in">suspend</span>=n org.apache.spark.deploy.worker.Worker spark://10.0.0.1:7077</span><br></pre></td></tr></table></figure><p>只要给该Worker分配一定的资源，确保在这个Worker上启动一个Executor即可。Intellij IDEA的设置上和之前的区别就是将Debugger mode改为Listen to remote JVM，然后首先需要启动Debugger的服务端，即先在Intellij IDEA当中点击debug开启服务，再运行Spark程序，这样远端的Spark Executor上运行的程序会自动进行连接，方便进行debug。这里需要注意的是，debug过程中不要让一行代码停留太长时间，否则driver会认为该Executor出现了故障，会不断进行重启Executor。</p><p>参考资料：</p><ul><li><a href="https://stackoverflow.com/questions/30403685/how-can-i-debug-spark-application-locally" target="_blank" rel="noopener">https://stackoverflow.com/questions/30403685/how-can-i-debug-spark-application-locally</a></li><li><a href="https://stackoverflow.com/questions/29090745/debugging-spark-applications" target="_blank" rel="noopener">https://stackoverflow.com/questions/29090745/debugging-spark-applications</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark运行原理</title>
      <link href="/2018/10/25/spark/spark%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/Spark%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86/"/>
      <url>/2018/10/25/spark/spark%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/Spark%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>spark的运行原理在大数据开发岗面试过程中是经常被问到的一个问题，我第一次被问到这个问题的时候有点摸不着头脑，这么大的一个问题我究竟应该怎样回答呢？是去描述一下spark的架构组成还是说一下底层的调用细节？后来查找了一些资料，看了一些书之后对这个问题有了一些理解，其实提这个问题的人可能最希望我们回答的是Spark运行的过程细节，简单来说就是把某个Spark程序从提交到执行完成中间经历了哪些步骤描述出来。如果在描述的过程中能够加入一些对Spark底层源码细节的解释会给提问者留下比较好的印象，认为你不仅仅是停留在使用Spark上，还对底层源码的原理有所了解。</p><h3 id="简单描述Spark的运行原理"><a href="#简单描述Spark的运行原理" class="headerlink" title="简单描述Spark的运行原理"></a>简单描述Spark的运行原理</h3><blockquote><p>用户使用spark-submit提交一个作业之后，会首先启动一个driver进程，driver进程会向集群管理器（standalone、YARN、Mesos）申请本次运行所需要的资源（这里的资源包括core和memory，可以在spark-submit的参数中进行设置），集群管理器会根据我们需要的参数在各个节点上启动executor。申请到对应资源之后，driver进程就会开始调度和执行我们编写的作业代码。作业会被提交给DAGScheduler，DAGScheduler会根据作业中RDD的依赖关系将作业拆分成多个stage，拆分的原则就是根据是否出现了宽依赖，每个stage当中都会尽可能多的包含连续的窄依赖。每个stage都包含了作业的一部分，会生成一个TaskSet提交给底层调度器TaskScheduler，TaskScheduler会把TaskSet提交到集群当中由executor进行执行。Task的划分是根据数据的partition进行划分，一个partition会划分为一个task。如此循环往复，直至执行完编写的driver程序的所有代码逻辑，并且计算完所有的数据。</p></blockquote><p>简单的运行流程如下图：</p><center><img style="border: none" src="https://user-gold-cdn.xitu.io/2018/9/30/16629a724b5034a3?w=1326&h=359&f=png&s=54756" width="60%" height="60%"><p>图一 spark运行流程</p></center><h3 id="SparkContext"><a href="#SparkContext" class="headerlink" title="SparkContext"></a>SparkContext</h3><p>Spark程序的整个运行过程都是围绕spark driver程序展开的，spark driver程序当中最重要的一个部分就是SparkContext，SparkContext的初始化是为了准备Spark应用程序的运行环境，SparkContext主要是负责与集群进行通信、向集群管理器申请资源、任务的分配和监控等。</p><p>driver与worker之间的架构如下图，driver负责向worker分发任务，worker将处理好的结果返回给driver。</p><center><img style="border: none" src="https://user-gold-cdn.xitu.io/2018/9/30/16629ab664dc9649?w=344&h=318&f=png&s=18157" width="20%"><p>图二 driver架构</p></center><p>SparkContext的核心作用是初始化Spark应用程序运行所需要的核心组件，包括高层调度器DAGScheduler、底层调度器TaskScheduler和调度器的通信终端SchedulerBackend，同时还会负责Spark程序向Master注册程序等。Spark应用当中的RDD是由SparkContext进行创建的，例如通过SparkContext.textFile()、SparkContext.parallel()等这些API。运行流程当中提及的向集群管理器Cluster Manager申请计算资源也是由SparkContext产生的对象来申请的。接下来我们从源码的角度学习一下SparkContext，关于SparkContext创建的各种组件，在SparkContext类中有这样一段代码来创建这些组件：</p><img style="border: none; margin-left: 0; margin-right: 0" src="https://user-gold-cdn.xitu.io/2018/10/25/166a8d2fbb706104?w=1246&h=220&f=png&s=63332" width="45%"><a id="more"></a>### DAGSchedulerDAGScheduler是一个高层调度器，能够将DAG的各个RDD划分到不同的Stage，并构建这些Stage之间的父子关系，最后将每个Stage根据partition划分为多个Task，并以TaskSet的形式提交给底层调度器TaskScheduler。Stage的划分按照的是RDD依赖关系中是否出现了宽依赖，宽依赖指的是父RDD中的一个partition被子RDD的多个partition所依赖，简单来说就是父RDD的partition的出度大于1，同理，窄依赖指的就是父RDD的一个partition只被子RDD的一个partition所依赖，也就是父RDD的partition的出度都是1。每个Stage当中都会尽可能包含多的窄依赖，将各个窄依赖的算子形成一整个pipeline进行运行，可以减少各个算子之间RDD的读写，不像MapReduce当中每个job只包含一个Map任务和一个Reduce任务，下一个Map任务都需要等待上一个Reduce任务全部都结束才能执行，pipeline形式的执行过程中没有产生shuffle，放在一起执行明显效率更高。Stage与Stage之间会出现shuffle，这里shuffle也是一个常常考察的点，另外的文章会详细说明。DAGScheduler还需要记录哪些RDD被存入磁盘等物化动作，同时要寻求Task的最优化调度，如在Stage内部数据的本地性等。DAGScheduler还需要监控因为shuffle跨节点输出可能导致的失败，如果发现这个Stage失败，可能就要重新提交该Stage。<h4 id="DAGScheduler具体调用过程"><a href="#DAGScheduler具体调用过程" class="headerlink" title="DAGScheduler具体调用过程"></a>DAGScheduler具体调用过程</h4><p>当一个job被提交时，DAGScheduler便会开始其工作，spark中job的提交是由RDD的action触发的，当发生action时，RDD中的action方法会调用其SparkContext的runJob方法，经过多次重载之后会调用到DAGScheduler的runJob方法。<br>DAGScheduler类当中runJob是提交job的入口函数，其中会调用submitJob方法返回一个JobWaiter来等待作业调度的结果，之后根据作业的成功或者失败打印相关的结果日志信息。</p><img style="border: none; margin-left: 0; margin-right: 0" src="https://user-gold-cdn.xitu.io/2018/10/25/166a8d18edda4035?w=1382&h=788&f=png&s=1863576&h=387&f=png&s=89774" width="50%"><img style="border: none; margin-left: 0; margin-right: 0" src="https://user-gold-cdn.xitu.io/2018/10/25/166a8d23c863f998?w=1424&h=1002&f=png&s=220504" width="50%"><p>submitJob方法会获取jobId以及校验partitions是否存在，并向eventProcessLoop发送了一个case class JobSubmitted对象，JobSubmitted对象封装了jobId、最后一个RDD，对RDD操作的函数，哪些partition需要被计算等内容。eventProcessLoop当中有一个eventThread线程，是一个deamon线程，用于接收通过post方法发送到该线程的JobSubmitted对象，放入其中的一个eventQueue阻塞队列进行处理，从eventQueue中take出来的event会调用onReceive方法（该方法由eventProcessLoop实现），onReceive方法中又会调用doOnReceive方法，按照不同的event类型进行不同的处理。<br>这里读源码的时候可能会有一个疑问，为何不直接在DAGScheduler调用submitJob的时候直接调用doOnReceive来处理job，为何要新启一个线程来进行处理，并且自己给自己发消息进行处理（eventProcessLoop是DAGScheduler内部的一个对象）。这里实际上是一个线程的异步通信方式，只是将消息以线程通信的方式post（这里的线程通信方式实际上是用了一个阻塞队列）给另一个线程，submitJob的方法能够立刻返回，不会阻塞在处理event的过程当中。这里我们不要浅显的认为DAGScheduler当中自己在给自己发消息，实际上还有别的组件会给DAGScheduler发消息，这种采用一个守护线程的方式进行消息处理可以将这两者统一起来，两者处理的逻辑都是一致的，扩展性非常好，使用消息循环器，就能统一处理所有的消息，保证处理的业务逻辑都是一致的。这里的eventProcessLoop实际上能够处理多种消息，不仅仅是JobSubmitted，源码当中能看到有如下多种event的处理：</p><blockquote><ol><li>JobSubmitted(jobId, rdd, func, partitions, callSite, listener, properties)</li><li>MapStageSubmitted(jobId, dependency, callSite, listener, properties)</li><li>StageCancelled(stageId, reason)</li><li>JobCancelled(jobId, reason)</li><li>JobGroupCancelled(groupId)</li><li>AllJobsCancelled</li><li>ExecutorAdded(execId, host)</li><li>ExecutorLost(execId, reason)</li><li>WorkerRemoved(workerId, host, message)</li><li>BeginEvent(task, taskInfo)</li><li>SpeculativeTaskSubmitted(task)</li><li>GettingResultEvent(taskInfo)</li><li>completion</li><li>TaskSetFailed(taskSet, reason, exception)</li><li>ResubmitFailedStages</li></ol></blockquote><p>JobSubmitted会去调用DAGScheduler中的handleJobSubmitted方法，该方法是构建Stage的开始阶段，会创建Stage中的最后一个Stage——ResultStage，而其他Stage为ShuffleMapStage。ResultStage的创建是由createResultStage这个函数完成的，其中的getOrCreateParentStage方法将会获取或创建一个给定RDD的父Stages列表，这个方法就是我们之前所说的具体划分Stage的方法，这个方法的源码很简单，如下：</p><img style="border: none; margin-left: 0; margin-right: 0" src="https://user-gold-cdn.xitu.io/2018/10/25/166a8d02e3c97db0?w=1364&h=172&f=png&s=40256" width="45%"><p>其中调用了一个函数getShuffleDependencies用来返回给定RDD的父节点中直接的shuffle依赖，其源码如下：</p><img style="border: none; margin-left: 0; margin-right: 0" src="https://user-gold-cdn.xitu.io/2018/10/25/166a8cf96b737078?w=1004&h=686&f=png&s=118575&s=61184" width="32%"><p>这里有三个主要的数据结构，为两个HashSet——parents和visited，还有一个Stack——waitingForVisit，代码中首先将传入的RDD加入用于进行栈式访问的waitingForVisit中，这里使用栈我们也可以看出这是一个深度优先搜索的策略，visited用于记录访问过的节点保证不会重复访问，接下来对访问的RDD的依赖进行区分，如果是shuffleDep（即宽依赖），就将依赖加入parents，如果是dependency（窄依赖），则将依赖的RDD加入waitingForVisit进行深度优先搜索遍历，这里最终将返回parents，产生的结果就是parents当中记录的都是shuffleDep，即两个Stage之间的依赖。之后根据得到的shuffle dependency来调用getOrCreateShuffleMapStage产生ShuffleMapStage，产生的ShuffleMapStage会存储在shuffleIdToMapStage这个HashMap当中，如果在该数据结构中已经存在创建过的ShuffleMapStage就直接返回，不存在则调用createShuffleMapStage进行创建，创建的时候会调用getMissingAncestorShuffleDependencies去搜索祖先shuffle dependency，先将依赖的Stage进行创建。<br>Stage创建完毕之后，handleJobSubmitted将会调用submitStage来提交finalStage，submitStage将会递归优先提交父Stage，父Stage是通过getMissingParentStages来获取的，并按照Stage的id进行排序，优先提交id小的Stage。</p><h4 id="具体例子说明"><a href="#具体例子说明" class="headerlink" title="具体例子说明"></a>具体例子说明</h4><p>如下图所示是5个RDD的转换图，假设RDD E最后出发了一个action（比如collect），接下来按照图中的关系仔细讲解一下DAGScheduler对Stage的生成过程。</p><center><img style="border: none; margin-left: 0; margin-right: 0" src="https://user-gold-cdn.xitu.io/2018/10/8/16651b2460a458ec?w=645&h=515&f=png&s=55464" width="32%"></center><ul><li>RDD.collect方法会出发SparkContext.runJob方法，之后调用到DAGScheduler.runJob方法，继而调用submitJob方法将这个事件封装成JobSubmitted事件进行处理，调用到handleJobSubmitted，在这个方法中会调用createResultStage。</li><li>createResultStage会基于jobId创建ResultStage（ResultStage中的rdd即是出发action的那个RDD，即finalRDD）。调用getOrCreateResultStages创建所有父Stage，返回parents: List[Stage]作为父Stage，将parents传入ResultStage，实例化生成ResultStage。在示意图中即是RDD E调用createResultStage，通过getOrCreateResultStages获取Stage1、Stage2，然后创建自己的Stage3。</li><li>getOrCreateParentStages方法中的getShuffleDependencies会获取RDD E的所有直接款依赖集合RDD B和RDD D，然后对这两个RDD分别调用getOrCreateShuffleMapStage，由于这两个RDD都没有父Stage，则getMissingAncestorShuffleDependencies会返回为空，会创建这两个ShuffleMapStage，最后再将这两个Stage作为Stage3的父Stage，创建Stage3。</li><li>之后会调用handleJobSubmitted中的submitStage来提交Stage，提交的时候采用从后往前回溯的方式，优先提交前面的Stage，并且按照Stage的id优先提交Stage的id小的，后面的Stage依赖于前面的Stage，只有前面的Stage计算完毕才会去计算后面的Stage。</li></ul><h3 id="SchedulerBackend和TaskScheduler"><a href="#SchedulerBackend和TaskScheduler" class="headerlink" title="SchedulerBackend和TaskScheduler"></a>SchedulerBackend和TaskScheduler</h3><p>之前讲到的TaskScheduler和SchedulerBackend都只是一个trait，TaskScheduler的具体实现类是TaskSchedulerImpl，而SchedulerBackend的子类包括有：</p><blockquote><ol><li>LocalSchedulerBackend</li><li>StandaloneSchedulerBackend</li><li>CoarseGrainedSchedulerBackend</li><li>MesosCoarseGrainedSchedulerBackend</li><li>YarnSchedulerBackend</li></ol></blockquote><p>不同的SchedulerBackend对应不同的Spark运行模式。传给createTaskScheduler不同的master参数就会输出不同的SchedulerBackend，在这里spark实际上是根据master传入的字符串进行正则匹配来生成不同的SchedulerBackend。这里采用了设计模式当中的策略模式，根据不同的需要来创建不同的SchedulerBackend的子类，如果使用的是本地模式，就会创建LocalSchedulerBackend，而standalone集群模式则会创建StandaloneSchedulerBackend。StandaloneSchedulerBackend中有一个重要的方法start，首先会调用其父类的start方法，之后定义了一个Command对象command，其中有个对象成员mainClass为org.apache.spark.executor.CoarseGrainedExecutorBackend，这个类非常重要，我们在运行spark应用时会在worker节点上看到名称为CoarseGrainedExecutorBackend的JVM进程，这里的进程就可以理解为executor进程，master发指令给worker去启动executor所有的进程时加载的Main方法所在的入口类就是这个CoarseGrainedExecutorBackend，在CoarseGrainedExecutorBackend中启动executor，executor通过构建线程池来并发地执行task，然后再调用它的run方法。在start方法中还会创建一个十分重要的对象StandaloneAppClient，会调用它的start方法，在该方法中会创建一个ClientEndpoint对象，这是一个RpcEndPoint，会向Master注册。</p><p>SchedulerBackend实际上是由TaskScheduler来进行管理的，createTaskScheduler方法中都会调用TaskScheduler的initialize方法将SchedulerBackend作为参数输入，绑定两者的关系。</p><img style="border: none; margin-left: 0; margin-right: 0" src="https://user-gold-cdn.xitu.io/2018/10/25/166a8ce68002717f?w=1394&h=514&f=png&s=124060" width="50%"><p>initialize方法当中还会创建一个Pool来初始定义资源的分布模式Scheduling Mode，默认是先进先出（FIFO）模式，还有一种支持的模式是公平（FAIR）模式。FIFO模式指的是任务谁先提交谁就先执行，后面的任务需要等待前面的任务执行，FAIR模式支持在调度池中为任务进行分组，不同的调度池权重不同，任务可以按照权重来决定执行的先后顺序。</p><p>TaskScheduler的核心任务是提交TaskSet到集群运算运算并汇报结果。我们知道，之前所讲的DAGScheduler会将任务划分成一系列的Stage，而每个Stage当中会封装一个TaskSet，这些TaskSet会按照先后顺序提交给底层调度器TaskScheduler进行执行。TaskScheduler接收的TaskSet是DAGScheduler中的submitMissingTasks方法传递过来的，具体调用的函数为TaskScheduler.submitTasks，TaskScheduler会为每一个TaskSet初始化一个TaskSetManager对其生命周期进行管理，当TaskScheduler得到Worker节点上的Executor计算资源的时候，TaskSetManager便会发送具体的Task到Executor上进行执行。如果Task执行的过程中出现失败的情况，TaskSetManager也会负责进行处理，会通知DAGScheduler结束当前的Task，并将失败的Task再次添加到待执行队列当中进行后续的再次计算，重试次数默认为4次，处理该逻辑的方法为TaskSetManager.handleFailedTask。Task执行完毕，TaskSetManager会将结果反馈给DAGScheduler进行后续处理。</p><p>TaskScheduler的具体实现类为TaskSchedulerImpl，其中有一个方法为submitTasks非常重要，该方法源码如下所示：</p><img style="border: none; margin-left: 0; margin-right: 0" src="https://user-gold-cdn.xitu.io/2018/10/25/166a8cc8d4837aa6?w=1456&h=1204&f=png&s=272129" width="50%"><p>该方法中会创建TaskSetManager，并通过一个HashMap将stage的id和TaskSetManager进行对应管理。之后会调用SchedulableBuilder的addTaskSetManager方法将创建的TaskSetManager加入其中，SchedulableBuilder会确定TaskSetManager的调度顺序并确定每个Task具体运行在哪个ExecutorBackend中。submitTasks方法的最后会调用backend.reviveOffer，该backend具体类型一般为CoarseGrainedSchedulerBackend，是SchedulerBackend的一个子类，其reviveOffers方法中调用的是driverEndPoint.send方法，这个方法会给DriverEndPoint发送ReviveOffers消息，会触发底层资源调度，即进行TaskSet所需要资源的分配。 driverEndPoint的receive方法匹配到ReceiveOffers消息，就调用makeOffers方法，该方法如下所示：</p><img style="border: none; margin-left: 0; margin-right: 0" src="https://user-gold-cdn.xitu.io/2018/10/25/166a8d66c824cdd7?w=1286&h=524&f=png&s=113549" width="50%"><p>该方法会获取活动的Executor，根据activeExecutor生成所有可用于计算的workOffers，workOffers在创建时会传入Executor的id，host和可用的core等信息，可用的内存信息在其他地方已经获取。makeOffers方法中还调用了scheduler的resourceOffers方法，这个方法便是给用于计算的workOffers提供资源，均匀的将任务分发给每个workOffer(Executor)进行计算。在这里我曾经有一个疑问，就是任务是不是按顺序发给每个Executor进行计算的，即假设有100个Task，5个Executor，分发任务的时候是不是总是按照0号Executor、1号Executor、2号Executor……这样的顺序进行分发的，也就是0号Executor总是拿到id为TaskId % 5的任务，1号Executor总是拿到id为TaskId % 5 + 1的任务。但阅读源码发现，其中有一个环节是进行shuffle操作，调用的是Random.shuffle(offers)，即把workOffers(Executors)在Seq中的顺序进行洗牌，避免总是把任务放在同一组worker节点，这一点我们在后续的resourceOfferSingleTaskSet方法中可以很清楚的看到任务具体分发的过程其实就是按照workerOffers在Seq中的顺序进行的，在源码中就是对workerOffers的一个简单的for遍历进行读取可用的core资源并将可用的资源分发给TaskSetManager用于对应的TaskSet的计算：</p><img style="border: none; margin-left: 0; margin-right: 0" src="https://user-gold-cdn.xitu.io/2018/10/25/166a9030d75e7bad?w=1614&h=1202&f=png&s=269378" width="60%"><p>源码中按照shuffledOffers的索引进行顺序遍历，因为之前已经进行过shuffle操作，workerOffer的顺序每次都是打乱的，所以在这里分配任务时不会总是按照一定的顺序给workerOffer分配对应id号的Task，而是会以随机乱序的方式给workerOffer分配Task，但是任务的分配还会考虑任务的本地性，在分配任务时会将对应的Executor资源输入给TaskSetManager的resourceOffer方法，该方法会返回需要计算的Task的TaskDescription，这里很重要的一个依据就是尽量给Executor分配计算本地性高的任务。数据的本地优先级从高到低依次为：PROCESS_LOCAL、NODE_LOCAL、NO_PREF、RACK_LOCAL、ANY，因此对于一些任务，其数据一直处于某个节点上，因而该任务也会一直分配给该节点上的Executor进行计算，之前对workerOffer进行打乱分配的效果可能看起来就不是特别明显了，会发现一些任务一直处于某些节点上进行计算。DAGScheduler也会有本地性的考虑，但是DAGScheduler是从数据的层面进行考虑的，从RDD的层面确定就可以，而TaskScheduler是从具体计算的角度考虑计算的本地性，是更具体的底层调度，满足数据本地性和计算本地性。</p><p>在resourceOfferSingleTaskSet方法中我们看到有一个变量CPUS_PER_TASK，之前我一直理解的是一个Task是由一个cpu core进行执行的，但是这个变量实际上来源于配置参数spark.task.cpus，当我们将这个参数设置为2时一个Task会被分配到2个core，从Stack Overflow当中了解到这个参数的设置实际上是为了满足一些特殊的Task的需求，有些Task内部可能会出现多线程的情况，或者启动额外的线程进行其他交互操作，这样设置能够确保对core资源的总需求在按照设置的情况运行时不会超过一定的设置值（但这里并没有强制要求，如果Task启动的线程数大于设置的spark.task.cpus也不会有问题，但可能会因为超过一定的值造成资源抢占，影响效率）。</p><p>进行资源分配的taskSet实际上是有一定的顺序的，在TaskSchedulerImpl.resourceOffers方法中调用了rootPool.getSortedTaskSetQueue获取按照一定规则排序后的taskSet进行遍历处理，这里的规则就是之前所说的FIFO或FAIR，指的是属于一个Stage的TaskSet的计算的优先级。resourceOffers函数一开始也会对每一个活着的slave进行标记，记录其主机名并跟踪是否增加了新的Executor，这里可能的情况是有一些Executor挂掉了重新启动了新的，需要在有新的TaskSet计算请求时加入到计算资源信息记录当中。</p><p>任务的资源分配好之后，会获得Task的TaskDescription，接下来CoarseGrainedSchedulerBackend调用launchTasks方法把任务发送给对应的ExecutorBackend进行执行。</p><img style="border: none; margin-left: 0; margin-right: 0" src="https://user-gold-cdn.xitu.io/2018/10/25/166aa25cf98aad30?w=1684&h=962&f=png&s=238746" width="60%"><p>如果任务序列化之后大小超过了maxRpcMessageSize(默认128M)会丢弃，否则根据TaskDescription中记录的执行该Task的executorId获取executorData，将其中的freeCores减去运行任务需要的core数，并使用executorEndPoint的send方法发送LaunchTask给指定的Executor的ExecutorBackend进行执行，LaunchTask是一个case class，其中存储的内容就是序列化的Task。</p><p>参考文献：</p><ul><li>Spark大数据商业实战三部曲/王家林，段智华，夏阳编著. 北京:清华大学出版社，2018</li><li><a href="https://stackoverflow.com/questions/36671832/number-of-cpus-per-task-in-spark" target="_blank" rel="noopener">https://stackoverflow.com/questions/36671832/number-of-cpus-per-task-in-spark</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Spark源码阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gradle中使用proguard</title>
      <link href="/2018/05/23/java/Gradle%E4%B8%AD%E4%BD%BF%E7%94%A8proguard/"/>
      <url>/2018/05/23/java/Gradle%E4%B8%AD%E4%BD%BF%E7%94%A8proguard/</url>
      
        <content type="html"><![CDATA[<p>最近做了一个Java项目，老板让我们将核心部分的代码进行混淆，防止jar包被反编译出来。Java项目是基于Gradle进行构建的，使用了shadowJar这个插件将源码生成的jar包和所有的依赖的jar包打包到一起，称为一个fat-jar。我之前单独使用过proguard的gui，也使用过maven的proguard plugin以及sbt的plugin，都踩了很多坑最终混淆成功了，以为这次应该很轻松能完成任务，但事实上我遇到了很多之前没有遇到过的问题，现在将我解决这个问题的每个阶段记录下来。</p><h4 id="阶段一"><a href="#阶段一" class="headerlink" title="阶段一"></a>阶段一</h4><p>下载了最新的proguard6.0.3，执行proguardgui.sh，图形界面出来之后，写好一个配置文件并load进去，配置文件中将包含依赖的fat-jar作为输入，libraryjars只添加了<code>jre/lib/rt.jar</code>，因为其他库文件都包含在了fat-jar包当中，这样混淆有一个问题就是会去混淆依赖的库，虽然可以通过<code>keep class</code>来保持依赖的库不被混淆，但是proguard还是会去遍历所有的依赖库中的内容，导致混淆的时间非常长。这对于我来说是不能接受的，我现在都还不知道我写的混淆配置文件能不能让混淆后的jar包正常运行，如果测试一次要花这么长时间，肯定是不能按时完成任务的，而且整个调试的过程会非常痛苦。我看了一下jar包有200M左右，但实际上我们源码对应的jar包只有5M左右，其他的内容都是依赖的库，实际上我是不需要去混淆这些依赖，proguard花费时间去遍历这些依赖是没有意义的。</p><h4 id="阶段二"><a href="#阶段二" class="headerlink" title="阶段二"></a>阶段二</h4><p>我先不用shadowJar进行打包，只使用jar任务编译出一个不包含依赖的jar包，只对这个不包含依赖的jar包进行混淆，把其依赖的库通过proguard配置文件中的<code>-libraryjars</code>参数添加进去（不添加进去会出现找不到依赖的库的问题）。这样proguard就只会混淆我们所写的代码，不会涉及到依赖的库，代码很快就混淆完了。混淆后的库文件中包含有<code>MAINIFEST.MF</code>文件，<code>Class-Path</code>中记录了所依赖的库文件的路径，使得独立的jar包也能正常运行。我写的混淆配置文件混淆的力度并不是很大，我以为程序能够正常运行，但是却并没有如我所愿。</p><h4 id="阶段三"><a href="#阶段三" class="headerlink" title="阶段三"></a>阶段三</h4><p>独立混淆的jar包在混淆环节并没有出错，但是执行的时候却遇到了一个很奇怪的问题，我追踪代码发现在某一个地方使用了<code>ClassLoader.getResource(packageName)</code>方法去获取在packageName包下的所有资源，这个方法在jar包没有混淆之前是能正确找到packageName下的所有资源，但是混淆之后这个方法就什么都获取不到了。为了探究原因，我关闭了proguard的所有功能，包括optimize、obfuscate、shrink，相当于不对输入的jar包做任何处理，最后输出的jar包还是会有这个问题。同时，我把混淆前的jar包和不开启proguard任何功能输出的jar包使用JAPICC进行比较，发现里面的内容是完全一致的。查找资料发现proguard会对jar包进行优化，以期减少其大小。默认情况下，proguard会删除jar中的目录元素，导致ClassLoader().getResource（）方法找不到对应的资源，只需要在使用时加上<code>-keepdirectories</code>选项即可。附上官方文档的说明：</p><blockquote><p><strong>-keepdirectories</strong> [_directory_filter_]<br>Specifies the directories to be kept in the output jars (or aars, wars, ears, zips, apks, or directories). By default, directory entries are removed. This reduces the jar size, but it may break your program if the code tries to find them with constructs like “com.example.MyClass.class.getResource(“”)”. You’ll then want to keep the directory corresponding to the package, “-keepdirectories com.example”. If the option is specified without a filter, all directories are kept. With a filter, only matching directories are kept. For instance, “-keepdirectories mydirectory” matches the specified directory, “-keepdirectories mydirectory/*” matches its immediate subdirectories, and “-keepdirectories mydirectory/**” matches all of its subdirectories.</p></blockquote><h4 id="阶段四"><a href="#阶段四" class="headerlink" title="阶段四"></a>阶段四</h4><p>最后的要求还是需要将源码和依赖的库打包到一起，需要在shadowJar打包之前先将源码产生的jar包进行混淆，shadowJar任务的输入改成这个混淆后的jar包即可。proguard实际上也能作为gradle的一个插件进行使用，可以在<code>build.gradle</code>当中加入一个proguard的task进行混淆，proguard官网提供了一种使用方法：</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">buildscript &#123;</span><br><span class="line">  repositories &#123;</span><br><span class="line">    flatDir <span class="string">dirs:</span> <span class="string">'/usr/local/java/proguard/lib'</span></span><br><span class="line">  &#125;</span><br><span class="line">  dependencies &#123;</span><br><span class="line">    classpath <span class="string">':proguard:'</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义task的方式如下：</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">task myProguardTask(<span class="string">type:</span> proguard.gradle.ProGuardTask) &#123;</span><br><span class="line">  .....</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但这样需要自己手动下载proguard，并存放在编译gradle的服务器上，十分不方便。还有一种方式比较方便，每次会自动下载需要的jar包：</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">buildscript &#123;</span><br><span class="line">  repositories &#123;</span><br><span class="line">    mavenCentral()</span><br><span class="line">    jcenter() <span class="comment">// for shadow plugin</span></span><br><span class="line">  &#125;</span><br><span class="line">  dependencies &#123;</span><br><span class="line">    classpath <span class="string">'net.sf.proguard:proguard-gradle:6.0.3'</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我所定义的proguard的混淆任务如下：</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">task obfuscate(<span class="string">type:</span> proguard.gradle.ProGuardTask) &#123;</span><br><span class="line">  injars jar</span><br><span class="line">  outjars <span class="string">"$buildDir/libs/$&#123;project.name&#125;-pg.jar"</span></span><br><span class="line">  libraryjars <span class="string">"$&#123;System.getProperty('java.home')&#125;/lib/rt.jar"</span></span><br><span class="line">  libraryjars files(configurations.compile.collect())</span><br><span class="line"></span><br><span class="line">  useuniqueclassmembernames</span><br><span class="line"></span><br><span class="line">  dontshrink</span><br><span class="line">  dontoptimize</span><br><span class="line">  dontnote</span><br><span class="line">  dontwarn</span><br><span class="line"></span><br><span class="line">  <span class="comment">//keepnames 'class ** &#123; *; &#125;'</span></span><br><span class="line">  configuration <span class="string">'proguard.pro'</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里<code>injars</code>直接写jar即可，会得到jar任务的输出（即源码编译产生的jar），<code>outjars</code>输出到<code>build/libs</code>路径下，<code>rt.jar</code>也许要添加，jre的路径可以使用<code>${System.getProperty(&#39;java.home&#39;)}</code>获得。另外，依赖的所有库可以通过一种很简洁的方式表述出来，不需要一个依赖一个依赖的添加，<code>libraryjars files(configurations.compile.collect())</code>，这句话会把compile环节所依赖的所有库文件的获取到，并添加到libraryjar当中。proguard的配置参数可以直接在gradle的task中写，一般来说是将普通的proguard参数去掉前面的-，参数的值需要写到一个字符串当中，遇到配置字符串需要换行的配置情况需要在最后加上一个\。<br>同时，还需要将混淆产生的jar包作为shadowJar任务的输入才能将这个混淆的jar包和依赖打包到一起，具体写法如下：</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">task myShadow(<span class="string">type:</span> ShadowJar) &#123;</span><br><span class="line">  baseName = jar.baseName</span><br><span class="line">  from obfuscate</span><br><span class="line">  configurations = [project.configurations.runtime]</span><br><span class="line">  classifier = <span class="string">'shadow'</span></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>from指明了需要打包的jar的来源，这里指定obfuscate就是之前写的obfuscate任务的输出，configurations指定了配置文件，指定之后会根据这个配置文件找到所有的依赖库文件，这里指定的是打包compile环节依赖的库文件，并且<code>[project.configurations.runtime]</code>实际上是default <code>shadowJar</code> task的默认配置。</p><p>这里有一个坑需要注意，如果你使用了默认的shadowJar任务（shadowJar），最后生成的fat-jar会包含有依赖库、没混淆的代码、混淆的代码三部分，正如Stack Overflow上这个问题所描述的一样：<a href="https://stackoverflow.com/questions/43643609/gradle-shadowjar-output-contains-obfuscated-and-non-obfuscated-classes?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa" target="_blank" rel="noopener">https://stackoverflow.com/questions/43643609/gradle-shadowjar-output-contains-obfuscated-and-non-obfuscated-classes?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa</a><br>这里产生这种情况的原因是，默认的shadowJar任务总会将main文件夹中的源文件添加到输入当中，要解决这个问题就是自己定义一个type为shadowJar的task，不要去使用默认的shadowJar任务，其实这个问题在shadowJar官方说明文档当中也写到了：</p><blockquote><p>The built in shadowJar task only provides an output for the main source set of the project. It is possible to add arbitrary ShadowJar tasks to a project. When doing so, ensure that the configurations property is specified to inform Shadow which dependencies to merge into the output.</p></blockquote><p>官方提供了一个例子可以将test中的源文件与testRuntime中依赖的库文件进行打包的方法，也说到了默认的shadowJar任务只能将main中的源文件进行打包，也提示了我们如果要用proguard混淆之后的jar作为输入需要自己定义shadowJar任务，不能使用默认的shadowJar任务。</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">task testJar(<span class="string">type:</span> ShadowJar) &#123;</span><br><span class="line">  classifier = <span class="string">'tests'</span></span><br><span class="line">  from sourceSets.test.output</span><br><span class="line">  configurations = [project.configurations.testRuntime]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://www.guardsquare.com/en/proguard/manual/usage" target="_blank" rel="noopener">https://www.guardsquare.com/en/proguard/manual/usage</a></li><li><a href="https://www.oschina.net/question/237480_166440" target="_blank" rel="noopener">https://www.oschina.net/question/237480_166440</a></li><li><a href="https://stackoverflow.com/questions/43643609/gradle-shadowjar-output-contains-obfuscated-and-non-obfuscated-classes?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa" target="_blank" rel="noopener">https://stackoverflow.com/questions/43643609/gradle-shadowjar-output-contains-obfuscated-and-non-obfuscated-classes?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa</a></li><li><a href="http://imperceptiblethoughts.com/shadow/" target="_blank" rel="noopener">http://imperceptiblethoughts.com/shadow/</a></li><li><a href="https://www.huangyunkun.com/2013/12/23/gradle_with_proguard/" target="_blank" rel="noopener">https://www.huangyunkun.com/2013/12/23/gradle_with_proguard/</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Javai </tag>
            
            <tag> 技术 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS安装高版本gcc</title>
      <link href="/2018/04/16/linux/CentOS%E5%AE%89%E8%A3%85%E9%AB%98%E7%89%88%E6%9C%ACgcc/"/>
      <url>/2018/04/16/linux/CentOS%E5%AE%89%E8%A3%85%E9%AB%98%E7%89%88%E6%9C%ACgcc/</url>
      
        <content type="html"><![CDATA[<p>最近需要在CentOS 7.2上安装matlab，发现matlabR2017b Linux版本安装需要gcc 4.9.x，但是CentOS 7.2 使用yum安装的gcc版本最高为4.8.5，于是决定将gcc版本进行升级。升级gcc一般建议采用编译安装的方式，但是这种方式比较麻烦，需要先编译安装mpfr、gmp、mpc等，于是在网上找到了一种通过yum比较方便的升级方式，而且可以随时在bash、zsh等当中切换各种gcc版本，特记录在此。</p><h2 id="gcc-4-9安装"><a href="#gcc-4-9安装" class="headerlink" title="gcc 4.9安装"></a>gcc 4.9安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install centos-release-scl</span><br><span class="line">sudo yum install devtoolset-3-toolchain</span><br><span class="line">scl <span class="built_in">enable</span> devtoolset-3 bash</span><br></pre></td></tr></table></figure><p>这里scl enable就是用来切换不同版本的gcc的。这个切换是临时的，表示在bash中临时切换到gcc4.9的工作环境，当使用<code>exit</code>指令之后，就会回退到原始的gcc版本，可以使用<code>scl -l</code>来查看所有可以切换的开发工具集。</p><h2 id="gcc-5-2"><a href="#gcc-5-2" class="headerlink" title="gcc 5.2"></a>gcc 5.2</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install centos-release-scl</span><br><span class="line">sudo yum install devtoolset-4-toolchain</span><br><span class="line">scl <span class="built_in">enable</span> devtoolset-4 bash</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark源码分析RDD缓存过程</title>
      <link href="/2018/04/05/spark/spark%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/Spark%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90RDD%E7%BC%93%E5%AD%98%E8%BF%87%E7%A8%8B/"/>
      <url>/2018/04/05/spark/spark%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/Spark%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90RDD%E7%BC%93%E5%AD%98%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>Spark提供了一种将RDD持久化的方式(cache、persist)，这种方式适用于需要多次执行action操作的RDD，因为持久化之后的RDD中的内容不需要重新计算，可以直接使用，对于多次执行action的RDD来说，这样做能省下许多重复计算的时间。Task在启动之初读取一个分区的时候，会先判断这个分区是否已经被持久化，如果没有则会再去检查是否存在Checkpoint，还没有找到的话会根据血统重新计算。RDD的缓存是一种特殊的持久化操作，即<code>RDD.cache()</code>等同于<code>RDD.persist(MEMORY_ONLY)</code>即缓存是一种只将RDD持久化到内存当中的方式。本文基于Spark 2.1版本的源码对RDD的缓存过程进行了分析，文章中涉及到的源码文件主要有以下几个：</p><ul><li><a href="https://github.com/apache/spark/blob/branch-2.1/core/src/main/scala/org/apache/spark/storage/memory/MemoryStore.scala" target="_blank" rel="noopener"><code>spark/core/src/main/scala/org/apache/spark/storage/memory/MemoryStorage.scala</code></a></li><li><a href="https://github.com/apache/spark/blob/branch-2.1/core/src/main/scala/org/apache/spark/memory/StorageMemoryPool.scala" target="_blank" rel="noopener"><code>spark/core/src/main/scala/org/apache/spark/memory/StorageMemoryPool.scala</code></a></li><li><a href="https://github.com/apache/spark/blob/branch-2.1/core/src/main/scala/org/apache/spark/util/collection/SizeTrackingVector.scala" target="_blank" rel="noopener"><code>spark/core/src/main/scala/org/apache/spark/util/collection/SizeTrackingVector.scala</code></a></li><li><a href="https://github.com/apache/spark/blob/branch-2.1/core/src/main/scala/org/apache/spark/util/collection/SizeTracker.scala" target="_blank" rel="noopener"><code>spark/core/src/main/scala/org/apache/spark/util/collection/SizeTracker.scala</code></a></li></ul><h2 id="RDD缓存分析"><a href="#RDD缓存分析" class="headerlink" title="RDD缓存分析"></a>RDD缓存分析</h2><p>RDD在缓存到内存之前，Partition中的数据一般以迭代器(Iterator)的数据结构来访问，通过Iterator可以获得分区中每一条序列化或者非序列化的Record，这些Record在访问的时候占用的是JVM堆内存中other部分的内存区域，同一个Partition的不同Record的空间并不是连续的。RDD被缓存之后，会由Partition转化为Block，并且存储位置变为了Storage Memory区域，并且此时Block中的Record所占用的内存空间是连续的。我们可以在Spark的源码当中多次看到unroll这个词，字面意思是展开，在Spark当中的意义就是将存储在Partition中的Record由不连续的存储空间转换为连续存储空间的过程。Unroll操作的时候需要在Storage Memory当中通过<code>reserveUnrollMemoryForThisTask</code>来申请Unroll操作所需要的内存，使用完毕之后，又通过<code>releaseUnrollMemoryForThisTask</code>方法来释放这部分内存。这与1.6.0版本之前固定Unroll内存的方式不同，是动态申请的，因为这部分内存只在Unroll的时候有用，动态申请这块内存能够在不需要Unroll的时候将这块内存区域用于其他的用途上，提升内存资源的利用率。Block有两种存储方式，分别为序列化存储和非序列化存储，这两种存储方式具有其对应的Entry，在MemoryStore类中通过一个<code>LinkedHashMap</code>来存储堆内和对外内存中的所有Block对象的实例：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Note: all changes to memory allocations, notably putting blocks, evicting blocks, and</span></span><br><span class="line"><span class="comment">// acquiring or releasing unroll memory, must be synchronized on `memoryManager`!</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> entries = <span class="keyword">new</span> <span class="type">LinkedHashMap</span>[<span class="type">BlockId</span>, <span class="type">MemoryEntry</span>[_]](<span class="number">32</span>, <span class="number">0.75</span>f, <span class="literal">true</span>)</span><br></pre></td></tr></table></figure><p>通过这段源码的注释我们也可以知道，对这个map的数据结构进行操作的时候需要严格遵循同步的原则，因为一个Executor会对应一个MemoryStore，而一个Executor有多个core的时候会并行执行Task，就会有多个线程共享使用一块Storage Memory，即共享使用这一个LinkedHashMap，修改LinkedHashMap时需要做到同步。<br>因为不能保证存储空间可以一次容纳 Iterator 中的所有数据，当前的计算任务在 Unroll 时要向 MemoryManager 申请足够的 Unroll 空间来临时占位，空间不足则 Unroll 失败，空间足够时可以继续进行。至于为何要选择LinkedHashMap来存储也是有原因的，因为LinkedHashMap能够很好地支持LRU算法(最近最少使用，常用于页面置换算法)，我们可以看到定义LinkedHashMap的第三个参数<code>accessOrder=true</code>，即基于访问顺序，被访问到的元素会被加到LinkedHashMap的最后。基于这个特性，当新Block加入的时候发现内存空间不足的时候，会按照最近最少使用的顺序淘汰LinkedHashMap中的Block。</p><h3 id="序列化存储"><a href="#序列化存储" class="headerlink" title="序列化存储"></a>序列化存储</h3><p>序列化存储使用了一个名为SerializedMemoryEntry的case class：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">SerializedMemoryEntry</span>[<span class="type">T</span>](<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    buffer: <span class="type">ChunkedByteBuffer</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    memoryMode: <span class="type">MemoryMode</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    classTag: <span class="type">ClassTag</span>[<span class="type">T</span>]</span>) <span class="keyword">extends</span> <span class="title">MemoryEntry</span>[<span class="type">T</span>] </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">size</span></span>: <span class="type">Long</span> = buffer.size</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的主要存储结构为<code>ChunkedByteBuffer</code>，实际上这个类是Spark自己实现的用于存储<code>ByteBuffer</code>的数据结构，其本质为<code>Array[ByteBuffer]</code>，Array的每一个元素被称为一个chunk。对于已经序列化的Partition在转化为Block进行存储时，因为在存储时就已经知道序列化的ByteBuffer的size，其所需要的Unroll空间可以直接累加计算，一次申请。存储所使用的方法为<code>putBytes</code>，需要输入Block的ID、占用的内存空间大小、存储模式为堆内内存还是堆外内存以及存放序列化数据的ByteBuffer，其返回的内容指示了是否缓存成功：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">putBytes</span></span>[<span class="type">T</span>: <span class="type">ClassTag</span>](</span><br><span class="line">      blockId: <span class="type">BlockId</span>,</span><br><span class="line">      size: <span class="type">Long</span>,</span><br><span class="line">      memoryMode: <span class="type">MemoryMode</span>,</span><br><span class="line">      _bytes: () =&gt; <span class="type">ChunkedByteBuffer</span>): <span class="type">Boolean</span></span><br></pre></td></tr></table></figure><p>获取序列化缓存的内容可以直接使用<code>getBytes</code>方法，输入Block的ID，获取对应的ChunkByteBuffer。</p><a id="more"></a><h3 id="非序列化存储"><a href="#非序列化存储" class="headerlink" title="非序列化存储"></a>非序列化存储</h3><p>非序列化存储使用了一个名为DeserializedMemoryEntry的case class：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">DeserializedMemoryEntry</span>[<span class="type">T</span>](<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    value: <span class="type">Array</span>[<span class="type">T</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">    size: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    classTag: <span class="type">ClassTag</span>[<span class="type">T</span>]</span>) <span class="keyword">extends</span> <span class="title">MemoryEntry</span>[<span class="type">T</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> memoryMode: <span class="type">MemoryMode</span> = <span class="type">MemoryMode</span>.<span class="type">ON_HEAP</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，非序列化的存储方式为将元素直接按照Array的方式进行存储，获取其中的存储内容时，可以直接返回装有数据的Iterator。非序列化的存储方式在遍历Record并申请内存时较为复杂，因为无法直接估计Block中所有Record的总空间大小，需要在遍历Record过程中一次申请，即每读取一条Record，采样估算其所需的Unroll空间并进行申请，空间不足时可以中断，释放已占用的Unroll空间。如果最终Unroll成功，当前Partition所占用的Unroll空间被转换为正常的缓存RDD的存储空间。采用估算使用的是<code>SizeTrackingVector</code>，其实现了<code>SizeTracker</code>接口，可以通过采样的方式，在O(1)时间估计出输入的Block的大小，若估计出的大小超出了申请的内存的临界值，便会再申请内存来存放新加入的Record。这种依次申请内存的方式，其占用的内存是通过周期性地采样近似估算而得，即并不是每次新增的数据项都会计算一次占用的内存大小，这种方法降低了时间开销但是有可能误差较大，导致某一时刻的实际内存有可能远远超出预期。但这也是一种权衡方式，即在计算以及申请内存的时间开销和申请内存准确度上的平衡，在大多数情况下，采样获得的内存大小估计还是准确的。<br>非序列化的Block有两种存储方式，一种是按照Array的方式存储原值，另一种为将原值进行序列化后存储，所调用的方法为<code>putIteratorAsValues</code>和<code>putIteratorAsBytes</code>：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Attempt to put the given block in memory store as values.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * It's possible that the iterator is too large to materialize and store in memory. To avoid</span></span><br><span class="line"><span class="comment"> * OOM exceptions, this method will gradually unroll the iterator while periodically checking</span></span><br><span class="line"><span class="comment"> * whether there is enough free memory. If the block is successfully materialized, then the</span></span><br><span class="line"><span class="comment"> * temporary unroll memory used during the materialization is "transferred" to storage memory,</span></span><br><span class="line"><span class="comment"> * so we won't acquire more memory than is actually needed to store the block.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @return in case of success, the estimated size of the stored data. In case of failure, return</span></span><br><span class="line"><span class="comment"> *         an iterator containing the values of the block. The returned iterator will be backed</span></span><br><span class="line"><span class="comment"> *         by the combination of the partially-unrolled block and the remaining elements of the</span></span><br><span class="line"><span class="comment"> *         original input iterator. The caller must either fully consume this iterator or call</span></span><br><span class="line"><span class="comment"> *         `close()` on it in order to free the storage memory consumed by the partially-unrolled</span></span><br><span class="line"><span class="comment"> *         block.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span>[storage] <span class="function"><span class="keyword">def</span> <span class="title">putIteratorAsValues</span></span>[<span class="type">T</span>](</span><br><span class="line">    blockId: <span class="type">BlockId</span>,</span><br><span class="line">    values: <span class="type">Iterator</span>[<span class="type">T</span>],</span><br><span class="line">    classTag: <span class="type">ClassTag</span>[<span class="type">T</span>]): <span class="type">Either</span>[<span class="type">PartiallyUnrolledIterator</span>[<span class="type">T</span>], <span class="type">Long</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[storage] <span class="function"><span class="keyword">def</span> <span class="title">putIteratorAsBytes</span></span>[<span class="type">T</span>](</span><br><span class="line">    blockId: <span class="type">BlockId</span>,</span><br><span class="line">    values: <span class="type">Iterator</span>[<span class="type">T</span>],</span><br><span class="line">    classTag: <span class="type">ClassTag</span>[<span class="type">T</span>],</span><br><span class="line">    memoryMode: <span class="type">MemoryMode</span>): <span class="type">Either</span>[<span class="type">PartiallySerializedBlock</span>[<span class="type">T</span>], <span class="type">Long</span>]</span><br></pre></td></tr></table></figure><h2 id="RDD的持久化级别"><a href="#RDD的持久化级别" class="headerlink" title="RDD的持久化级别"></a>RDD的持久化级别</h2><p>前面既然说道了RDD缓存时会有序列化存储和非序列化存储两种方式，我们就顺便说一下RDD持久化的存储级别，这里涉及到的Spark源码当中的文件为<code>spark/core/src/main/scala/org/apache/spark/storage/StorageLevel.scala</code>，其中描述了Spark持久化存储级别当中5个重要的变量，这5个变量能组合称为RDD的11中存储级别：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">var</span> _useDisk: <span class="type">Boolean</span>,</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">var</span> _useMemory: <span class="type">Boolean</span>,</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">var</span> _useOffHeap: <span class="type">Boolean</span>,</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">var</span> _deserialized: <span class="type">Boolean</span>,</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">var</span> _replication: <span class="type">Int</span> = <span class="number">1</span></span><br></pre></td></tr></table></figure><p>这5个变量的前3个表示的是存储的位置，分别为磁盘、堆内内存和堆外内存。例如<code>DISK_ONLY</code>表示只存储在磁盘当中，<code>MEMORY_AND_DISK</code>表示可以存储在堆内内存和磁盘上，<code>OFF_HEAP</code>则只能存储在堆外内存上。<br><code>_deserialized</code>表示是否序列化，例如<code>MEMORY_ONLY_SER</code>表示序列化存储在堆内内存上，不加SER的存储级别则为不进行序列化。<br><code>_replication</code>表示备份的数量，默认不会进行冗余备份，<code>MEMORY_AND_DISK_2</code>则表示可以存储在堆内内存和磁盘上，并且创建一个副本进行备份，一般冗余备份会备份到其他的节点，保证持久化的数据的容错性。</p><h2 id="Block存储的淘汰和落盘"><a href="#Block存储的淘汰和落盘" class="headerlink" title="Block存储的淘汰和落盘"></a>Block存储的淘汰和落盘</h2><p>我们可以从Spark源码的一些注释当中看到，当有新的Block要存储，内存又不够用时，会通过LRU淘汰一部分最近不常使用的Block，释放其内存给新加入的Block进行存储，如果被淘汰的Block的持久化级别当中有DISK，则会将其写入磁盘当中，称为落盘。Block的淘汰也不是仅仅依赖于LRU算法，其具有一定的规则：</p><blockquote><ul><li>被淘汰的旧 Block 要与新 Block 的 MemoryMode 相同，即同属于堆外或堆内内存</li><li>新旧 Block 不能属于同一个 RDD，避免循环淘汰</li><li>旧 Block 所属 RDD 不能处于被读状态，避免引发一致性问题</li><li>遍历 LinkedHashMap 中 Block，按照最近最少使用（LRU）的顺序淘汰，直到满足新 Block 所需的空间。其中 LRU 是 LinkedHashMap 的特性</li></ul></blockquote><p>淘汰Block并释放其内存调用的方法为<code>evictBlocksToFreeSpace</code>：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Try to evict blocks to free up a given amount of space to store a particular block.</span></span><br><span class="line"><span class="comment"> * Can fail if either the block is bigger than our memory or it would require replacing</span></span><br><span class="line"><span class="comment"> * another block from the same RDD (which leads to a wasteful cyclic replacement pattern for</span></span><br><span class="line"><span class="comment"> * RDDs that don't fit into memory that we want to avoid).</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param blockId the ID of the block we are freeing space for, if any</span></span><br><span class="line"><span class="comment"> * @param space the size of this block</span></span><br><span class="line"><span class="comment"> * @param memoryMode the type of memory to free (on- or off-heap)</span></span><br><span class="line"><span class="comment"> * @return the amount of memory (in bytes) freed by eviction</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span>[spark] <span class="function"><span class="keyword">def</span> <span class="title">evictBlocksToFreeSpace</span></span>(</span><br><span class="line">    blockId: <span class="type">Option</span>[<span class="type">BlockId</span>],</span><br><span class="line">    space: <span class="type">Long</span>,</span><br><span class="line">    memoryMode: <span class="type">MemoryMode</span>): <span class="type">Long</span></span><br></pre></td></tr></table></figure><p>我们也可以在这段代码的注释当中看到一些淘汰Block可能会出现fail的情况，包括新存储的Block所占用的空间大于总内存，或者需要替换处于同一个RDD的不同的Block。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文主要从Spark源码的角度分析了Storage Memory部分，RDD的缓存机制，同时简略介绍了RDD持久化的存储级别。Spark对堆内内存的管理是一种逻辑上的”规划式”的管理，因为对象实例占用内存的申请和释放都由JVM完成，Spark只能在申请后和释放前记录这些内存。所谓记录就是Spark不会有具体的释放内存的操作，只是记录内存变化而已(释放内存时会将不需要的对象置为null，让JVM的GC来回收)，从源码当中我们也可以看到对各种内存的释放和申请调用的方法只是在StorageManager当中进行一个数字的记录和改变，例如如下这段代码：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transferUnrollToStorage</span></span>(amount: <span class="type">Long</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// Synchronize so that transfer is atomic</span></span><br><span class="line">  memoryManager.synchronized &#123;</span><br><span class="line">    releaseUnrollMemoryForThisTask(<span class="type">MemoryMode</span>.<span class="type">ON_HEAP</span>, amount)</span><br><span class="line">    <span class="keyword">val</span> success = memoryManager.acquireStorageMemory(blockId, amount, <span class="type">MemoryMode</span>.<span class="type">ON_HEAP</span>)</span><br><span class="line">    assert(success, <span class="string">"transferring unroll memory to storage memory failed"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Acquire storage memory if necessary to store this block in memory.</span></span><br><span class="line"><span class="keyword">val</span> enoughStorageMemory = &#123;</span><br><span class="line">  <span class="keyword">if</span> (unrollMemoryUsedByThisBlock &lt;= size) &#123;</span><br><span class="line">    <span class="keyword">val</span> acquiredExtra =</span><br><span class="line">      memoryManager.acquireStorageMemory(</span><br><span class="line">        blockId, size - unrollMemoryUsedByThisBlock, <span class="type">MemoryMode</span>.<span class="type">ON_HEAP</span>)</span><br><span class="line">    <span class="keyword">if</span> (acquiredExtra) &#123;</span><br><span class="line">      transferUnrollToStorage(unrollMemoryUsedByThisBlock)</span><br><span class="line">    &#125;</span><br><span class="line">    acquiredExtra</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123; <span class="comment">// unrollMemoryUsedByThisBlock &gt; size</span></span><br><span class="line">    <span class="comment">// If this task attempt already owns more unroll memory than is necessary to store the</span></span><br><span class="line">    <span class="comment">// block, then release the extra memory that will not be used.</span></span><br><span class="line">    <span class="keyword">val</span> excessUnrollMemory = unrollMemoryUsedByThisBlock - size</span><br><span class="line">    releaseUnrollMemoryForThisTask(<span class="type">MemoryMode</span>.<span class="type">ON_HEAP</span>, excessUnrollMemory)</span><br><span class="line">    transferUnrollToStorage(size)</span><br><span class="line">    <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>unrollMemory在释放的时候，需要比较申请到的unrollMemory是否大于最后存储Block的entry的size，如果小于size，会有一个申请不足的storageMemory的过程，并将unrollMemroy转换(transfer)为storageMemory，而Storage Memory的申请还是释放最终都归结为StorageMemoryPool中一个Long类型的<code>_memoryUsed</code>变量的值的改变而已。例如如下StorageMemoryPool释放内存的代码：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">releaseMemory</span></span>(size: <span class="type">Long</span>): <span class="type">Unit</span> = lock.synchronized &#123;</span><br><span class="line">  <span class="keyword">if</span> (size &gt; _memoryUsed) &#123;</span><br><span class="line">    logWarning(<span class="string">s"Attempted to release <span class="subst">$size</span> bytes of storage "</span> +</span><br><span class="line">      <span class="string">s"memory when we only have <span class="subst">$&#123;_memoryUsed&#125;</span> bytes"</span>)</span><br><span class="line">    _memoryUsed = <span class="number">0</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    _memoryUsed -= size</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于Spark的内存管理，在被Spark标记为释放的对象实例，很有可能在实际上并没有被JVM回收，导致实际可用的内存小于Spark记录的可用内存，所以Spark并不能准确记录实际可用的堆内内存，从而也就无法完全OOM的异常，我们在平时管理Spark内存的时候要做好充分的内存监控以及调优，保证我们的程序能够在有限的内存环境下正常快速的运行。有时候为了调优可能还需要深刻了解JVM GC的机制，才能做到最大程度的内存充分理由和不出现OOM的异常。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://www.ibm.com/developerworks/cn/analytics/library/ba-cn-apache-spark-memory-management/index.html" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/analytics/library/ba-cn-apache-spark-memory-management/index.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Spark源码阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark的内存管理</title>
      <link href="/2018/04/04/spark/Spark%E7%9A%84%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"/>
      <url>/2018/04/04/spark/Spark%E7%9A%84%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>Spark相对于Hadoop来说一个最大的优势就是可以支持迭代运算在内存当中进行，正如Spark官网首页上列出的第一个优势“Speed”，官方是这样描述的：</p><blockquote><p><strong>Speed</strong><br>Run programs up to 100x faster than Hadoop MapReduce in memory, or 10x faster on disk. Apache Spark has an advanced DAG<br>execution engine that support acyclic data flow and in-memory<br>computing.</p></blockquote><p>同时官方还给了这样一张图来说明对于迭代式计算的逻辑回归而言，Spark比Hadoop快了可不是一点半点。</p><p> <img src="http://spark.apache.org/images/logistic-regression.png" alt="Logistic regression in Hadoop and Spark"></p><p>对于in-memory的Spark来说，了解一下其内存管理还是十分重要的，因为Spark的in-memory的计算特性，其对内存的消耗还是很巨大的，如果对Spark的内存管理不够了解便不能充分利用所有的内存资源，并且很容易导致内存不够用时中间数据被缓存到了磁盘当中影响计算的速度。</p><h2 id="Spark内存管理接口"><a href="#Spark内存管理接口" class="headerlink" title="Spark内存管理接口"></a>Spark内存管理接口</h2><p>Spark为存储内存和执行内存的管理提供了统一的抽象类——<a href="https://github.com/apache/spark/blob/branch-1.6/core/src/main/scala/org/apache/spark/memory/MemoryManager.scala" target="_blank" rel="noopener">MemoryManager</a>，同一个Executor内的任务都调用这个抽象类的方法来申请或释放内存，几个关键的内存管理接口定义如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">acquireStorageMemory</span></span>(</span><br><span class="line">    blockId: <span class="type">BlockId</span>,</span><br><span class="line">    numBytes: <span class="type">Long</span>,</span><br><span class="line">    evictedBlocks: mutable.<span class="type">Buffer</span>[(<span class="type">BlockId</span>, <span class="type">BlockStatus</span>)]): <span class="type">Boolean</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">acquireUnrollMemory</span></span>(</span><br><span class="line">    blockId: <span class="type">BlockId</span>,</span><br><span class="line">    numBytes: <span class="type">Long</span>,</span><br><span class="line">    evictedBlocks: mutable.<span class="type">Buffer</span>[(<span class="type">BlockId</span>, <span class="type">BlockStatus</span>)]): <span class="type">Boolean</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[memory]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">acquireExecutionMemory</span></span>(</span><br><span class="line">    numBytes: <span class="type">Long</span>,</span><br><span class="line">    taskAttemptId: <span class="type">Long</span>,</span><br><span class="line">    memoryMode: <span class="type">MemoryMode</span>): <span class="type">Long</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[memory]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">releaseExecutionMemory</span></span>(</span><br><span class="line">    numBytes: <span class="type">Long</span>,</span><br><span class="line">    taskAttemptId: <span class="type">Long</span>,</span><br><span class="line">    memoryMode: <span class="type">MemoryMode</span>): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">  memoryMode <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">MemoryMode</span>.<span class="type">ON_HEAP</span> =&gt; onHeapExecutionMemoryPool.releaseMemory(numBytes, taskAttemptId)</span><br><span class="line">    <span class="keyword">case</span> <span class="type">MemoryMode</span>.<span class="type">OFF_HEAP</span> =&gt; offHeapExecutionMemoryPool.releaseMemory(numBytes, taskAttemptId)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[memory] <span class="function"><span class="keyword">def</span> <span class="title">releaseAllExecutionMemoryForTask</span></span>(taskAttemptId: <span class="type">Long</span>): <span class="type">Long</span> = synchronized &#123;</span><br><span class="line">  onHeapExecutionMemoryPool.releaseAllMemoryForTask(taskAttemptId) +</span><br><span class="line">    offHeapExecutionMemoryPool.releaseAllMemoryForTask(taskAttemptId)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">releaseStorageMemory</span></span>(numBytes: <span class="type">Long</span>): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">  storageMemoryPool.releaseMemory(numBytes)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">releaseAllStorageMemory</span></span>(): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">  storageMemoryPool.releaseAllMemory()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">releaseUnrollMemory</span></span>(numBytes: <span class="type">Long</span>): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">  releaseStorageMemory(numBytes)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Spark的内存系统随着Spark版本的发展具有非常多的变化，1.6.0版本之后新的内存管理模块的实现类为<a href="https://github.com/apache/spark/blob/branch-1.6/core/src/main/scala/org/apache/spark/memory/UnifiedMemoryManager.scala" target="_blank" rel="noopener">UnifiedMemoryManager</a>，1.6.0版本之前采用的静态管理<a href="https://github.com/apache/spark/blob/branch-1.6/core/src/main/scala/org/apache/spark/memory/StaticMemoryManager.scala" target="_blank" rel="noopener">StaticMemoryManager</a>方式仍被保留，称为Legacy模式。Legacy模式默认是关闭的，需要通过增加一个配置参数<code>spark.memory.useLegacyMode=true</code>来开启。</p><h1 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h1><h2 id="静态内存管理"><a href="#静态内存管理" class="headerlink" title="静态内存管理"></a>静态内存管理</h2><p>首先来简略地了解一下Spark 1.6.0版本之前的内存管理模型，对于一个Executor，内存一般由3个部分构成：</p><ol><li>Executor Memory，这片内存区域是为了解决shuffle、joins、sorts以及aggregations过程中为了避免繁琐的IO需要的buffer，可以通过参数<code>spark.shuffle.memoryFraction</code>配置，其默认值为0.2。</li><li>Storage Memory，这片内存区域是用于RDD的cache、persist以及broadcasts和task results的存储，可以通过参数<code>spark.storage.memoryFraction</code>配置，默认值为0.6.</li><li>Other Memory，给系统预留的，因为程序本身运行也是需要内存的，其默认比例为0.2。<br>除此之外，为了防止OOM，一般都会有个safetyFraction，这种内存分配机制最大的问题就是其静态性，每个部分都不能超过自己的上限，规定了多少就是多少，这在Storage Memory和Executor Memory当中尤为严重。借用别人的一张图片能够很清楚的说明静态内存的分配方式：<a id="more"></a><img src="https://www.ibm.com/developerworks/cn/analytics/library/ba-cn-apache-spark-memory-management/image002.png" alt="static-memory"></li></ol><h2 id="统一内存管理"><a href="#统一内存管理" class="headerlink" title="统一内存管理"></a>统一内存管理</h2><p>首先来看一张图片，这张图片很清晰地展示了1.6.0版本之后Spark在堆内存当中的使用情况。</p><p><img src="https://github.com/liujiayi771/liujiayi771.github.io/blob/master/assets/blogImg/Spark-Memory-Management-1.6.0.jpg?raw=true" alt="unified-memory"></p><p>从图片当中可以看到，在这种方式的内存管理下，一共有3个主要的内存区域，分别为Reserved Memory、User Memory和Spark Memory，接下来分别对这3块内存区域进行说明：</p><ol><li><p><strong>Reserved Memory</strong>，这块内存区域是Spark系统预留的内存区域，用于存储Spark的内部对象，它的大小是在源码当中固定死的，为300MB，我们可以从源码中看到这段对Reserved Memory限定的代码：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Set aside a fixed amount of memory for non-storage, non-execution purposes.</span></span><br><span class="line"><span class="comment">// This serves a function similar to `spark.memory.fraction`, but guarantees that we reserve</span></span><br><span class="line"><span class="comment">// sufficient memory for the system even for small heaps. E.g. if we have a 1GB JVM, then</span></span><br><span class="line"><span class="comment">// the memory used for execution and storage will be (1024 - 300) * 0.75 = 434MB by default.</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> <span class="type">RESERVED_SYSTEM_MEMORY_BYTES</span> = <span class="number">300</span> * <span class="number">1024</span> * <span class="number">1024</span></span><br></pre></td></tr></table></figure><p>Reserved Memory的大小只能通过自己编译修改过的Spark源码来实现更改，还有一点需要说明的是，如果给每个Executor设定的内存值小于<code>1.5 * Reserved Memory = 450MB</code>，Executor将不会被正常启动，会报一个错误信息“please use larger heap size”。我们也可以从源码的注释信息中看到，用于execution和storage的内存大小为<code>(Java Heap Memory - Reserved Memory) * 0.75</code>，即Spark 1.6.0中<code>spark.memory.fraction</code>的默认值为0.75，但是目前版本的Spark，其默认值为0.6。</p></li><li><p><strong>User Memory</strong>，这块内存区域为用户内存，用于用户保存在RDD转换操作中需要使用的自己的数据结构。这块区域的大小为<code>(Java Heap Memory - Reserved Memory) * (1 - spark.memory.fraction)</code>，对于这块区域的使用，Spark对于用户使用这块内存区域做什么以及使用的内存是否会超出这个区域的限制都不加管束，因此用户在使用时如果不加注意，很容易产生OOM的问题。</p></li><li><p><strong>Spark Memory</strong>，这块内存区域由Spark来管理和使用，其大小为<code>(Java Heap Memory - Reserved Memory) * spark.memory.fraction</code>。这块内存区域又会被分为两部分，分别为<strong>Storage Memory</strong>和<strong>Execution Memory</strong>，这两块区域的大小通过一个参数<code>spark.memory.storageFraction</code>来控制，其默认值为0.5。Legacy内存管理方式下，对于这两块区域的限定有一个非常好的优点就是这两块区域内存大小的限定并不是静态的，根据两块内存区域的内存压力这个划分边界会随之改变，一片区域的内存大小会通过向另一片区域“借”内存来增加，一方空闲而另一方内存不足的时候，内存不足的一方可以借用另一方的内存。这种内存借用的机制会导致在内存“归还”的时候需要释放借用的那部分内存，对于Storage Memory占用了Executor Memory的情况，当Executor Memory不够用需要Storage Memory归还占用的内存的时候，这时会强制释放Storage Memory中属于Executor Memory的那部分内存，Storage Memory丢失的那部分数据会在下次使用的时候被重新计算；对于Executor Memory占用Storage Memory的情况，当Storage Memory内存不够用的时候，不会强制释放被Executor Memory占用的那部分属于Storage Memory的内存，Storage Memory会一直等待，直到Executor Memory主动释放其占用的那部分属于Storage Memory的内存，因为强制释放Executor Memory会导致任务失败。接下来再详细说一下Storage Memory和Executor Memory。</p><ul><li>Storage Memory<br>用来存储Spark缓存的数据（RDD的cache或者说是persist）、unroll数据以及广播变量。unroll指的是将序列化的数据反序列化为可以直接被访问的数据，Storage Memory中有一部分被称为Unroll Memory，在Spark中数据可以以序列化和反序列化的形式存储，序列化后的数据是无法直接被访问的，只有反序列化之后才可以被使用，反序列化过程中用到的内存就是Unroll Memory，Spark中大部分数据都是以序列化的方式进行传输的。</li><li>Executor Memory<br>这部分内存用来存储Spark执行task过程中需要用到的对象，例如shuffle过程中mapper的输出，这部分的内存区域不够用时，也支持将数据写到磁盘上。Execution Memory当中有一部分为Shuffle Memory，是shuffle阶段使用的内存，主要用在sort上，如果这一块没有足够的内存来做shuffle，将会出现OOM。</li></ul></li></ol><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="http://www.leocook.org/2016/10/13/spark%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/" target="_blank" rel="noopener">http://www.leocook.org/2016/10/13/spark%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</a></li><li><a href="https://0x0fff.com/spark-memory-management/" target="_blank" rel="noopener">https://0x0fff.com/spark-memory-management/</a></li><li><a href="https://www.ibm.com/developerworks/cn/analytics/library/ba-cn-apache-spark-memory-management/index.html" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/analytics/library/ba-cn-apache-spark-memory-management/index.html</a></li><li><a href="http://spark.apache.org/docs/1.6.0/configuration.html#memory-management" target="_blank" rel="noopener">http://spark.apache.org/docs/1.6.0/configuration.html#memory-management</a></li><li><a href="https://zhuanlan.zhihu.com/p/26905029" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/26905029</a></li><li><a href="https://www.jianshu.com/p/b250797b452a" target="_blank" rel="noopener">https://www.jianshu.com/p/b250797b452a</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark对大规模数据进行分区</title>
      <link href="/2018/03/17/spark/Spark%E5%AF%B9%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%88%86%E5%8C%BA/"/>
      <url>/2018/03/17/spark/Spark%E5%AF%B9%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%88%86%E5%8C%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="groupByKey"><a href="#groupByKey" class="headerlink" title="groupByKey"></a>groupByKey</h1><p>在编写处理大规模数据的Spark代码的时候遇到一个问题，对大规模数据进行groupByKey操作的时候时间非常长，而且很容易出现OOM的情况。这其中的主要原因有几点，一是groupByKey会造成大量的数据shuffle，大量的IO会影响程序的运行时间；二是每一个key下对应的数据非常不均匀，有的key对应的key非常多，在某个executor上的数据可能会超出内存大小，造成OOM的情况。</p><p>groupByKey这个API事实上不是一个非常高效的API，会造成大量的数据搬移，效率不高。在我的项目当中，我实际上要做的任务是将我的数据按照染色体序号进行group，将染色体号为1的记录归并到一起进行处理，将染色体序号为2的记录归并到一起处理，等等。由于记录的数量非常庞大，并且不同染色体号的记录数量又和染色体的长度相关，是十分不均匀的，例如1号染色体对应的记录数量就远远大于Y染色体，groupByKey会消耗非常多的时间在数据迁移以及数据的序列化反序列化上，同时，每一个group数据量的不均匀性又会导致某些executor上内存压力过大，出现OOM的情况。</p><h1 id="partitionBy"><a href="#partitionBy" class="headerlink" title="partitionBy"></a>partitionBy</h1><p>其实对于我的这种情况使用partitionBy会更为适合，可以自己实现一个partitioner，也可以直接使用HashPartitioner，以染色体号作为key进行重新分区，然后再使用mapPartition在每个分区内处理不同染色体，partitionBy的效率会比groupByKey高很多。</p><h1 id="repartitionAndSortWithinPartitions"><a href="#repartitionAndSortWithinPartitions" class="headerlink" title="repartitionAndSortWithinPartitions"></a>repartitionAndSortWithinPartitions</h1><p>在我的项目当中，对每个染色体号对应的记录进行的数据处理包括对数据的排序操作，在数据量很大的时候，这个排序操作也会很耗费时间，但是在partitionBy对数据进行shuffle的时候，已经对数据进行过遍历了，之后再次排序需要又一次遍历数据，十分浪费时间。于是，我又找到了一个非常适合我的程序的一个新的分区接口<code>repartitionAndSortWithinPartitions</code>，首先看下这个接口的使用方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def repartitionAndSortWithinPartitions(partitioner: Partitioner): RDD[(K, V)]</span><br><span class="line"></span><br><span class="line">Repartition the RDD according to the given partitioner and, within each resulting partition, sort records by their keys.</span><br><span class="line"></span><br><span class="line">This is more efficient than calling repartition and then sorting within each partition because it can push the sorting down into the shuffle machinery.</span><br></pre></td></tr></table></figure><p>为了使用这个接口，我就必须将我自己定义的数据类型定义一个排序规则，即定义一个Ordering，具体的定义方法如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">MySAMRecord</span> </span>&#123;</span><br><span class="line">  <span class="keyword">implicit</span> <span class="keyword">val</span> samRecordOrdering: <span class="type">Ordering</span>[<span class="type">MySAMRecord</span>] = <span class="keyword">new</span> <span class="type">Ordering</span>[<span class="type">MySAMRecord</span>] &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compare</span></span>(x: <span class="type">MySAMRecord</span>, y: <span class="type">MySAMRecord</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">      <span class="keyword">if</span> (x.referenceIndex != y.referenceIndex) x.referenceIndex - y.referenceIndex</span><br><span class="line">      <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (x.startPos != y.startPos) &#123;</span><br><span class="line">          x.startPos - y.startPos</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">if</span> (<span class="keyword">new</span> <span class="type">String</span>(x.originalStrByteArr) &gt; <span class="keyword">new</span> <span class="type">String</span>(y.originalStrByteArr)) <span class="number">1</span> <span class="keyword">else</span> <span class="number">-1</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同时，由于<code>repartitionAndSortWithinPartitions</code>接口的排序是按照key进行的，我就不能使用原有的HashPartitioner进行分区，需要自己定义Partitioner，使得我自己定义的数据类型作为key值时，仍然能够按照染色体序号进行分区，我自己的Partitioner函数定义如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">Partitioner</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySAMRecordPartitioner</span>(<span class="params">numParts: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">numPartitions</span></span>: <span class="type">Int</span> = numParts</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getPartition</span></span>(key: <span class="type">Any</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> record: <span class="type">MySAMRecord</span> = key.asInstanceOf[<span class="type">MySAMRecord</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> code = record.regionId % numPartitions</span><br><span class="line">    <span class="keyword">if</span> (code &lt; <span class="number">0</span>) &#123;</span><br><span class="line">      code + numPartitions</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      code</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">equals</span></span>(other: <span class="type">Any</span>): <span class="type">Boolean</span> = other <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> records: <span class="type">MySAMRecordPartitioner</span> =&gt;</span><br><span class="line">      records.numPartitions == numPartitions</span><br><span class="line">    <span class="keyword">case</span> _ =&gt;</span><br><span class="line">      <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">hashCode</span></span>(): <span class="type">Int</span> = numPartitions</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当我的数据输入是<code>RDD[MySAMRecord]</code>时，为了使用<code>repartitionAndSortWithinPartitions</code>，需要将输入转换成键值对形式，RDD[(MySAMRecord, None)]，repartition之后，每个partition中的数据就会被自动排序完成，从源码注释当中我们也可以看到，这样子操作是比repartition之后再在每个分区中sorting是要快的，因为这个排序是在shffle的同时进行的，对数据的遍历在shffle的时候只进行了一次，效率当然会高很多。之后再使用mapPartition对每个分区进行操作的时候，每个partition所对应的Iterable就已经是有序的了，不需要再进行新的排序操作。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol><li>在处理的数据比较大的时候，尽量不要使用groupByKey操作，这个操作的效率很低，可以使用reduceByKey(当需要后续操作的时候)来代替，也可以使用partitionBy，repartition等接口进行替代。</li><li>在处理的数据分区之后，如果还要进行排序操作的话，可以尝试使用repartitionAndSortWithinPartitions，这个接口能够在shuffle数据的同时进行排序，减少遍历数据的次数，节省程序运行时间。</li></ol><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/best_practices/prefer_reducebykey_over_groupbykey.html" target="_blank" rel="noopener">https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/best_practices/prefer_reducebykey_over_groupbykey.html</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mesos kill framework的方法</title>
      <link href="/2017/11/16/Mesos-kill-framework%E7%9A%84%E6%96%B9%E6%B3%95/"/>
      <url>/2017/11/16/Mesos-kill-framework%E7%9A%84%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>最近将Spark集群部署到了Mesos之上，运行Spark程序时，能够方便的在Mesos的sandbox中查看程序运行时产生的stderr和stdout，并且这两个文件可以动态加载，不像在Spark管理界面上需要手动点击load more才能加载出来，十分方便。但是也发现了一个问题，当调试Spark代码时手动kill掉spark-submit的进程，或者Ctrl-c时，spark的程序已经停止了，但是在Mesos的管理界面上有时候还会看到有Job在运行，会占用资源，影响之后提交的程序的资源获取。但是Mesos网页管理界面上又没有像Spark管理界面上的kill按钮，就一时不知道如何kill掉这些实际已经不在运行的Job。在Stack Overflow上查到了几种方法，其中我觉得比较好用的一个贴在这里方便之后查看。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST http://mesos-master-ip-address:5050/master/teardown -d <span class="string">'frameworkId=&lt;frameId-you-want-to-kill&gt;'</span></span><br></pre></td></tr></table></figure><p>这里使用到了Mesos的HTTP Endpoint teardown，有很多人可能会查到是shutdown，但是从Mesos某个版本之后，已经从shutdown改为了teardown，具体的有关HTTP Endpoint的官方文档说明在参考文档当中。</p><p>指令发送了一个POST请求给Mesos的一个HTTP Endpoint，要求关闭指定frameworkId的framework。可以将这个指令写在<code>~/.bashrc</code>中，方便之后使用，如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">killmesostask</span></span>()&#123; curl -XPOST http://gpu-server5:5050/master/teardown -d <span class="string">'frameworkId='</span><span class="variable">$@</span><span class="string">''</span>; &#125; ;</span><br></pre></td></tr></table></figure><p>之后就可以使用<code>killmesostask &lt;frameworkId&gt;</code>的方式来kill指定Id的framework，需要注意的是这个指令一定要在mesos的master所在的服务器上运行，如果使用了zookeeper，master有时候会发生变化，需要在每个运行mesos-master进程的机器上都加上这个语句，需要kill的时候在对应那个时刻为master的机器上运行指令。</p><a id="more"></a><p>还有一种比较复杂的方法，但可以不需要在mesos master所在的机器上运行，可以在任何机器上使用Mesos的http api来kill指定的framework，参考官方说明的如下json包：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">TEARDOWN Request (JSON):</span><br><span class="line">POST /api/v1/scheduler  HTTP/1.1</span><br><span class="line"></span><br><span class="line">Host: masterhost:5050</span><br><span class="line">Content-Type: application/json</span><br><span class="line">Mesos-Stream-Id: 130ae4e3-6b13-4ef4-baa9-9f2e85c3e9af</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"framework_id"</span>    : &#123;<span class="attr">"value"</span> : <span class="string">"12220-3440-12532-2345"</span>&#125;,</span><br><span class="line">  <span class="attr">"type"</span>            : <span class="string">"TEARDOWN"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TEARDOWN Response:</span><br><span class="line">HTTP/1.1 202 Accepted</span><br></pre></td></tr></table></figure><p>可以通过postman模拟这样一个json包发送到指定的地址，就同样能够实现kill指定frameworkId的framework的功能。</p><p>参考文档：</p><ul><li><a href="http://mesos.apache.org/documentation/latest/endpoints/" target="_blank" rel="noopener">http://mesos.apache.org/documentation/latest/endpoints/</a></li><li><a href="http://mesos.apache.org/documentation/latest/scheduler-http-api/#teardown" target="_blank" rel="noopener">http://mesos.apache.org/documentation/latest/scheduler-http-api/#teardown</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mesos </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mac终端配置</title>
      <link href="/2017/08/22/mac%E7%BB%88%E7%AB%AF%E9%85%8D%E7%BD%AE/"/>
      <url>/2017/08/22/mac%E7%BB%88%E7%AB%AF%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h3 id="1-安装iTerm2"><a href="#1-安装iTerm2" class="headerlink" title="1.安装iTerm2"></a>1.安装iTerm2</h3><h3 id="2-安装oh-my-zsh"><a href="#2-安装oh-my-zsh" class="headerlink" title="2.安装oh-my-zsh"></a>2.安装oh-my-zsh</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot;</span><br></pre></td></tr></table></figure><ul><li>使用该指令能自动切换bash为zsh</li><li>将oh-my-zsh的主题切换为ys</li><li><code>brew install autojump</code>，在.zshrc中添加plugins中的autojump，并添加<code>[[ -s ~/.autojump/etc/profile.d/autojump.sh ]] &amp;&amp; . ~/.autojump/etc/profile.    d/autojump.sh</code></li></ul><h3 id="3-安装dircolors-solarized"><a href="#3-安装dircolors-solarized" class="headerlink" title="3.安装dircolors-solarized"></a>3.安装dircolors-solarized</h3><ul><li>安装之后能够使得终端中使用ls指令具有彩色的输出</li><li><code>brew install coreutils</code></li><li><code>git clone https://github.com/liujiayi771/dircolors-solarized.git</code>，将clone文件夹中的dircolors.ansi-dark复制到~/.dir_colors</li><li>在.zshrc中添加如下内容</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if brew list | grep coreutils &gt; /dev/null ; then</span><br><span class="line">PATH=&quot;$(brew --prefix coreutils)/libexec/gnubin:$PATH&quot;</span><br><span class="line">alias ls=&apos;ls -F --show-control-chars --color=auto&apos;</span><br><span class="line">eval `gdircolors -b $HOME/.dir_colors`</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="4-修改vim主题"><a href="#4-修改vim主题" class="headerlink" title="4.修改vim主题"></a>4.修改vim主题</h3><ul><li><code>git clone git://github.com/altercation/solarized.git</code></li><li><code>mkdir -p ~/.vim/colors</code></li><li><code>cp solarized/vim-colors-solarized/colors/solarized.vim ~/.vim/colors</code></li><li><code>vim ~/.vimrc</code>，添加如下内容</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">syntax enable</span><br><span class="line">set background=dark</span><br><span class="line">colorscheme solarized</span><br><span class="line">set nu</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> mac </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>普通用户安装CNVkit</title>
      <link href="/2017/08/08/python/%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7%E5%AE%89%E8%A3%85CNVkit/"/>
      <url>/2017/08/08/python/%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7%E5%AE%89%E8%A3%85CNVkit/</url>
      
        <content type="html"><![CDATA[<p>安装python的library的时候经常需要sudo权限，原因是许多机器上安装的python都是使用apt-get(ubuntu)、yum(CentOS)安装的，在这种情况下python被安装到了root用户目录下，再使用pip安装各种库的时候，有时候库需要被安装到这些root用户目录下，就会出现权限问题。解决这个问题的方法是通过源码安装python到普通用户目录下，再通过源码安装setuptools和pip便能在普通用户下安装python的各种库。</p><h2 id="1-编译安装python"><a href="#1-编译安装python" class="headerlink" title="1.编译安装python"></a>1.编译安装python</h2><p>下载python源码，<a href="https://www.python.org/downloads/source/" target="_blank" rel="noopener">https://www.python.org/downloads/source/</a><br>这里选择python2.7.13进行测试，<a href="https://www.python.org/downloads/release/python-2713/" target="_blank" rel="noopener">https://www.python.org/downloads/release/python-2713/</a><br>下载xz压缩格式的源码，使用<code>tar -xvf Python-2.7.13.tar.xz</code>解压后进入目录，<code>./configure --prefix=/home/spark/Softwares/python2</code>通过<code>--prefix</code>指定安装目录为普通用户目录，<code>make</code>进行编译，<code>make install</code>进行安装。之后在<code>~/.bashrc</code>文件内添加PATH指定python的安装路径<code>export PATH=/home/spark/Softwares/python2/bin:$PATH</code>，然后<code>source ~/.bashrc</code>，此时python便被指定为编译安装的python了。</p><h2 id="2-编译安装setuptools和pip"><a href="#2-编译安装setuptools和pip" class="headerlink" title="2.编译安装setuptools和pip"></a>2.编译安装setuptools和pip</h2><p>下载setuptools源码，<a href="https://pypi.python.org/pypi/setuptools" target="_blank" rel="noopener">https://pypi.python.org/pypi/setuptools</a></p><p>下载zip压缩格式源码，使用<code>unzip setuptools-36.2.7.zip</code>进行解压，进入目录之后使用<code>python setup.py install</code>进行安装，此时需要确保python指令指向的是之前编译安装的python。</p><p>下载pip源码，<a href="https://pypi.python.org/pypi/pip" target="_blank" rel="noopener">https://pypi.python.org/pypi/pip</a></p><p>下载tar.gz格式的源码，使用<code>tar -zxvf pip-9.0.1.tar.gz</code>进行解压，进入目录后，首先使用<code>python setup.py build</code>进行编译，然后使用<code>python setup.py install</code>进行安装，这之后会发现在编译安装python的路径的bin目录中会有pip和setuptools程序。由于之前已经添加该bin目录到PATH环境变量当中，此时使用pip安装即为普通用户目录下的pip，可以不需要sudo权限安装各种library。</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux断点续传大文件</title>
      <link href="/2017/08/03/linux/Linux%E6%96%AD%E7%82%B9%E7%BB%AD%E4%BC%A0%E5%A4%A7%E6%96%87%E4%BB%B6/"/>
      <url>/2017/08/03/linux/Linux%E6%96%AD%E7%82%B9%E7%BB%AD%E4%BC%A0%E5%A4%A7%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h3 id="后台断点续传大文件"><a href="#后台断点续传大文件" class="headerlink" title="后台断点续传大文件"></a>后台断点续传大文件</h3><p>使用rync指令进行断点续传</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -P --rsh=ssh slurm@XXX.XXX.XXX.XXX:/path/to/file.tar.gz file.tar.gz</span><br></pre></td></tr></table></figure><p>以上指令表示将远端的file.tar.gz文件传输到近端，输入以上指令之后需要输入密码，此时输入密码便开始进行传输。此时传输的程序是运行在前台的，我们需要将该程序转入后台运行。此时使用<code>Ctrl+z</code>挂起该传输进程，再使用<code>jobs</code>指令能够看到挂起的进程的序号以及状态，例如序号为1，接下来使用<code>bg %1</code>便能将这个序号为1的挂起任务重新再后台进行执行。但是此时如果退出登录该传输进程还是会被kill，原因是该进程此时属于这个登录用户，该用户下线之后该进程便会被自动注销关闭，所以需要将该进程的所有者由当前登录的用户移交给root用户，使用<code>disown -h %1</code>便能达到这个效果，此时该进程便能顺利的在后台进行传输了，如果需要中断，只能使用手动查找到传输的进程，使用<code>kill</code>指令进行关闭。</p><p>使用ssh协议来进行rsync操作，能够在传输的时候暂停或者因为网络故障等中断传输以后下次可以继续传输，传输过程中，被传输的文件会被存储为一个隐藏文件，文件传输完毕后该隐藏文件会被转换成普通文件。如果传输过程中断，该隐藏文件也会被转换为普通文件，下次继续传输时会再转换为隐藏文件进行传输。</p><h3 id="断点传输目录"><a href="#断点传输目录" class="headerlink" title="断点传输目录"></a>断点传输目录</h3><p>使用方法基本一致</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -Pr --rsh=ssh source/dirname slurm@XXX.XXX.XXX.XXX:/home/slurm/dest/dirname</span><br></pre></td></tr></table></figure><p>断点续传目录的时候，目录中的文件会被依次以上面的那种方法的形式进行传输，传输如果中断，之前已经上传完毕的文件会被进行完整性检查，如果确认是完整传输的文件，就不会被继续传输了。</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>slurm分布式调度系统搭建</title>
      <link href="/2017/07/21/slurm%E5%88%86%E5%B8%83%E5%BC%8F%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA/"/>
      <url>/2017/07/21/slurm%E5%88%86%E5%B8%83%E5%BC%8F%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h3 id="创建云主机集群"><a href="#创建云主机集群" class="headerlink" title="创建云主机集群"></a>创建云主机集群</h3><p>登录清华大学<a href="http://cloud.iiis.systems/" target="_blank" rel="noopener">EasyStack</a>，概况中可以看到目前集群资源的使用情况，点击左侧计算资源-云主机，选择创建云主机对云主机进行创建。填入云主机名字，例如canu，选择从镜像中安装云主机，镜像选择CentOS6.5，之后对配置进行设置，对于canu项目来说建议选择16core-64GB内存-500GB磁盘的配置，网络选择share_net，安全组中将joey安全策略加入，密码设置自己密码即可，之后点击创建云主机。由于本次需要搭建一个集群，我们先完整配置好一台机器再通过该机器建立云主机快照，根据该快照来创建其他节点（即将这台机器一模一样复制多台出来）。主机创建完毕大概需要20分钟左右。</p><p>创建完毕之后需要对该主机绑定公网ip，公网ip可以到网络资源中进行申请，选择100Mbps的公网。选中之前创建的那台云主机，在更多种选择绑定公网ip，将之前申请的公网ip绑定上去。之后便可以通过vpn来连接该主机，由于windows连接清华大学vpn比较麻烦，已经在gpu-server5上打开了与清华大学的vpn连接，可以首先连接gpu-server5再连接清华大学集群。</p><h3 id="搭建slurm环境"><a href="#搭建slurm环境" class="headerlink" title="搭建slurm环境"></a>搭建slurm环境</h3><ol><li>刚创建的云主机只有root用户，一般用root用户操作有许多不便之处，需要先创建slurm用户来进行操作。(#表示需要sudo权限或root用户的操作)</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># useradd slurm</span><br></pre></td></tr></table></figure><p>之后需要增加slurm用户的sudo权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># chmod -v u+w /etc/sudoers</span><br><span class="line"># yum install vim git -y</span><br><span class="line"># vim /etc/sudoers</span><br></pre></td></tr></table></figure><p>模仿root用户的权限控制加入<code>slurm    ALL=(ALL)    ALL</code><br>之后需要恢复<code>/etc/sudoers</code>的权限，使用<code># chmod -v u-w /etc/sudoers</code></p><p>接下来<code>su slurm</code>进行操作</p><a id="more"></a><ol start="2"><li>编译安装munge，slurm通过munge来进行通信，虽然可以直接使用yum来安装munge，但这样安装的munge很容易出问题，使用编译安装的方式进行安装。下载<a href="https://github.com/dun/munge/releases/download/munge-0.5.11/munge-0.5.11.tar.bz2" target="_blank" rel="noopener">编译安装包</a>。编译安装之前需要先安装一些编译所依赖的包（可能没有列完全，需要什么依赖会有提示，按照需要的依赖自行安装即可）</li></ol><p>后来发现编译安装的munge不会有create-munge-key这个命令，还是需要用yum来进行安装，<code>yum install munge munge-devel</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># yum install -y rpm-build rpmdevtools bzip2-devel openssl-devel zlib-devel</span><br></pre></td></tr></table></figure><p>之后使用如下方法进行编译安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># rpmbuild -tb --clean munge-0.5.11.tar.bz2</span><br><span class="line"># cd /root/rpmbuild/RPMS/x86_64</span><br><span class="line"># rpm --install munge*.rpm</span><br></pre></td></tr></table></figure><p>之后需要创建文件夹并修改所有者（如果文件夹已经存在则不需要创建）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># mkdir /etc/munge</span><br><span class="line"># mkdir /var/run/munge</span><br><span class="line"># mkdir /var/lib/munge</span><br><span class="line"># mkdir /var/log/munge</span><br><span class="line"># chown slurm:slurm /etc/munge</span><br><span class="line"># chown slurm:slurm /var/run/munge</span><br><span class="line"># chown slurm:slurm /var/lib/munge</span><br><span class="line"># chown slurm:slurm /var/log/munge</span><br></pre></td></tr></table></figure><p>使用<code>create-munge-key</code>命令来创建秘钥，并修改所有者<code># chown slurm:slurm /etc/munge/munge.key</code></p><p>启动munge的命令为<code>munged</code>，可以使用<code>ps aux | grep munged</code>来判断munge是否正常启动</p><ol start="3"><li>编译安装slurm，下载<a href="https://www.schedmd.com/archives.php" target="_blank" rel="noopener">编译安装包15.08.13</a>，首先需要安装依赖</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># yum install -y readline-devel pam-devel perl-DBI perl-ExtUtils-MakeMaker</span><br></pre></td></tr></table></figure><p>之后使用如下方法进行编译安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># rpmbuild -ta --clean slurm-15.08.13.tar.bz2</span><br><span class="line"># cd /root/rpmbuild/RPMS/x86_64</span><br><span class="line"># rpm --install slurm*.rpm</span><br></pre></td></tr></table></figure><p>修改slurm.conf文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># cp /etc/slurm/slurm.conf.example /etc/slurm.conf</span><br><span class="line"># vim /etc/slurm/slurm.conf</span><br></pre></td></tr></table></figure><p>参考配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">#</span><br><span class="line"># Example slurm.conf file. Please run configurator.html</span><br><span class="line"># (in doc/html) to build a configuration file customized</span><br><span class="line"># for your environment.</span><br><span class="line">#</span><br><span class="line">#</span><br><span class="line"># slurm.conf file generated by configurator.html.</span><br><span class="line">#</span><br><span class="line"># See the slurm.conf man page for more information.</span><br><span class="line">#</span><br><span class="line">ClusterName=canu</span><br><span class="line">ControlMachine=canu</span><br><span class="line">ControlAddr=192.168.73.202</span><br><span class="line">#BackupController=</span><br><span class="line">#BackupAddr=</span><br><span class="line">#</span><br><span class="line">SlurmUser=slurm</span><br><span class="line">#SlurmdUser=root</span><br><span class="line">SlurmctldPort=6817</span><br><span class="line">SlurmdPort=6818</span><br><span class="line">AuthType=auth/munge</span><br><span class="line">#JobCredentialPrivateKey=</span><br><span class="line">#JobCredentialPublicCertificate=</span><br><span class="line">StateSaveLocation=/tmp</span><br><span class="line">SlurmdSpoolDir=/tmp/slurmd</span><br><span class="line">SwitchType=switch/none</span><br><span class="line">MpiDefault=none</span><br><span class="line">SlurmctldPidFile=/var/run/slurmctld.pid</span><br><span class="line">SlurmdPidFile=/var/run/slurmd.pid</span><br><span class="line">ProctrackType=proctrack/pgid</span><br><span class="line">#PluginDir=</span><br><span class="line">#FirstJobId=</span><br><span class="line">ReturnToService=0</span><br><span class="line">#MaxJobCount=</span><br><span class="line">#PlugStackConfig=</span><br><span class="line">#PropagatePrioProcess=</span><br><span class="line">#PropagateResourceLimits=</span><br><span class="line">#PropagateResourceLimitsExcept=</span><br><span class="line">#Prolog=</span><br><span class="line">#Epilog=</span><br><span class="line">#SrunProlog=</span><br><span class="line">#SrunEpilog=</span><br><span class="line">#TaskProlog=</span><br><span class="line">#TaskEpilog=</span><br><span class="line">#TaskPlugin=</span><br><span class="line">#TrackWCKey=no</span><br><span class="line">#TreeWidth=50</span><br><span class="line">#TmpFS=</span><br><span class="line">#UsePAM=</span><br><span class="line">#</span><br><span class="line"># TIMERS</span><br><span class="line">SlurmctldTimeout=300</span><br><span class="line">SlurmdTimeout=300</span><br><span class="line">InactiveLimit=0</span><br><span class="line">MinJobAge=300</span><br><span class="line">KillWait=30</span><br><span class="line">Waittime=0</span><br><span class="line">#</span><br><span class="line"># SCHEDULING</span><br><span class="line">SchedulerType=sched/backfill</span><br><span class="line">#SchedulerAuth=</span><br><span class="line">#SelectType=select/linear</span><br><span class="line">FastSchedule=1</span><br><span class="line">#PriorityType=priority/multifactor</span><br><span class="line">#PriorityDecayHalfLife=14-0</span><br><span class="line">#PriorityUsageResetPeriod=14-0</span><br><span class="line">#PriorityWeightFairshare=100000</span><br><span class="line">#PriorityWeightAge=1000</span><br><span class="line">#PriorityWeightPartition=10000</span><br><span class="line">#PriorityWeightJobSize=1000</span><br><span class="line">#PriorityMaxAge=1-0</span><br><span class="line">#</span><br><span class="line"># LOGGING</span><br><span class="line">SlurmctldDebug=3</span><br><span class="line">SlurmctldLogFile=/var/log/slurmctld.log</span><br><span class="line">SlurmdDebug=3</span><br><span class="line">SlurmdLogFile=/var/log/slurmd.log</span><br><span class="line">JobCompType=jobcomp/none</span><br><span class="line">#JobCompLoc=</span><br><span class="line">#</span><br><span class="line"># ACCOUNTING</span><br><span class="line">#JobAcctGatherType=jobacct_gather/linux</span><br><span class="line">#JobAcctGatherFrequency=30</span><br><span class="line">#</span><br><span class="line">AccountingStorageType=accounting_storage/slurmdbd</span><br><span class="line">AccountingStorageHost=canu</span><br><span class="line">#AccountingStorageLoc=</span><br><span class="line">AccountingStoragePass=elwg324</span><br><span class="line">AccountingStorageUser=root</span><br><span class="line">#</span><br><span class="line"># COMPUTE NODES</span><br><span class="line">NodeName=canu NodeAddr=192.168.73.202 CPUs=12 RealMemory=64000 State=UNKNOWN</span><br><span class="line">NodeName=slurm-1 NodeAddr=192.168.73.203 CPUs=12 RealMemory=64000 State=UNKNOWN</span><br><span class="line">NodeName=slurm-2 NodeAddr=192.168.73.204 CPUs=12 RealMemory=64000 State=UNKNOWN</span><br><span class="line">NodeName=slurm-3 NodeAddr=192.168.73.205 CPUs=12 RealMemory=64000 State=UNKNOWN</span><br><span class="line">PartitionName=control Nodes=canu Default=NO MaxTime=INFINITE State=UP</span><br><span class="line">PartitionName=compute Nodes=slurm-[1-3] Default=YES MaxTime=INFINITE State=UP</span><br></pre></td></tr></table></figure><p>配置中关于节点的ip地址信息可以在清华集群控制台查看，slurm-1等节点现在还没有创建出来可以先不写。注意：此处需要配置ACCOUNTING，这个我之前没有配置，我这样配置不一定能够正常运行，你们需要去学习一下如何配置slurm的accounting，在slurm的官网当中有说明<br><a href="https://slurm.schedmd.com/accounting.html" target="_blank" rel="noopener">https://slurm.schedmd.com/accounting.html</a></p><p>配置这个的好处是可以把每次任务的运行细节存储到数据库中，之后可以使用sacct命令来查看历史运行记录（运行时间等信息），没配置的话sacct无法使用。</p><h3 id="将创建好的canu机器进行复制称为slave节点"><a href="#将创建好的canu机器进行复制称为slave节点" class="headerlink" title="将创建好的canu机器进行复制称为slave节点"></a>将创建好的canu机器进行复制称为slave节点</h3><p>在清华大学集群控制台计算资源-云主机中选择要创建镜像的云主机，在更多种选择创建快照，创建完成后创建slave节点，点击创建云主机，其他步骤都和之前所说相同，但这次不是从镜像安装机器，而是从云主机快照中选择刚刚创建的那个云主机快照，云主机名字写slurm数量可以根据需要写，会自动加入-1，-2，-3的后缀在slurm后面。</p><p>slave主机创建完成后，（暂且称第一台创建的主机为头节点，后面复制的节点为计算节点），将头节点和计算节点中/etc/hosts文件的内容进行添加，把每台机器的hostname和内网ip信息都加入进去。（可以先写好一台机器，然后scp到其他所有机器上去）</p><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><ol><li>每计算节点创建完毕之后，都需要进入之后打开munge</li><li>每个节点的slurm配置文件都必须完全一样</li><li>节点打开slurm的方法为<code># /etc/init.d/slurm start</code></li><li>sinfo始终显示partition为down的状态可以先使用<code># /etc/init.d/slurm stop</code>停止，再使用<code># /etc/init.d/slurm cleanstart</code>来启动节点</li><li>munge运行能否成功和各种文件夹的权限所有者都很有关系，要仔细配置</li></ol><h3 id="参考网站"><a href="#参考网站" class="headerlink" title="参考网站"></a>参考网站</h3><ol><li><a href="http://ju.outofmemory.cn/entry/203355" target="_blank" rel="noopener">http://ju.outofmemory.cn/entry/203355</a></li><li><a href="https://www.slothparadise.com/how-to-install-slurm-on-centos-7-cluster/" target="_blank" rel="noopener">https://www.slothparadise.com/how-to-install-slurm-on-centos-7-cluster/</a></li><li><a href="http://blog.csdn.net/datuqiqi/article/details/50827040" target="_blank" rel="noopener">http://blog.csdn.net/datuqiqi/article/details/50827040</a></li></ol><p>此外，我搭好的测试集群可以使用<code>ssh slurm@10.2.1.25</code>来进行查看</p><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"># useradd slurm</span><br><span class="line"># passwd slurm</span><br><span class="line"># yum install -y vim git ansible gcc gcc-c++ rpm-build rpmdevtools bzip2-devel openssl-devel zlib-devel readline-devel pam-devel perl-DBI perl-ExtUtils-MakeMaker munge munge-devel</span><br><span class="line"># chmod -v u+w /etc/sudoers</span><br><span class="line"># vim /etc/sudoers</span><br><span class="line">在rootALL=(ALL)ALL 之后添加如下内容</span><br><span class="line">slurmALL=(ALL)ALL</span><br><span class="line"></span><br><span class="line"># chmod -v u-w /etc/sudoers</span><br><span class="line"># ssh-keygen</span><br><span class="line"># ssh-copy-id canu</span><br><span class="line"># su slurm</span><br><span class="line">$ ssh-keygen</span><br><span class="line">$ ssh-copy-id canu</span><br><span class="line">$ sudo mkdir /etc/munge</span><br><span class="line">$ sudo mkdir /var/run/munge</span><br><span class="line">$ sudo mkdir /var/lib/munge</span><br><span class="line">$ sudo mkdir /var/log/munge</span><br><span class="line">$ sudo chown slurm:slurm /etc/munge</span><br><span class="line">$ sudo chown slurm:slurm /var/run/munge</span><br><span class="line">$ sudo chown slurm:slurm /var/lib/munge</span><br><span class="line">$ sudo chown slurm:slurm /var/log/munge</span><br><span class="line">$ sudo create-munge-key</span><br><span class="line">$ sudo chown slurm:slurm /etc/munge/munge.key</span><br><span class="line">此时先不要启动munge</span><br><span class="line"></span><br><span class="line">$ rpmbuild -ta --clean slurm-15.08.13.tar.bz2</span><br><span class="line">$ cd /root/rpmbuild/RPMS/x86_64</span><br><span class="line">$ sudo rpm --install slurm*.rpm</span><br><span class="line">$ sudo cp /etc/slurm/slurm.conf.example /etc/slurm/slurm.conf</span><br><span class="line">$ sudo vim /etc/slurm/slurm.conf</span><br><span class="line">修改slurm的配置文件，有关slave的IP信息先放着不填</span><br></pre></td></tr></table></figure><p>制作快照，并建立其他slave节点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ sudo vim /etc/hosts</span><br><span class="line">将master节点和slave节点的ip信息写入，格式为xxx.xxx.xxx.xxxhostname</span><br><span class="line">并将hosts文件拷贝到所有slave节点当中去</span><br><span class="line"></span><br><span class="line">$ sudo vim /etc/ansible/hosts</span><br><span class="line">写入两个控制group，一个包含有master节点，一个包含有slave节点，具体写法参照10.2.0.80中的写法</span><br><span class="line">接下来需要关闭每个节点的防火墙</span><br><span class="line">$ sudo ansible slurm-all -m shell -a &apos;service iptables stop&apos;</span><br><span class="line">$ ansible slurm-all -m shell -a &apos;/etc/init.d/munge start&apos;</span><br><span class="line">$ sudo ansible slurm-all -m shell -a &apos;/etc/init.d/slurm start&apos;</span><br></pre></td></tr></table></figure><p>启动munge不要用sudo，启动slurm需要使用sudo权限</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Intellij IDEA 编译spark源码报错解决方法</title>
      <link href="/2017/07/05/spark/spark%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/Intellij%20IDEA%20%E7%BC%96%E8%AF%91spark%E6%BA%90%E7%A0%81%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"/>
      <url>/2017/07/05/spark/spark%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/Intellij%20IDEA%20%E7%BC%96%E8%AF%91spark%E6%BA%90%E7%A0%81%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h3 id="SparkFlumeProtocol"><a href="#SparkFlumeProtocol" class="headerlink" title="SparkFlumeProtocol"></a>SparkFlumeProtocol</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Error:(45, 66) not found: type SparkFlumeProtocol</span><br><span class="line">  val transactionTimeout: Int, val backOffInterval: Int) extends SparkFlumeProtocol with Logging &#123;</span><br></pre></td></tr></table></figure><p>这个问题是由于flume-sink所需要的部分源文件idea不会自动下载，所以编译时不能通过。</p><h4 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h4><p>在Intellij IDEA里面：</p><ul><li>打开View -&gt; Tool Windows -&gt; Maven Projects</li><li>右击Spark Project External Flume Sink</li><li>点击Generate Sources and Update Folders<br>随后，Intellij IDEA会自动下载Flume Sink相关的包</li></ul><h3 id="SqlBaseParser"><a href="#SqlBaseParser" class="headerlink" title="SqlBaseParser"></a>SqlBaseParser</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Error:(36, 45) object SqlBaseParser is not a member of package org.apache.spark.sql.catalyst.parser</span><br><span class="line">import org.apache.spark.sql.catalyst.parser.SqlBaseParser._</span><br></pre></td></tr></table></figure><p>这个问题和之前的问题类似，是idea不会自动下载部分catalyst相关的源文件，导致编译时不能通过。</p><h4 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h4><p>在Intellij IDEA里面：</p><ul><li>打开View -&gt; Tool Windows -&gt; Maven Projects</li><li>右击Spark Project Catalyst</li><li>点击Generate Sources and Update Folders<br>随后，Intellij IDEA会自动下载Catalyst相关的包</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>IDEA编译spark源码出错大多都是不能正确下载相关的源文件，在Maven的管理菜单内选择相对应的库选择下载源码并更新即可解决大多数问题。</p><p>spark build error集合：<br><a href="https://www.mail-archive.com/search?l=user@spark.apache.org&amp;q=subject:%22Build+error%22&amp;o=newest&amp;f=1" target="_blank" rel="noopener">https://www.mail-archive.com/search?l=user@spark.apache.org&amp;q=subject:%22Build+error%22&amp;o=newest&amp;f=1</a></p>]]></content>
      
      
      <categories>
          
          <category> Spark源码阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux搭建NAT共享网络</title>
      <link href="/2017/06/14/linux/Linux%E6%90%AD%E5%BB%BANAT%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/"/>
      <url>/2017/06/14/linux/Linux%E6%90%AD%E5%BB%BANAT%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h3 id="1-配置双网卡静态IP信息"><a href="#1-配置双网卡静态IP信息" class="headerlink" title="1. 配置双网卡静态IP信息"></a>1. 配置双网卡静态IP信息</h3><p><code>sudo vim /etc/sysconfig/network-scripts/ifcfg-enp15s0</code></p><p>配置该网卡为外网IP，需要添加的内容如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">BOOTPROTO=static</span><br><span class="line">ONBOOT=yes</span><br><span class="line">DNS1=202.114.0.242</span><br><span class="line">IPADDR=XXX.XXX.XXX.XXX</span><br><span class="line">PREFIX=23</span><br><span class="line">GATEWAY=115.156.163.254</span><br></pre></td></tr></table></figure><p><code>sudo vim /etc/sysconfig/network-scripts/ifcfg-eno1</code></p><p>配置该网卡转发enp15s0的网络包，需要添加的内容如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">BOOTPROTO=static</span><br><span class="line">ONBOOT=yes</span><br><span class="line">DNS1=202.114.0.242</span><br><span class="line">IPADDR=10.0.0.1</span><br><span class="line">PREFIX=24</span><br><span class="line">GATEWAY=10.0.0.1</span><br></pre></td></tr></table></figure><h3 id="2-配置系统内核实现ipv4转发"><a href="#2-配置系统内核实现ipv4转发" class="headerlink" title="2. 配置系统内核实现ipv4转发"></a>2. 配置系统内核实现ipv4转发</h3><p><code>sudo vim /etc/sysctl.conf</code></p><p>添加如下内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Controls IP packet forwarding</span></span><br><span class="line">net.ipv4.ip_forward = 1</span><br></pre></td></tr></table></figure><p>如果需要不重启实现ipv4转发功能可以使用如下指令</p><p><code>sysctl -w net.ipv4.ip_forward=1</code></p><h3 id="3-修改iptables转发规则"><a href="#3-修改iptables转发规则" class="headerlink" title="3. 修改iptables转发规则"></a>3. 修改iptables转发规则</h3><p>运行如下指令</p><p><code>sudo iptables -t nat -A POSTROUTING -s 10.0.0.0/24 -o enp15s0 -j SNAT --to XXX.XXX.XXX.XXX</code></p><p><code>iptables -A OUTPUT -p tcp --dport 53 -j ACCEPT</code></p><p><code>iptables -A OUTPUT -p udp --dport 53 -j ACCEPT</code></p><p>保存iptables配置的结果防止重启失效</p><p><code>sudo iptables-save</code></p><h3 id="4-其他一些关于网络的问题"><a href="#4-其他一些关于网络的问题" class="headerlink" title="4. 其他一些关于网络的问题"></a>4. 其他一些关于网络的问题</h3><ul><li>多网卡机器1号网卡作为内网网段，2号网卡作为外网网段不能上网的问题，可以通过修改默认路由来实现。一般来说，默认路由为1号网卡（如果没有配置的话），设置路由使用route指令，route指令说明如下：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Usage: route [-nNvee] [-FC] [&lt;AF&gt;]           List kernel routing tables</span><br><span class="line">       route [-v] [-FC] &#123;add|del|flush&#125; ...  Modify routing table for AF.</span><br><span class="line"></span><br><span class="line">       route &#123;-h|--help&#125; [&lt;AF&gt;]              Detailed usage syntax for specified AF.</span><br><span class="line">       route &#123;-V|--version&#125;                  Display version/author and exit.</span><br><span class="line"></span><br><span class="line">        -v, --verbose            be verbose</span><br><span class="line">        -n, --numeric            don&apos;t resolve names</span><br><span class="line">        -e, --extend             display other/more information</span><br><span class="line">        -F, --fib                display Forwarding Information Base (default)</span><br><span class="line">        -C, --cache              display routing cache instead of FIB</span><br><span class="line"></span><br><span class="line">  &lt;AF&gt;=Use -4, -6, &apos;-A &lt;af&gt;&apos; or &apos;--&lt;af&gt;&apos;; default: inet</span><br><span class="line">  List of possible address families (which support routing):</span><br><span class="line">    inet (DARPA Internet) inet6 (IPv6) ax25 (AMPR AX.25)</span><br><span class="line">    netrom (AMPR NET/ROM) ipx (Novell IPX) ddp (Appletalk DDP)</span><br><span class="line">    x25 (CCITT X.25)</span><br></pre></td></tr></table></figure><p>使用如下指令来添加默认路由：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo route add default gw 10.0.0.1</span><br></pre></td></tr></table></figure><p>将默认网关设置为10.0.0.1这个上网的网段即可上网</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MPI常用函数及数据类型</title>
      <link href="/2016/10/21/MPI/MPI%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E5%8F%8A%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"/>
      <url>/2016/10/21/MPI/MPI%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E5%8F%8A%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<p>其他MPI中会用到的函数数据类型：</p><ul><li><code>MPI_Barrier</code> - <code>int MPI_Barrier( MPI_Comm comm )</code>阻塞执行到当前位置的处理程序，直到communicator中所有处理程序都到达该位置</li><li><code>MPI_Wtime</code> - <code>double MPI_Wtime( void )</code>返回调用这个函数的进程节点从创建开始经过的时间</li><li><code>MPI_Type_size</code> - <code>int MPI_Type_size(MPI_Datatype datatype, int *size)</code>返回datatype所占有的字节数</li><li><code>MPI_Send</code> - <code>int MPI_Send(const void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm)</code>MPI发送数据函数，buf为发送缓冲区的起始地址，count为将发送的数据的个数，datatype为发送数据的数据类型，dest为目的进程的标识号，tag为消息标志，comm为通信域，该函数的返回值为MPI_SUCCESS时表示发送成功</li><li><code>MPI_Irecv</code> = <code>int MPI_Irecv(void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status *status)</code>MPI接受数据函数，buf为接受缓冲区的起始地址，count为最多可接受的数据个数，datatype为接收数据的数据类型，source为接受数据的来源即发送数据的进程的进程标识号，tag为消息标识，与相应的发送操作的表示相匹配，comm为本进程和发送进程所在的通信域，status为返回状态<a id="more"></a></li><li><code>MPI_Bcast</code> - <code>int MPI_Bcast( void *buffer, int count, MPI_Datatype datatype, int root, MPI_Comm comm )</code>从进程rank号为root的进程向通信域中的其他进程发送一条广播消息</li><li><code>MPI_Datatype</code> - MPI数据类型枚举</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">enum</span> _MPI_Datatype &#123;</span><br><span class="line">  MPI_DATATYPE_NULL          = <span class="number">0x0c000000</span>,</span><br><span class="line">  MPI_CHAR                   = <span class="number">0x4c000101</span>,</span><br><span class="line">  MPI_UNSIGNED_CHAR          = <span class="number">0x4c000102</span>,</span><br><span class="line">  MPI_SHORT                  = <span class="number">0x4c000203</span>,</span><br><span class="line">  MPI_UNSIGNED_SHORT         = <span class="number">0x4c000204</span>,</span><br><span class="line">  MPI_INT                    = <span class="number">0x4c000405</span>,</span><br><span class="line">  MPI_UNSIGNED               = <span class="number">0x4c000406</span>,</span><br><span class="line">  MPI_LONG                   = <span class="number">0x4c000407</span>,</span><br><span class="line">  MPI_UNSIGNED_LONG          = <span class="number">0x4c000408</span>,</span><br><span class="line">  MPI_LONG_LONG_INT          = <span class="number">0x4c000809</span>,</span><br><span class="line">  MPI_LONG_LONG              = MPI_LONG_LONG_INT,</span><br><span class="line">  MPI_FLOAT                  = <span class="number">0x4c00040a</span>,</span><br><span class="line">  MPI_DOUBLE                 = <span class="number">0x4c00080b</span>,</span><br><span class="line">  MPI_LONG_DOUBLE            = <span class="number">0x4c00080c</span>,</span><br><span class="line">  MPI_BYTE                   = <span class="number">0x4c00010d</span>,</span><br><span class="line">  MPI_WCHAR                  = <span class="number">0x4c00020e</span>,</span><br><span class="line">  MPI_PACKED                 = <span class="number">0x4c00010f</span>,</span><br><span class="line">  MPI_LB                     = <span class="number">0x4c000010</span>,</span><br><span class="line">  MPI_UB                     = <span class="number">0x4c000011</span>,</span><br><span class="line">  MPI_C_COMPLEX              = <span class="number">0x4c000812</span>,</span><br><span class="line">  MPI_C_FLOAT_COMPLEX        = <span class="number">0x4c000813</span>,</span><br><span class="line">  MPI_C_DOUBLE_COMPLEX       = <span class="number">0x4c001614</span>,</span><br><span class="line">  MPI_C_LONG_DOUBLE_COMPLEX  = <span class="number">0x4c001615</span>,</span><br><span class="line">  MPI_2INT                   = <span class="number">0x4c000816</span>,</span><br><span class="line">  MPI_C_BOOL                 = <span class="number">0x4c000117</span>,</span><br><span class="line">  MPI_SIGNED_CHAR            = <span class="number">0x4c000118</span>,</span><br><span class="line">  MPI_UNSIGNED_LONG_LONG     = <span class="number">0x4c000819</span>,</span><br><span class="line">  MPI_CHARACTER              = <span class="number">0x4c00011a</span>,</span><br><span class="line">  MPI_INTEGER                = <span class="number">0x4c00041b</span>,</span><br><span class="line">  MPI_REAL                   = <span class="number">0x4c00041c</span>,</span><br><span class="line">  MPI_LOGICAL                = <span class="number">0x4c00041d</span>,</span><br><span class="line">  MPI_COMPLEX                = <span class="number">0x4c00081e</span>,</span><br><span class="line">  MPI_DOUBLE_PRECISION       = <span class="number">0x4c00081f</span>,</span><br><span class="line">  MPI_2INTEGER               = <span class="number">0x4c000820</span>,</span><br><span class="line">  MPI_2REAL                  = <span class="number">0x4c000821</span>,</span><br><span class="line">  MPI_DOUBLE_COMPLEX         = <span class="number">0x4c001022</span>,</span><br><span class="line">  MPI_2DOUBLE_PRECISION      = <span class="number">0x4c001023</span>,</span><br><span class="line">  MPI_2COMPLEX               = <span class="number">0x4c001024</span>,</span><br><span class="line">  MPI_2DOUBLE_COMPLEX        = <span class="number">0x4c002025</span>,</span><br><span class="line">  MPI_REAL2                  = MPI_DATATYPE_NULL,</span><br><span class="line">  MPI_REAL4                  = <span class="number">0x4c000427</span>,</span><br><span class="line">  MPI_COMPLEX8               = <span class="number">0x4c000828</span>,</span><br><span class="line">  MPI_REAL8                  = <span class="number">0x4c000829</span>,</span><br><span class="line">  MPI_COMPLEX16              = <span class="number">0x4c00102a</span>,</span><br><span class="line">  MPI_REAL16                 = MPI_DATATYPE_NULL,</span><br><span class="line">  MPI_COMPLEX32              = MPI_DATATYPE_NULL,</span><br><span class="line">  MPI_INTEGER1               = <span class="number">0x4c00012d</span>,</span><br><span class="line">  MPI_COMPLEX4               = MPI_DATATYPE_NULL,</span><br><span class="line">  MPI_INTEGER2               = <span class="number">0x4c00022f</span>,</span><br><span class="line">  MPI_INTEGER4               = <span class="number">0x4c000430</span>,</span><br><span class="line">  MPI_INTEGER8               = <span class="number">0x4c000831</span>,</span><br><span class="line">  MPI_INTEGER16              = MPI_DATATYPE_NULL,</span><br><span class="line">  MPI_INT8_T                 = <span class="number">0x4c000133</span>,</span><br><span class="line">  MPI_INT16_T                = <span class="number">0x4c000234</span>,</span><br><span class="line">  MPI_INT32_T                = <span class="number">0x4c000435</span>,</span><br><span class="line">  MPI_INT64_T                = <span class="number">0x4c000836</span>,</span><br><span class="line">  MPI_UINT8_T                = <span class="number">0x4c000137</span>,</span><br><span class="line">  MPI_UINT16_T               = <span class="number">0x4c000238</span>,</span><br><span class="line">  MPI_UINT32_T               = <span class="number">0x4c000439</span>,</span><br><span class="line">  MPI_UINT64_T               = <span class="number">0x4c00083a</span>,</span><br><span class="line">  MPI_AINT                   = <span class="number">0x4c00083b</span> (_WIN64), <span class="number">0x4c00043b</span>,</span><br><span class="line">  MPI_OFFSET                 = <span class="number">0x4c00083c</span>,</span><br><span class="line">  MPI_FLOAT_INT              = <span class="number">0x8c000000</span>,</span><br><span class="line">  MPI_DOUBLE_INT             = <span class="number">0x8c000001</span>,</span><br><span class="line">  MPI_LONG_INT               = <span class="number">0x8c000002</span>,</span><br><span class="line">  MPI_SHORT_INT              = <span class="number">0x8c000003</span>,</span><br><span class="line">  MPI_LONG_DOUBLE_INT        = <span class="number">0x8c000004</span></span><br><span class="line">&#125; MPI_Datatype;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MPI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MPI的helloworld教程</title>
      <link href="/2016/10/21/MPI/MPI%E7%9A%84helloworld%E6%95%99%E7%A8%8B/"/>
      <url>/2016/10/21/MPI/MPI%E7%9A%84helloworld%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mpi.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Initialize the MPI environment</span></span><br><span class="line">    MPI_Init(<span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Get the number of processes</span></span><br><span class="line">    <span class="keyword">int</span> world_size;</span><br><span class="line">    MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Get the rank of the process</span></span><br><span class="line">    <span class="keyword">int</span> world_rank;</span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Get the name of the processor</span></span><br><span class="line">    <span class="keyword">char</span> processor_name[MPI_MAX_PROCESSOR_NAME];</span><br><span class="line">    <span class="keyword">int</span> name_len;</span><br><span class="line">    MPI_Get_processor_name(processor_name, &amp;name_len);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Print off a hello world message</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"Hello world from processor %s, rank %d"</span></span><br><span class="line">           <span class="string">" out of %d processors\n"</span>,</span><br><span class="line">           processor_name, world_rank, world_size);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Finalize the MPI environment.</span></span><br><span class="line">    MPI_Finalize();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><a id="more"></a><p>MPI程序首先需要includeMPI的头文件<code>#include &lt;mpi.h&gt;</code>，之后，MPI环境需要使用如下语句进行初始化</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MPI_Init(</span><br><span class="line"><span class="keyword">int</span>* argc,</span><br><span class="line"><span class="keyword">char</span>*** argv)</span><br></pre></td></tr></table></figure><p><code>MPI_Init</code>之后，所有的MPI需要的全局和内部变量都会被创建完成，例如会产生一个通信域communicator负责所有产生的进程之间的通信，并且每一个MPI进程都会有一个唯一的rank值产生。<br><code>MPI_Init</code>之后，一般会调用两个函数</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MPI_Comm_size(</span><br><span class="line">MPI_Comm communicator,</span><br><span class="line"><span class="keyword">int</span>* <span class="built_in">size</span>)</span><br></pre></td></tr></table></figure><p><code>MPI_Comm_size</code>会返回communicator的大小，<code>MPI_COMM_WORLD</code>（由MPI产生）封装了所有MPI job中的进程，因此这个函数的调用会返回MPI job中所需要的进程的数量。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MPI_Comm_rank(</span><br><span class="line">MPI_Comm communicator,</span><br><span class="line"><span class="keyword">int</span>* rank)</span><br></pre></td></tr></table></figure><p><code>MPI_Comm_rank</code>返回在一个communicator中某一个节点的rank值。在communicator中的每一个进程都会被赋予一个从0开始递增的rank值。所有进程的rank值主要作用为在发送和接受信息时起到标识的作用。<br>在这个例子中用到了一个使用很少的函数</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MPI_Get_processor_name(</span><br><span class="line"><span class="keyword">char</span>* name,</span><br><span class="line"><span class="keyword">int</span>* name_length)</span><br></pre></td></tr></table></figure><p><code>MPI_Get_processor_name</code>获得正在执行的进程的真实名字，这个程序最后会执行</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MPI_Finalize()</span><br></pre></td></tr></table></figure><p><code>MPI_Finalize</code>的作用是情理MPI环境，这个函数调用之后，MPI的其他操作将不能再继续调用</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MPI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Django连接mysql数据库</title>
      <link href="/2016/10/17/Django/Django%E8%BF%9E%E6%8E%A5mysql%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
      <url>/2016/10/17/Django/Django%E8%BF%9E%E6%8E%A5mysql%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<h3 id="使用pymysql替代MySQLdb"><a href="#使用pymysql替代MySQLdb" class="headerlink" title="使用pymysql替代MySQLdb"></a>使用pymysql替代MySQLdb</h3><p>Django与mysql进行连接使用的是MySQLdb模块，但是该模块并不支持python3，需要使用别的库来替代MySQLdb，这里采用的是pymysql，可以使用pip来安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install pymysql</span><br></pre></td></tr></table></figure><p>之后在Django的站点文件夹中的<strong>init</strong>.py文件夹中添加如下代码即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line">pymysql.install_as_MySQLdb()</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="修改setting-py文件"><a href="#修改setting-py文件" class="headerlink" title="修改setting.py文件"></a>修改setting.py文件</h3><p>在setting.py文件中修改DATABASES中的内容如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DATABASES = &#123;</span><br><span class="line"><span class="string">'default'</span>: &#123;</span><br><span class="line">        <span class="string">'ENGINE'</span>: <span class="string">'django.db.backends.mysql'</span>,</span><br><span class="line">        <span class="string">'NAME'</span>: <span class="string">'&lt;database_name&gt;'</span>,</span><br><span class="line">        <span class="string">'USER'</span>: <span class="string">'&lt;user_name&gt;'</span>,</span><br><span class="line">        <span class="string">'PASSWORD'</span>: <span class="string">'&lt;password&gt;'</span>,</span><br><span class="line">        <span class="string">'HOST'</span>: <span class="string">'&lt;ip_address&gt;'</span>,</span><br><span class="line">        <span class="string">'PORT'</span>: <span class="string">'&lt;port_num&gt;'</span>,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="添加测试表"><a href="#添加测试表" class="headerlink" title="添加测试表"></a>添加测试表</h3><p>使用startapp users命令来新建一个名称为users的app，并在users文件夹中的models.py文件中添加如下内容进行测试</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.db <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    username = models.CharField(max_length=<span class="number">32</span>)</span><br><span class="line">    password = models.CharField(max_length=<span class="number">32</span>)</span><br><span class="line">    nickname = models.CharField(max_length=<span class="number">200</span>)</span><br></pre></td></tr></table></figure><p>通过以上代码，会在数据库中创建一个叫users_user的表，表中有三个字段为username、password和nickname，字段的类型、特性可以在新建字段时进行设置</p><h3 id="manage-py运行命令"><a href="#manage-py运行命令" class="headerlink" title="manage.py运行命令"></a>manage.py运行命令</h3><p>首先运行如下命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 manage.py makemigrations users</span><br></pre></td></tr></table></figure><p>通过运行makemigrations，可以告诉Django框架在users中model有所改变，使得这些改变会被作为migration进行存储。Migration是Django用于存储model的变化，只是在硬盘上存储的文件，可以从硬盘当中读取migration文件进行查看。例如上例中产生的migration文件存储在<code>users/migrations/0001_initial.py</code>当中，可以通过如下命令查看其中的SQL语句内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 manage.py sqlmigrate users 0001</span><br></pre></td></tr></table></figure><p>要想在数据库中真正创建上例中的表，需要运行如下命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 manage.py migrate</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>三个步骤来改变数据库结构</p><ul><li>在model.py中改变数据库结构</li><li>运行命令<code>python3 manage.py makemigrations</code>来对改变创建migration文件</li><li>运行命令<code>python3 manage.py migrate</code>来应用这些改变到数据库中</li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在pycharm上运行pyspark程序</title>
      <link href="/2016/06/28/spark/%E5%9C%A8pycharm%E4%B8%8A%E8%BF%90%E8%A1%8Cpyspark%E7%A8%8B%E5%BA%8F/"/>
      <url>/2016/06/28/spark/%E5%9C%A8pycharm%E4%B8%8A%E8%BF%90%E8%A1%8Cpyspark%E7%A8%8B%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<h3 id="配置pycharm"><a href="#配置pycharm" class="headerlink" title="配置pycharm"></a>配置pycharm</h3><ol><li>在pycharm上创建project之后，在Run-&gt;Edit Configurations-&gt;Environment variables中添加两个环境变量：<br><code>PYTHONPATH = /opt/spark/spark1.6.2/python</code><br><code>SPARK_HOME = /opt/spark/spark1.6.2</code><a id="more"></a></li><li>将<code>spark/python</code>目录中的pyspark目录拷贝到工程文件夹中</li></ol><h3 id="编写pyspark程序"><a href="#编写pyspark程序" class="headerlink" title="编写pyspark程序"></a>编写pyspark程序</h3><ol><li>pyspark程序中经常会用到一个变量sqlContext，这个变量一般是通过<code>sqlContext = SQLContext(sc)</code>生成的，变量<code>sc</code>是一个pyspark的shenll自动生成的helper变量</li><li>在pyspark的shell中，这个变量是会自动生成作为helper变量的，但是在pycharm编写的程序中需要自己去定义这个变量：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SQLContext</span><br><span class="line">conf = SparkConf().setAppName(<span class="string">"berkeleySpark"</span>)</span><br><span class="line">sc = SparkContext(conf=conf)</span><br><span class="line">sqlContext = SQLContext(sc)</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>sudo不需要使用密码</title>
      <link href="/2016/06/17/linux/sudo%E4%B8%8D%E9%9C%80%E8%A6%81%E4%BD%BF%E7%94%A8%E5%AF%86%E7%A0%81/"/>
      <url>/2016/06/17/linux/sudo%E4%B8%8D%E9%9C%80%E8%A6%81%E4%BD%BF%E7%94%A8%E5%AF%86%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<p>在使用linux时，sudo指令是经常会用到的，但是这个加sudo之后经常需要输入密码十分不便，可以通过设置来使加sudo的指令不需要密码，编辑<code>/etc/sudoer</code>文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/sudoers</span><br></pre></td></tr></table></figure><p>在其中<code>root    ALL=(ALL:ALL) ALL</code>后加一行<code>hadoop    ALL=NOPASSWD:ALL</code>，即可使hadoop用户sudo不需要密码，其他用户的设置类似</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ubuntu安装mysql5.7</title>
      <link href="/2016/06/17/mysql/ubuntu%E5%AE%89%E8%A3%85mysql5.7/"/>
      <url>/2016/06/17/mysql/ubuntu%E5%AE%89%E8%A3%85mysql5.7/</url>
      
        <content type="html"><![CDATA[<h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><p>1.下载mysql5.7源码进行编译安装： <a href="http://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.13.tar.gz" target="_blank" rel="noopener">http://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.13.tar.gz</a><br>2.安装必备的包和工具</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install build-essential</span><br><span class="line">sudo apt install cmake</span><br><span class="line">sudo apt install bison</span><br><span class="line">sudo apt install libncurses5-dev</span><br></pre></td></tr></table></figure><p>  编译安装zlib（安装nginx时一般已经安装）<br>3.安装功能需要的包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install libxml</span><br><span class="line">sudo apt install openssl</span><br></pre></td></tr></table></figure><p>4.下载Boost库<br>从mysql5.7.5开始Boost库是必须的，一般需要的版本为1_59_0，下载地址为： <a href="http://mirrors.sohu.com/mysql/MySQL-5.7/mysql-5.7.10.tar.gz" target="_blank" rel="noopener">http://mirrors.sohu.com/mysql/MySQL-5.7/mysql-5.7.10.tar.gz</a><br>下载后解压到与mysql源码相同的目录处</p><a id="more"></a><p>5.直接安装mysql在后续操作中可能会出现启动mysql段错误的情况，需要在编译修改源代码来解决<br>在源码包中，找到<code>cmd-line-utils/libedit/terminal.c</code>，找到其中<code>area = buf</code>的语句，将其改为<code>area = NULL</code>即可</p><h3 id="创建用户组和用户"><a href="#创建用户组和用户" class="headerlink" title="创建用户组和用户"></a>创建用户组和用户</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo groupadd mysql</span><br><span class="line">sudo useradd mysql</span><br></pre></td></tr></table></figure><h3 id="源码编译及安装"><a href="#源码编译及安装" class="headerlink" title="源码编译及安装"></a>源码编译及安装</h3><p>1.mysql采用cmake的方式进行编译，编译指令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cmake \</span><br><span class="line">-DCMAKE_INSTALL_PREFIX=/usr/local/mysql \</span><br><span class="line">-DMYSQL_DATADIR=/usr/local/mysql/data \</span><br><span class="line">-DSYSCONFDIR=/etc \</span><br><span class="line">-DWITH_MYISAM_STORAGE_ENGINE=1 \</span><br><span class="line">-DWITH_INNOBASE_STORAGE_ENGINE=1 \</span><br><span class="line">-DWITH_MEMORY_STORAGE_ENGINE=1 \</span><br><span class="line">-DWITH_READLINE=1 \</span><br><span class="line">-DMYSQL_UNIX_ADDR=/var/lib/mysql/mysql.sock \</span><br><span class="line">-DMYSQL_TCP_PORT=3306 \</span><br><span class="line">-DENABLED_LOCAL_INFILE=1 \</span><br><span class="line">-DWITH_PARTITION_STORAGE_ENGINE=1 \</span><br><span class="line">-DEXTRA_CHARSETS=all \</span><br><span class="line">-DDEFAULT_CHARSET=utf8 \</span><br><span class="line">-DDEFAULT_COLLATION=utf8_general_ci \</span><br><span class="line">-DDOWNLOAD_BOOST=1 \</span><br><span class="line">-DWITH_BOOST=../boost_1_59_0</span><br></pre></td></tr></table></figure><p>2.编译完成之后，使用<code>make</code>及<code>make install</code>指令进行安装</p><h3 id="配置mysql"><a href="#配置mysql" class="headerlink" title="配置mysql"></a>配置mysql</h3><p>1.安装完成之后，将安装目录的所有者改为mysql</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chown -R mysql:mysql /usr/local/mysql</span><br></pre></td></tr></table></figure><p>2.复制配置文件到系统<code>etc</code>目录下，并修改所有者为mysql</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /usr/local/mysql/support-files/my-default.cnf /etc/my.cnf</span><br></pre></td></tr></table></figure><p>修改其中的内容如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">basedir = /usr/local/mysql</span><br><span class="line">datadir = /usr/local/mysql/data</span><br><span class="line">port = 3306</span><br></pre></td></tr></table></figure><p>3.配置mysql开机启动，将mysql.server文件复制到系统<code>etc/init.d</code>目录当中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysql</span><br><span class="line">sudo chmod +x /etc/init.d/mysql</span><br><span class="line">sudo update-rc.d -f mysql defaults</span><br></pre></td></tr></table></figure><h3 id="初始化数据库"><a href="#初始化数据库" class="headerlink" title="初始化数据库"></a>初始化数据库</h3><p>从mysql5.7开始，之前的mysql_install_db已经被废弃了，需采用新的指令进行数据库初始化操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo /usr/local/mysql/bin/mysqld \</span><br><span class="line">--initialize-insecure \</span><br><span class="line">--user=mysql \</span><br><span class="line">--basedir=/usr/local/mysql \</span><br><span class="line">--datadir=/usr/local/mysql/data</span><br></pre></td></tr></table></figure><p>需要注意的是：<br>–initialize会生成一个随机密码(~/.mysql_secret)<br>–initialize-insecure不生成密码<br>–datadir目标目录下不能有数据文件</p><h3 id="开启mysql服务"><a href="#开启mysql服务" class="headerlink" title="开启mysql服务"></a>开启mysql服务</h3><p>开启mysql</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service mysql start</span><br></pre></td></tr></table></figure><h3 id="修改数据库密码"><a href="#修改数据库密码" class="headerlink" title="修改数据库密码"></a>修改数据库密码</h3><p>之后可以使用<code>mysql -uroot -p</code>输入空密码进入mysql，采用如下语句修改mysql的密码</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> <span class="keyword">password</span> <span class="keyword">for</span> root@localhost = <span class="keyword">password</span>(<span class="string">'123'</span>);</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql赋给用户权限</title>
      <link href="/2016/06/17/mysql/mysql%E8%B5%8B%E7%BB%99%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/"/>
      <url>/2016/06/17/mysql/mysql%E8%B5%8B%E7%BB%99%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/</url>
      
        <content type="html"><![CDATA[<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">privileges</span> <span class="keyword">on</span> &lt;dbname&gt;.* <span class="keyword">to</span> <span class="string">'&lt;username&gt;'</span>@<span class="string">'localhost'</span> <span class="keyword">identified</span> <span class="keyword">by</span> <span class="string">'&lt;password&gt;'</span>;</span><br><span class="line"><span class="keyword">flush</span> <span class="keyword">privileges</span>;</span><br></pre></td></tr></table></figure><a id="more"></a><p><dbname>为想要共享的数据库名称，如果想共享所有的数据库，则为*号<br><username>为共享的用户名，如果该用户不存在，mysql会自动创建该用户，可以进入mysql数据库的user表查看，标识用户的信息除了用户名User，还包含有Host<br>localhost处可以替换为具体的ip地址，则代表只有该ip用该用户名才能访问，如果希望所有ip的用户都能通过该用户名访问，则将localhost替换为%号，identified by之后跟的是登录的密码</username></dbname></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CI3.0.2支持smarty3.1.29</title>
      <link href="/2016/06/02/php/CI3-0-2%E6%94%AF%E6%8C%81smarty3-1-29/"/>
      <url>/2016/06/02/php/CI3-0-2%E6%94%AF%E6%8C%81smarty3-1-29/</url>
      
        <content type="html"><![CDATA[<ol><li>下载smarty并解压复制libs文件夹到CI的applica/libraries文件夹中，将libs文件夹重命名为smarty</li><li>在application/libraries文件夹下新建Ci_smarty.php文件，在其中加入以下代码：</li></ol><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(!defined(<span class="string">'BASEPATH'</span>)) <span class="keyword">exit</span>(<span class="string">'No direct script access allowed'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">require</span>(APPPATH.<span class="string">'libraries/smarty/Smarty.class.php'</span>);</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Ci_smarty</span> <span class="keyword">extends</span> <span class="title">Smarty</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> $ci;</span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">__construct</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">parent</span>::__construct();</span><br><span class="line">        <span class="keyword">$this</span>-&gt;ci = &amp; get_instance();</span><br><span class="line">        <span class="keyword">$this</span>-&gt;ci-&gt;load-&gt;config(<span class="string">'smarty'</span>);<span class="comment">//加载smarty的配置文件</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取相关的配置项</span></span><br><span class="line">        <span class="keyword">$this</span>-&gt;cache_lifetime  = <span class="keyword">$this</span>-&gt;ci-&gt;config-&gt;item(<span class="string">'cache_lifetime'</span>);</span><br><span class="line">        <span class="keyword">$this</span>-&gt;caching         = <span class="keyword">$this</span>-&gt;ci-&gt;config-&gt;item(<span class="string">'caching'</span>);</span><br><span class="line">        <span class="keyword">$this</span>-&gt;template_dir    = <span class="keyword">$this</span>-&gt;ci-&gt;config-&gt;item(<span class="string">'template_dir'</span>);</span><br><span class="line">        <span class="keyword">$this</span>-&gt;compile_dir     = <span class="keyword">$this</span>-&gt;ci-&gt;config-&gt;item(<span class="string">'compile_dir'</span>);</span><br><span class="line">        <span class="keyword">$this</span>-&gt;cache_dir       = <span class="keyword">$this</span>-&gt;ci-&gt;config-&gt;item(<span class="string">'cache_dir'</span>);</span><br><span class="line">        <span class="keyword">$this</span>-&gt;use_sub_dirs    = <span class="keyword">$this</span>-&gt;ci-&gt;config-&gt;item(<span class="string">'use_sub_dirs'</span>);</span><br><span class="line">        <span class="keyword">$this</span>-&gt;left_delimiter  = <span class="keyword">$this</span>-&gt;ci-&gt;config-&gt;item(<span class="string">'left_delimiter'</span>);</span><br><span class="line">        <span class="keyword">$this</span>-&gt;right_delimiter = <span class="keyword">$this</span>-&gt;ci-&gt;config-&gt;item(<span class="string">'right_delimiter'</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><a id="more"></a><ol start="3"><li>在application/config目录下新建smarty.php文件，在其中加入以下代码：</li></ol><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(!defined(<span class="string">'BASEPATH'</span>)) <span class="keyword">exit</span>(<span class="string">'No direct script access allowed'</span>);</span><br><span class="line"></span><br><span class="line">$config[<span class="string">'cache_lifetime'</span>]   = <span class="number">30</span>*<span class="number">24</span>*<span class="number">3600</span>;</span><br><span class="line">$config[<span class="string">'caching'</span>]          = <span class="keyword">false</span>;</span><br><span class="line">$config[<span class="string">'template_dir'</span>]     = APPPATH .<span class="string">'views'</span>;</span><br><span class="line">$config[<span class="string">'compile_dir'</span>]      = APPPATH .<span class="string">'views/template_c'</span>;</span><br><span class="line">$config[<span class="string">'cache_dir'</span>]        = APPPATH . <span class="string">'views/cache'</span>;</span><br><span class="line">$config[<span class="string">'use_sub_dirs'</span>]     = <span class="keyword">false</span>;<span class="comment">//子目录变量(是否在缓存文件夹中生成子目录)</span></span><br><span class="line">$config[<span class="string">'left_delimiter'</span>]   = <span class="string">'&#123;'</span>;</span><br><span class="line">$config[<span class="string">'right_delimiter'</span>]  = <span class="string">'&#125;'</span>;</span><br></pre></td></tr></table></figure><ol start="4"><li>在application/core目录下新建MY_Controller.php文件，在其中加入以下代码：</li></ol><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!defined(<span class="string">'BASEPATH'</span>)) <span class="keyword">exit</span>(<span class="string">'No direct access allowed.'</span>);</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MY_Controller</span> <span class="keyword">extends</span> <span class="title">CI_Controller</span></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">__construct</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">parent</span>::__construct();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">assign</span><span class="params">($key,$val)</span></span>&#123;</span><br><span class="line"><span class="keyword">$this</span>-&gt;ci_smarty-&gt;assign($key,$val);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">display</span><span class="params">($html)</span></span>&#123;</span><br><span class="line"><span class="keyword">$this</span>-&gt;ci_smarty-&gt;display($html);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="5"><li><p>在application/config/autoload.php文件中找到<code>$autoload[&#39;libraries&#39;]=array();</code>，在其中加入对Ci_smarty类的自动加载</p></li><li><p>使用以下方法测试CI是否支持smarty，修改application/controller/Welcome.php如下所示：</p></li></ol><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="keyword">if</span> ( ! defined(<span class="string">'BASEPATH'</span>)) <span class="keyword">exit</span>(<span class="string">'No direct script access allowed'</span>);</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Welcome</span> <span class="keyword">extends</span> <span class="title">MY_Controller</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">index</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        $test=<span class="string">'ci 3.0.2 + smarty 3.1.29 配置成功'</span>;</span><br><span class="line">        <span class="keyword">$this</span>-&gt;assign(<span class="string">'test'</span>,$test);</span><br><span class="line">        <span class="keyword">$this</span>-&gt;display(<span class="string">'test.html'</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在application/views下新建smarty_test.html，在其中加入以下代码：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">xmlns</span>=<span class="string">"http://www.w3.org/1999/xhtml"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">"Content-Type"</span> <span class="attr">content</span>=<span class="string">"text/html; charset=utf-8"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>smarty配置测试<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">&#123;$test&#125;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>若能正确输出结果，则说明配置正确</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PHP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java中StringTokenizer学习</title>
      <link href="/2016/04/13/java/java%E4%B8%ADStringTokenizer%E5%AD%A6%E4%B9%A0/"/>
      <url>/2016/04/13/java/java%E4%B8%ADStringTokenizer%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<p>在平时编程中经常会遇到对字符串进行拆分的情况，例如有些字符串代表了许多组数据，这些数据以‘,’进行分隔，需要将这些数据单独提取出来，以前总是自己去写拆分函数，十分不方便。最近发现java中有一个类叫<code>StringTokenizer</code>可以很轻松地解决这个问题。</p><p>先来看看官方API文档对<code>StringTokenizer</code>的解释：</p><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The string tokenizer class allows an application to break a string into tokens.</span><br></pre></td></tr></table></figure><a id="more"></a><p>也就是说这个类能够使我们将一个字符串拆分成小部分。官方给出了一个使用该类的例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">StringTokenizer st = <span class="keyword">new</span> StringTokenizer(<span class="string">"this is a test"</span>);</span><br><span class="line">     <span class="keyword">while</span> (st.hasMoreTokens()) &#123;</span><br><span class="line">         System.out.println(st.nextToken());</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure><p>该段函数输出的内容为：</p><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">this</span><br><span class="line">is</span><br><span class="line">a</span><br><span class="line">test</span><br></pre></td></tr></table></figure><p>StringTokenizer将英文句子以空格为分隔拆分成了单个单词。以上的这种方法在之前可以用字符串数组的<code>split</code>方法进行实现，如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">String[] result = <span class="string">"this is a test"</span>.split(<span class="string">"\\s"</span>);</span><br><span class="line">     <span class="keyword">for</span> (<span class="keyword">int</span> x=<span class="number">0</span>; x&lt;result.length; x++)</span><br><span class="line">         System.out.println(result[x]);</span><br></pre></td></tr></table></figure><p>这两种方法输出的结果是一致的，但是<code>StringTokenizer</code>的方法和功能远不止这一种，还有许多新的更方便的功能。<br><code>StringTokenizer</code>一共有3种构造函数：</p><ol><li><code>StringTokenizer(String str)</code><br>Constructs a string tokenizer for the specified string.</li><li><code>StringTokenizer(String str, String delim)</code><br>Constructs a string tokenizer for the specified string.</li><li><code>StringTokenizer(String str, String delim, boolean returnDelims)</code><br>Constructs a string tokenizer for the specified string.<br>这三种构造函数的功能显而易见，第一种使用了默认的分隔符对字符串进行分割，默认的分隔符有<code>\t\n\r\f</code>，分别为空格（space character）、Tab制表符（tab character）、换行符（newline character）、回车符（carriage-return character）、换页符（form-feed character）。第二种和第三种指定了分隔符，并且第三种返回的Token中可以选择是否包含分隔符，若选择包含分隔符，分割符将会被当做一个长度为1的字符串单独作为一个Token。</li></ol><p><code>StringTokenizer</code>有6种方法：</p><ol><li><code>public boolean hasMoreTokens()</code><br>测试是否有更多的Token</li><li><code>public String nextToken()</code><br>返回下一个字符串Token</li><li><code>public String nextToken(String delim)</code><br>按照指定的分隔符返回下一个Token</li><li><code>public boolean hasMoreElements</code><br>功能与第一种方法完全相同，只是为了实现Enumeration的接口</li><li><code>public Object nextElement()</code><br>功能与第二种方法完全相同，只是为了实现Enumeration的接口</li><li><code>public int countTokens()</code><br>返回拆分的Token数量</li></ol>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>将毫秒数转化为用年日小时分秒毫秒表示</title>
      <link href="/2016/04/12/java/%E5%B0%86%E6%AF%AB%E7%A7%92%E6%95%B0%E8%BD%AC%E5%8C%96%E4%B8%BA%E5%B9%B4%E6%97%A5%E5%B0%8F%E6%97%B6%E5%88%86%E7%A7%92%E6%AF%AB%E7%A7%92/"/>
      <url>/2016/04/12/java/%E5%B0%86%E6%AF%AB%E7%A7%92%E6%95%B0%E8%BD%AC%E5%8C%96%E4%B8%BA%E5%B9%B4%E6%97%A5%E5%B0%8F%E6%97%B6%E5%88%86%E7%A7%92%E6%AF%AB%E7%A7%92/</url>
      
        <content type="html"><![CDATA[<p>在编写程序时经常会需要读取系统的时间，但是大多数语言获取的时间都是距1970年1月1日的毫秒数，十分不方便，在hadoop给出的计算<code>π</code>值的mapreduce例子中有一个millis2string函数能将毫秒数转化为年日小时分秒毫秒显示的String，书写十分简洁，值得学习借鉴。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Covert milliseconds to a String. */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">millis2String</span><span class="params">(<span class="keyword">long</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n &lt; <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="string">"-"</span> + millis2String(-n);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (n &lt; <span class="number">1000</span>)</span><br><span class="line">      <span class="keyword">return</span> n + <span class="string">"ms"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> StringBuilder b = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> millis = (<span class="keyword">int</span>)(n % <span class="number">1000L</span>);</span><br><span class="line">    <span class="keyword">if</span> (millis != <span class="number">0</span>)</span><br><span class="line">      b.append(String.format(<span class="string">".%03d"</span>, millis));</span><br><span class="line">    <span class="keyword">if</span> ((n /= <span class="number">1000</span>) &lt; <span class="number">60</span>)</span><br><span class="line">      <span class="keyword">return</span> b.insert(<span class="number">0</span>, n).append(<span class="string">"s"</span>).toString();</span><br><span class="line"></span><br><span class="line">    b.insert(<span class="number">0</span>, String.format(<span class="string">":%02d"</span>, (<span class="keyword">int</span>)(n % <span class="number">60L</span>)));</span><br><span class="line">    <span class="keyword">if</span> ((n /= <span class="number">60</span>) &lt; <span class="number">60</span>)</span><br><span class="line">      <span class="keyword">return</span> b.insert(<span class="number">0</span>, n).toString();</span><br><span class="line"></span><br><span class="line">    b.insert(<span class="number">0</span>, String.format(<span class="string">":%02d"</span>, (<span class="keyword">int</span>)(n % <span class="number">60L</span>)));</span><br><span class="line">    <span class="keyword">if</span> ((n /= <span class="number">60</span>) &lt; <span class="number">24</span>)</span><br><span class="line">      <span class="keyword">return</span> b.insert(<span class="number">0</span>, n).toString();</span><br><span class="line"></span><br><span class="line">    b.insert(<span class="number">0</span>, n % <span class="number">24L</span>);</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> days = (<span class="keyword">int</span>)((n /= <span class="number">24</span>) % <span class="number">365L</span>);</span><br><span class="line">    b.insert(<span class="number">0</span>, days == <span class="number">1</span>? <span class="string">" day "</span>: <span class="string">" days "</span>).insert(<span class="number">0</span>, days);</span><br><span class="line">    <span class="keyword">if</span> ((n /= <span class="number">365L</span>) &gt; <span class="number">0</span>)</span><br><span class="line">      b.insert(<span class="number">0</span>, n == <span class="number">1</span>? <span class="string">" year "</span>: <span class="string">" years "</span>).insert(<span class="number">0</span>, n);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> b.toString();</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>写一个函数输出现在与1970年1月1日的时间间隔，输出结果：</p><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">46 years 113 days 7:07:31.820</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>maupassant主题使用方法</title>
      <link href="/2016/04/11/hexo/maupassant%E4%B8%BB%E9%A2%98%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"/>
      <url>/2016/04/11/hexo/maupassant%E4%B8%BB%E9%A2%98%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>近期将操作系统重装之后需要重新部署hexo，安装maupassant主题时出了点问题，主题安装后所有网页输出均为空。报错为deploy方法git不存在和jade文件不能正常产生。解决该问题的方法如下：</p><ul><li>在hexo目录下运行</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br><span class="line">npm install hexo-renderer-jade --save</span><br><span class="line">npm install hexo-renderer-sass --save</span><br></pre></td></tr></table></figure><a id="more"></a><ul><li><code>npm install hexo-renderer-sass</code>安装时会报错，是因为国内网络问题。需要使用代理或者切换至淘宝NPM镜像安装，地址为 <a href="http://npm.taobao.org/" target="_blank" rel="noopener">http://npm.taobao.org/</a> </li><li>淘宝NPM镜像安装方法为将npm指令重写为cnpm指令：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">alias</span> cnpm=<span class="string">"npm --registry=https://registry.npm.taobao.org \</span></span><br><span class="line"><span class="string">--cache=<span class="variable">$HOME</span>/.npm/.cache/cnpm \</span></span><br><span class="line"><span class="string">--disturl=https://npm.taobao.org/dist \</span></span><br><span class="line"><span class="string">--userconfig=<span class="variable">$HOME</span>/.cnpmrc"</span></span><br></pre></td></tr></table></figure><p>用cnpm指令替代npm指令即可成功安装<code>hexo-renderer-sass</code></p>]]></content>
      
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ubuntu安装PHP5.6</title>
      <link href="/2016/04/11/php/ubuntu%E5%AE%89%E8%A3%85PHP5-6/"/>
      <url>/2016/04/11/php/ubuntu%E5%AE%89%E8%A3%85PHP5-6/</url>
      
        <content type="html"><![CDATA[<p>总体上来说，ubuntu安装PHP5.6与CentOS是差不多的，但是有一些库的名称在ubuntu和CentOS上是不一样的，安装过程中还是有一些细微的差别.</p><ul><li>在安装PHP时，使用的configure指令如下所示：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">./configure \</span><br><span class="line">--prefix=/usr/<span class="built_in">local</span>/php \</span><br><span class="line">--with-curl \</span><br><span class="line">--with-gd \</span><br><span class="line">--<span class="built_in">enable</span>-sockets \</span><br><span class="line">--with-freetype-dir=/usr/<span class="built_in">local</span>/freetype \</span><br><span class="line">--<span class="built_in">enable</span>-mbstring \</span><br><span class="line">--<span class="built_in">enable</span>-bcmath \</span><br><span class="line">--with-gettext \</span><br><span class="line">--with-jpeg-dir=/usr/<span class="built_in">local</span>/libjpeg \</span><br><span class="line">--with-config-file-path=/usr/<span class="built_in">local</span>/php/etc \</span><br><span class="line">--with-mysql=/usr/<span class="built_in">local</span>/mysql \</span><br><span class="line">--with-mysqli=/usr/<span class="built_in">local</span>/mysql/bin/mysql_config \</span><br><span class="line">--with-mysql-sock=/var/lib/mysql/mysql.sock \</span><br><span class="line">--with-pdo-mysql=/usr/<span class="built_in">local</span>/mysql \</span><br><span class="line">--<span class="built_in">enable</span>-fpm \</span><br><span class="line">--<span class="built_in">disable</span>-fileinfo</span><br></pre></td></tr></table></figure><a id="more"></a><p>其中with-curl需要安装curl、libcurl3、libcurl3-dev和php5-curl<br>需要指定jpeg-dir，采用apt-get安装的libjpeg不能被PHP的gd扩展识别，需要再次手动安装libjpeg，采用编译安装的方式，在 <a href="http://www.ijg.org/files/" target="_blank" rel="noopener">http://www.ijg.org/files/</a> 下载最新的libjpeg源码，进行编译安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/libjpeg</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><p>但是libpng是能被gd扩展库识别的，安装好之后可以在phpinfo函数的输出界面观察到支持的结果<br>freetype也需要手动编译安装，下载地址为 <a href="http://download.savannah.gnu.org/releases/freetype/" target="_blank" rel="noopener">http://download.savannah.gnu.org/releases/freetype/</a> 下载最新的版本，采用如下指令进行安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/freetype</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><ul><li>在安装PHP扩展库的时候，使用phpize指令可能会出现<code>Cannot find autoconf.</code>的错误。在ubuntu中，我们可以使用如下指令来解决这个问题：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install m4</span><br><span class="line">sudo apt-get install autoconf</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PHP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>log4j日志文件在程序运行过程中进行清空操作</title>
      <link href="/2016/03/28/java/log4j%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E5%9C%A8%E7%A8%8B%E5%BA%8F%E8%BF%90%E8%A1%8C%E8%BF%87%E7%A8%8B%E4%B8%AD%E8%BF%9B%E8%A1%8C%E6%B8%85%E7%A9%BA%E6%93%8D%E4%BD%9C/"/>
      <url>/2016/03/28/java/log4j%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E5%9C%A8%E7%A8%8B%E5%BA%8F%E8%BF%90%E8%A1%8C%E8%BF%87%E7%A8%8B%E4%B8%AD%E8%BF%9B%E8%A1%8C%E6%B8%85%E7%A9%BA%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<p>log4j是Apache基金会的一个开源项目，作为一个java日志框架，能够方便地在程序中记录日志，提供许多记录日志的选项和功能。日志文件一般是不允许修改的，在隐藏权限中加入了只能增加不能删减的权限。但是，我在近期做了一个项目，需要在程序运行过程中将日志文件上传至数据库，上传之后要清空日志文件重新记录。我尝试了一下几种方法：</p><ol><li>将记录日志的文件删除，让日志框架重新生成</li><li>将记录日志的文件删除，并手动创建名称一致的日志文件</li><li>复制一个log4j自动生成的空的同名日志文件来覆盖旧的日志文件</li><li>调用linux命令<code>echo &gt; &lt;log_file_name&gt;</code>来清空日志<br>经过测试发现，log4j生成的日志文件只要被移动或删除，log4j就不会继续向其中写入日志，复制过来的空的同名日志文件也是一样的情况。调用linux命令清空日志文件之后，log4j能向日志文件中写入内容，但是不能被识别为txt或log文件，无法用编辑器打开查看（有例外，Atom编辑器能查看到其中的内容），gedit会说字符编码无法识别，无法打开；sublime会直接将这个文件当作二进制文件来打开，只能看到其中的0101内容。我用vim将其打开，发现在文件的开始处有许多“@^@^”这样的内容，在网上查到这是一种正常编码格式无法识别的字符，也称为“/0”。因此，只要将这些编码无法识别的内容除去即可。在网上查到了一个sed指令可以做这件事。使用如下代码来除去“@^”：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -r <span class="string">'s/\x0//g'</span> -i &lt;file_name&gt;</span><br></pre></td></tr></table></figure><a id="more"></a><p>除去之后果然能够用gedit、sublime等编辑器打开了，但是还是存在一个问题，当用这个语句处理过日志文件之后，相当于将日志文件做了修改（文件本身修改，<code>echo &gt; &lt;log_file_name&gt;</code>只是内容修改），log4j框架就不能继续向其中写入日志内容了。我采用的方法是先将日志文件复制到一个临时的地方，进行sed操作之后就上传到数据库，上传完成之后就删除，然后用<code>echo &gt; &lt;log_file_name&gt;</code>将原日志文件清空，使log4j继续记录。</p><p>清空日志文件的linux语句：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">: &gt; filename</span><br><span class="line">&gt; filename</span><br><span class="line"><span class="built_in">echo</span> <span class="string">""</span> &gt; filename</span><br><span class="line"><span class="built_in">echo</span> /dev/null &gt; filename</span><br><span class="line">cat /dev/null &gt; filename</span><br><span class="line">truncate filename --size 0</span><br></pre></td></tr></table></figure><p>我之后采用了最后一种方法，因为其他的方法有些会在日志文件开始产生一行空行。<br>此外，在用java的exec函数执行linux命令时，有些符号是不能在java中直接使用的，例如”&gt;”、引号等。这时候，需要加上如下代码对命令进行修正：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">String[] cmdarray = &#123;<span class="string">"/bin/sh"</span>, <span class="string">"-c"</span>, cmd&#125;;</span><br><span class="line">Process ps = Runtime.getRuntime().<span class="built_in">exec</span>(cmdarray);</span><br><span class="line">ps.waitFor();</span><br></pre></td></tr></table></figure><p>其中cmd是要执行的linux指令的String字符串。</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux统计当前文件夹下文件、目录的个数</title>
      <link href="/2016/03/25/linux/Linux%E7%BB%9F%E8%AE%A1%E5%BD%93%E5%89%8D%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B%E6%96%87%E4%BB%B6%E3%80%81%E7%9B%AE%E5%BD%95%E7%9A%84%E4%B8%AA%E6%95%B0/"/>
      <url>/2016/03/25/linux/Linux%E7%BB%9F%E8%AE%A1%E5%BD%93%E5%89%8D%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B%E6%96%87%E4%BB%B6%E3%80%81%E7%9B%AE%E5%BD%95%E7%9A%84%E4%B8%AA%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<h3 id="统计当前文件夹下文件的个数"><a href="#统计当前文件夹下文件的个数" class="headerlink" title="统计当前文件夹下文件的个数"></a>统计当前文件夹下文件的个数</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -l | grep <span class="string">"^-"</span> | wc -l</span><br></pre></td></tr></table></figure><h3 id="统计当前文件夹下目录的个数"><a href="#统计当前文件夹下目录的个数" class="headerlink" title="统计当前文件夹下目录的个数"></a>统计当前文件夹下目录的个数</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -l | grep <span class="string">"^d"</span> | wc -l</span><br></pre></td></tr></table></figure><h3 id="统计当前文件夹下文件的个数（包括子文件夹中的文件）"><a href="#统计当前文件夹下文件的个数（包括子文件夹中的文件）" class="headerlink" title="统计当前文件夹下文件的个数（包括子文件夹中的文件）"></a>统计当前文件夹下文件的个数（包括子文件夹中的文件）</h3><a id="more"></a><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -lR | grep <span class="string">"^-"</span> | wc -l</span><br></pre></td></tr></table></figure><h3 id="统计当前文件夹下目录的个数（包括子文件夹中的目录）"><a href="#统计当前文件夹下目录的个数（包括子文件夹中的目录）" class="headerlink" title="统计当前文件夹下目录的个数（包括子文件夹中的目录）"></a>统计当前文件夹下目录的个数（包括子文件夹中的目录）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -lR | grep <span class="string">"^d"</span> | wc -l</span><br></pre></td></tr></table></figure><h3 id="各参数的含义"><a href="#各参数的含义" class="headerlink" title="各参数的含义"></a>各参数的含义</h3><p><code>ls -l</code>表示列出当前文件夹下文件的信息<br><code>grep &quot;^-&quot;</code>grep表示将ls输出的信息进行过滤 <code>&quot;^-&quot;</code>表示得到文件,<code>&quot;&quot;^d</code>表示得到目录<br><code>wc -l</code>表示统计输出信息的行数</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql 导出database结构及数据的方法</title>
      <link href="/2016/03/25/mysql/mysql-%E5%AF%BC%E5%87%BAdatabase%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E6%B3%95/"/>
      <url>/2016/03/25/mysql/mysql-%E5%AF%BC%E5%87%BAdatabase%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>基本的使用方法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -u&lt;user_name&gt; -p&lt;password&gt; -d &lt;database_name&gt; &lt;table_name&gt; &lt;file_name&gt;.sql</span><br></pre></td></tr></table></figure><h4 id="导出名称为dbname的database的所有表结构（导出database所有的表，只有结构，不包含数据）"><a href="#导出名称为dbname的database的所有表结构（导出database所有的表，只有结构，不包含数据）" class="headerlink" title="导出名称为dbname的database的所有表结构（导出database所有的表，只有结构，不包含数据）"></a>导出名称为dbname的database的所有表结构（导出database所有的表，只有结构，不包含数据）</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -u&lt;user_name&gt; -p&lt;password&gt; -d dbname &gt; db.sql</span><br></pre></td></tr></table></figure><h4 id="导出名称为dbname的database的名称为tbname的表的结构（导出databse的某张表，只有结构，不包含数据）"><a href="#导出名称为dbname的database的名称为tbname的表的结构（导出databse的某张表，只有结构，不包含数据）" class="headerlink" title="导出名称为dbname的database的名称为tbname的表的结构（导出databse的某张表，只有结构，不包含数据）"></a>导出名称为dbname的database的名称为tbname的表的结构（导出databse的某张表，只有结构，不包含数据）</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -u&lt;user_name&gt; -p&lt;password&gt; -d dbname tbname &gt; db.sql</span><br></pre></td></tr></table></figure><h4 id="导出名称为dbname的database的所有表结构及数据（导出database所有的表，不仅有结构，还包含数据）"><a href="#导出名称为dbname的database的所有表结构及数据（导出database所有的表，不仅有结构，还包含数据）" class="headerlink" title="导出名称为dbname的database的所有表结构及数据（导出database所有的表，不仅有结构，还包含数据）"></a>导出名称为dbname的database的所有表结构及数据（导出database所有的表，不仅有结构，还包含数据）</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -u&lt;user_name&gt; -p&lt;password&gt; dbname &gt; db.sql</span><br></pre></td></tr></table></figure><h4 id="导出名称为dbname的databases的名称为tbname的表的结构及数据（导出database的某张表，不仅又结构，还包含数据）"><a href="#导出名称为dbname的databases的名称为tbname的表的结构及数据（导出database的某张表，不仅又结构，还包含数据）" class="headerlink" title="导出名称为dbname的databases的名称为tbname的表的结构及数据（导出database的某张表，不仅又结构，还包含数据）"></a>导出名称为dbname的databases的名称为tbname的表的结构及数据（导出database的某张表，不仅又结构，还包含数据）</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -u&lt;user_name&gt; -p&lt;password&gt; dbname tbname &gt; db.sql</span><br></pre></td></tr></table></figure><p>从中可以看出，参数<code>-d</code>的作用在于是否只导出表结构，加<code>-d</code>之后只导出结构，不导出数据</p><a id="more"></a><h4 id="将一个database中某个表中部分字段的数据导入另一个database的某个表的部分字段中"><a href="#将一个database中某个表中部分字段的数据导入另一个database的某个表的部分字段中" class="headerlink" title="将一个database中某个表中部分字段的数据导入另一个database的某个表的部分字段中"></a>将一个database中某个表中部分字段的数据导入另一个database的某个表的部分字段中</h4><p><a href="http://blog.163.com/l_tianwen/blog/static/35841670201431310363249/" target="_blank" rel="noopener">http://blog.163.com/l_tianwen/blog/static/35841670201431310363249/</a></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> databaseA.table(field1,field2,field3) <span class="keyword">SELECT</span> field1,field2,field3 <span class="keyword">FROM</span> databaseB.table</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>初学maven管理java项目</title>
      <link href="/2016/03/24/java/%E5%88%9D%E5%AD%A6maven%E7%AE%A1%E7%90%86java%E9%A1%B9%E7%9B%AE/"/>
      <url>/2016/03/24/java/%E5%88%9D%E5%AD%A6maven%E7%AE%A1%E7%90%86java%E9%A1%B9%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<ul><li>今天很粗浅地学会了如何使用maven来管理我的java项目，也就初步了解了一些项目的依赖如何写入<code>pom.xml</code>文件中，以及几个maven的插件。项目的依赖包可以到maven的仓库中进行查询，并将依赖的xml代码复制到自己项目的<code>pom.xml</code>文件中，maven仓库的地址为：<br><a href="http://mvnrepository.com/" target="_blank" rel="noopener">http://mvnrepository.com/</a></li><li>使用maven首先需要在系统上安装maven，对于linux系统而言，直接到maven官网下载tar.gz文件，解压到一个目录，例如<code>/usr/local/maven</code>，在环境变量中加入<code>M2_HOME</code>的值为maven的解压目录<code>/usr/local/maven</code>。在<code>PATH</code>变量中加入<code>${M2_HOME}/bin</code>，修改变量完毕之后不要忘记<code>source /etc/profile</code>。</li><li>在我的项目当中</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.sun.image.codec.jpeg.JPEGCodec;</span><br><span class="line"><span class="keyword">import</span> com.sun.image.codec.jpeg.JPEGImageEncoder;</span><br></pre></td></tr></table></figure><p>这两个包是sun公司的，并不对外公开，maven的仓库中当然也没有这两个包，导致maven项目不能成功编译。这两个包实际上是jdk和jre的lib中自带的，路径分别为<code>${JAVA_HOME}/lib/rt.jar</code>和<code>${JAVA_HOME}/jre/lib/jce.jar</code>，也就是说我们有这两个库，现在需要加入到maven项目当中。在Google查找资料发现一种可行的办法，就是在<code>pom.xml</code>中加入一个maven的插件(plugin)，具体的内容如下所示：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">encoding</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">compilerArguments</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">verbose</span> /&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">bootclasspath</span>&gt;</span>$&#123;java.home&#125;/lib/rt.jar:$&#123;java.home&#125;/lib/jce.jar<span class="tag">&lt;/<span class="name">bootclasspath</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">compilerArguments</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure><a id="more"></a><p>这样做就能成功编译了。</p><ul><li>maven编译可以在idea中很简单地实现，也可以在外部运行<code>mvn compile</code>指令，这样之后会产生编译后的class文件，但这些class文件一般不能运行，因为还依赖很多的jar包，这些jar包并不会在java执行的时候自动引入。目前我知道的方法只有说利用maven将整个项目打包成一个jar包，然后采用<code>java -jar &lt;project_name&gt;.jar</code>的方式来运行。maven本身并不支持打包，需要在<code>pom.xml</code>中加入插件的代码，如下所示：</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appendAssemblyId</span>&gt;</span>false<span class="tag">&lt;/<span class="name">appendAssemblyId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">archive</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">manifest</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">mainClass</span>&gt;</span>WormImage<span class="tag">&lt;/<span class="name">mainClass</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">manifest</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">archive</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>make-assembly<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">goal</span>&gt;</span>assembly<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure><p>这样就能通过idea中的maven项目管理中的package按钮来实现打包操作，也可以在外部终端中输入<code>mvn package</code>指令来实现打包操作。需要说明的是<code>&lt;plugin&gt;</code>标签需要插入在<build><plugins></plugins></build>标签之内，否则<code>pom.xml</code>文件会报错。当项目需要被push的时候，可以输入<code>mvn clean</code>指令来清除编译产生的文件，方便上传。</p><ul><li>使用maven来管理项目的一个好处是不需要将依赖的jar包也一起上传到github中，只是源码部分被上传了。依赖的包在编译项目的时候才被下载下来。当然，maven管理java项目的好处还有很多，今后也会制定计划对maven进一步学习。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> maven </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从coding git clone 私有项目到ec2</title>
      <link href="/2016/03/24/%E4%BB%8Ecoding%20git%20clone%20%E7%A7%81%E6%9C%89%E9%A1%B9%E7%9B%AE%E5%88%B0ec2/"/>
      <url>/2016/03/24/%E4%BB%8Ecoding%20git%20clone%20%E7%A7%81%E6%9C%89%E9%A1%B9%E7%9B%AE%E5%88%B0ec2/</url>
      
        <content type="html"><![CDATA[<p>之前从 coding git clone 私有项目到EC2服务器一直出现400的网页错误，不知道如何解决，今天查阅资料后发现需要以一下格式来 git clone 才能将私有项目成功 clone 下来。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> -b sci-demo https://&lt;coding_username&gt;:&lt;coding_password&gt;@git.coding.net/&lt;coding_username&gt;/&lt;repository_name&gt;.git</span><br></pre></td></tr></table></figure><p><coding_username> 为coding的账户名<br><coding_password> 为coding的密码<br><coding_repository> 为 clone 的项目的仓库名<br>实际上只需要将用户名和密码部分加上，其他部分的内容直接拷贝 git 地址即可</coding_repository></coding_password></coding_username></p>]]></content>
      
      
      
        <tags>
            
            <tag> EC2 </tag>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS SDK for Java 使用心得</title>
      <link href="/2016/03/17/java/AWS%20SDK%20for%20Java%20%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/"/>
      <url>/2016/03/17/java/AWS%20SDK%20for%20Java%20%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/</url>
      
        <content type="html"><![CDATA[<p>AWS SDK 是一套用于开发者与 Amazon Web Services进行交互的系统，其功能繁多，对于普通开发者来说，本人主要使用了其针对Java开发的向S3云存储上传文件和文件夹的功能。AWS开发工具包的下载地址：<br><a href="https://aws.amazon.com/cn/tools/" target="_blank" rel="noopener">https://aws.amazon.com/cn/tools/</a><br>其中的Java开发工具包的API文档地址：<br><a href="http://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/index.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/index.html</a><br>进行开发之前建议自习阅读其官方的开发引导：<br><a href="http://docs.aws.amazon.com/AWSSdkDocsJava/latest/DeveloperGuide/welcome.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/AWSSdkDocsJava/latest/DeveloperGuide/welcome.html</a></p><h3 id="心得"><a href="#心得" class="headerlink" title="心得"></a>心得</h3><ul><li>开发AWS应用仅靠API接口的阅读是不够的，最好能够仔细阅读官方SDK中的Sample文件夹中的程序，熟悉整个SDK开发的代码流程，也可以到论坛和GitHub中找与AWS相关的代码进行阅读</li><li>AWS SDK for Java 中有两种上传文件的方法，一种是构造一个PutObjectRequest，调用其中的构造函数：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PutObjectRequest(String bucketName, String key, File file)</span><br><span class="line">Constructs a new PutObjectRequest object to upload a file to the specified bucket and key.</span><br></pre></td></tr></table></figure><p>构造一个上传文件的PutObjectRequest对象，然后使用AmazonS3Client类中的putObject方法来实现上传文件的操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public PutObjectResult putObject(PutObjectRequest putObjectRequest)</span><br><span class="line">                          throws AmazonClientException,</span><br><span class="line">                                 AmazonServiceException</span><br></pre></td></tr></table></figure><a id="more"></a><p>还有一种方法是使用TransferManager类中的upload方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">TransferManager(AmazonS3 s3)</span><br><span class="line">Constructs a new TransferManager, specifying the client to use when making requests to Amazon S3.</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public Upload upload(String bucketName,</span><br><span class="line">            String key,</span><br><span class="line">            File file)</span><br><span class="line">              throws AmazonServiceException,</span><br><span class="line">                     AmazonClientException</span><br></pre></td></tr></table></figure><p>upload方法同样也可以传入一个PutObjectRequest对象，作用与之前描述的相同。<br>这两种方法都可以成功上传文件，但是前一种方法传输文件的速度比较慢但是不会出现timeout的问题，是一种简单并且稳定的传输方式，缺点就是传输速度很慢，并且只能传单个文件，不能传文件夹。传文件夹可以使用递归的方式通过深度搜索来传输文件夹中的每一个文件，但是在文件夹中文件数量很多的情况下，这样传输的方式会十分缓慢。后一种方法可以使用uploadDirectory方法来传输一个文件夹：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public MultipleFileUpload uploadDirectory(String bucketName,</span><br><span class="line">                                 String virtualDirectoryKeyPrefix,</span><br><span class="line">                                 File directory,</span><br><span class="line">                                 boolean includeSubdirectories)</span><br></pre></td></tr></table></figure><p>并且这种方式的传输在SDK内部是通过多线程的方式实现的，将文件传输分为多个线程来进行，传输速度慢，在传输一段时间之后会出现timeout的情况。<br>关于timeout的清空，网上众说纷纭，有人说通过设置AmazonS3Client的配置文件可以解决，有人说可以通过修改jre的networkaddress.cache.ttl时间为60秒可以解决。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java.security.Security.setProperty(<span class="string">"networkaddress.cache.ttl"</span>, <span class="string">"60"</span>);</span><br></pre></td></tr></table></figure><p>但是经过本人的尝试，这个timeout的出现还是与你所在的地区以及你的网速决定的，当我将代码在EC2服务器上运行时，是不会出现timeout的情况的，并且运行速度很快。</p><ul><li>在建立transfer连接之后一定要记得使用shudownNow函数来关闭连接，否则程序会一直等待连接的断开。</li><li>使用SDK与Amazon Web Service 进行连接需要提供 access key 和 secret access key，这些内容需要放到默认的~/.aws/credentials文件中去。</li><li>各种可配置的实例的配置文件一般在创建实例的时候传入。</li><li>使用upload和uploadDirectory方法传输文件时，要使用Upload.waitForCompletion函数来阻塞程序运行，等待传输完毕。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS 7.0 编译安装VIPS dzsave</title>
      <link href="/2016/01/13/centos/CentOS%207.0%20%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85VIPS%20dzsave/"/>
      <url>/2016/01/13/centos/CentOS%207.0%20%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85VIPS%20dzsave/</url>
      
        <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>VIPS 是一个能够处理大型图片的很棒的图片处理系统。特别是它能通过dzsave很简单地生成deepzoon图片（.dzi）。从VIPS版本7.40开始，它需要使用libgsf库来激活对dzsave的支持。</p><h2 id="安装libgsf库"><a href="#安装libgsf库" class="headerlink" title="安装libgsf库"></a>安装libgsf库</h2><p>libgsf库的作用在于能够使用dzsave指令，没有安装libgsf的话会报dzsave不存在的错误。安装libgsf之后需要重新编译安装vips才能使用dzsave。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install libgsf</span><br></pre></td></tr></table></figure><p>ubuntu中安装libgsf库的方法为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libgsf-1-dev</span><br></pre></td></tr></table></figure><h2 id="安装libjpeg和libpng库"><a href="#安装libjpeg和libpng库" class="headerlink" title="安装libjpeg和libpng库"></a>安装libjpeg和libpng库</h2><p>vips要支持png和jpeg还需要安装libpng和libjpeg，在CentOS中安装的方法为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install libjpeg libjpeg-devel libpng libpng-devel</span><br></pre></td></tr></table></figure><p>在ubuntu中安装方法为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install linpng12-0</span><br><span class="line">sudo apt-get install libjpeg-dev</span><br></pre></td></tr></table></figure><h2 id="安装VIPS"><a href="#安装VIPS" class="headerlink" title="安装VIPS"></a>安装VIPS</h2><p>简单的编译安装，采用<code>vips dzsave --version</code>来检查dzsave是否安装成功</p><h2 id="使用VIPS"><a href="#使用VIPS" class="headerlink" title="使用VIPS"></a>使用VIPS</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/vips dzsave &lt;source_file&gt; &lt;destination_file&gt; --suffix .png</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>安装redis&amp;memcache及PHP扩展</title>
      <link href="/2016/01/07/php/%E5%AE%89%E8%A3%85redis%E5%92%8Cmemcache%E5%8F%8APHP%E6%89%A9%E5%B1%95/"/>
      <url>/2016/01/07/php/%E5%AE%89%E8%A3%85redis%E5%92%8Cmemcache%E5%8F%8APHP%E6%89%A9%E5%B1%95/</url>
      
        <content type="html"><![CDATA[<h2 id="安装redis"><a href="#安装redis" class="headerlink" title="安装redis"></a>安装redis</h2><ul><li><p>下载地址： <a href="http://redis.io/download" target="_blank" rel="noopener">http://redis.io/download</a></p></li><li><p>解压并进入解压目录，并进行编译安装。直接make &amp; make install</p></li><li><p>拷贝配置文件到 /etc 目录，将其中的daemonize no改为daemonize yes</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp redis.conf /etc/</span><br></pre></td></tr></table></figure></li><li><p>将解压目录中 src/ 中的redis-benchmark redis-cli redis-server 拷贝到 /usr/bin 中，方便之后启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp src/redis-benchmark redis-cli redis-server /usr/bin/</span><br></pre></td></tr></table></figure></li></ul><a id="more"></a><ul><li><p>启动redis</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server /etc/redis.conf</span><br></pre></td></tr></table></figure></li><li><p>进入redis</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli</span><br></pre></td></tr></table></figure></li><li><p>关闭redis服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli shutdown</span><br></pre></td></tr></table></figure></li></ul><h2 id="安装redis的PHP扩展库"><a href="#安装redis的PHP扩展库" class="headerlink" title="安装redis的PHP扩展库"></a>安装redis的PHP扩展库</h2><ul><li><p>下载地址： <a href="http://pecl.php.net/package/redis" target="_blank" rel="noopener">http://pecl.php.net/package/redis</a></p></li><li><p>将phpize软链接到 /usr/bin</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /usr/<span class="built_in">local</span>/php/bin/phpize /usr/bin</span><br></pre></td></tr></table></figure></li><li><p>解压并进入解压目录，使用如下命令进行安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">phpize</span><br><span class="line">./configure --with-php-config=/usr/<span class="built_in">local</span>/php/bin/php-config</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure></li><li><p>查看输出信息，会告诉你redis.so放置在哪个文件夹下，并复制到PHP的扩展目录下，扩展目录一般为 /usr/local/php/lib/php/extensions/no-debug-non-zts-20131226/，在正常情况下，该文件已经被拷贝到正确的位置</p></li><li><p>在php.ini中添加一句extension=redis.so</p></li><li><p>重启PHP，在phpinfo界面会有redis信息显示则说明安装成功</p><h2 id="安装memcache"><a href="#安装memcache" class="headerlink" title="安装memcache"></a>安装memcache</h2></li><li><p>memcache需要使用libevent这个库用于socket的处理，需要安装libevent，下载地址： <a href="http://libevent.org/" target="_blank" rel="noopener">http://libevent.org/</a></p></li><li><p>编译安装libevent</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./configure --prefix=/usr</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure></li><li><p>memcache下载地址： <a href="http://memcached.org/" target="_blank" rel="noopener">http://memcached.org/</a></p></li><li><p>编译安装memcache</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./configure --with-libevent=/usr</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure></li><li><p>启动memcache</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">memcached -d -m 2048 -u root -c 1024 -p 11211 -P /tmp/memcached1.pid</span><br></pre></td></tr></table></figure></li></ul><p>-p 指定端口号（默认11211）<br>-m 指定最大使用内存大小（默认64MB）<br>-t 线程数（默认4）<br>-l 连接的IP地址, 默认是本机<br>-d start 启动memcached服务<br>-d restart 重起memcached服务<br>-d stop|shutdown 关闭正在运行的memcached服务<br>-m 最大内存使用，单位MB。默认64MB<br>-M 内存耗尽时返回错误，而不是删除项<br>-c 最大同时连接数，默认是1024<br>-f 块大小增长因子，默认是1.25<br>-n 最小分配空间，key+value+flags默认是48</p><h2 id="安装memcache的PHP扩展库"><a href="#安装memcache的PHP扩展库" class="headerlink" title="安装memcache的PHP扩展库"></a>安装memcache的PHP扩展库</h2><ul><li><p>下载地址： <a href="http://pecl.php.net/package/memcache" target="_blank" rel="noopener">http://pecl.php.net/package/memcache</a></p></li><li><p>用如下指令进行安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">phpize</span><br><span class="line">./configure --<span class="built_in">enable</span>-memcache --with-php-config=/usr/<span class="built_in">local</span>/php/bin/php-config --with-zlib-dir</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure></li><li><p>在php.ini中增加一行：extension=memcache.so</p></li><li><p>查看phpinfo()的输出，观察memcache的扩展库是否存在</p></li></ul><h2 id="PHP7安装memcache的PHP扩展库的问题"><a href="#PHP7安装memcache的PHP扩展库的问题" class="headerlink" title="PHP7安装memcache的PHP扩展库的问题"></a>PHP7安装memcache的PHP扩展库的问题</h2><ul><li><p>原生的memcache扩展库在PHP7中已经不能编译了，需要使用github上的pecl-memcache分支版本<br><a href="https://github.com/websupport-sk/pecl-memcache" target="_blank" rel="noopener">https://github.com/websupport-sk/pecl-memcache</a></p></li><li><p>此外，还有一个扩展库叫memcached，与memcache不同，功能更强大，可以在<a href="https://github.com/rlerdorf/php-memcached" target="_blank" rel="noopener">https://github.com/rlerdorf/php-memcached</a> 进行下载安装，编译需要安装libmemcached</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install libmemcached-dev</span><br></pre></td></tr></table></figure></li><li><p>再提供一个redis扩展库的github地址<a href="https://github.com/phpredis/phpredis/" target="_blank" rel="noopener">https://github.com/phpredis/phpredis/</a> ，后续redis扩展库对PHP7支持不好可以从该地址下载进行扩展库安装</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PHP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS 7.0 安装MySQL 5.6</title>
      <link href="/2016/01/07/centos/CentOS%207.0%20%E5%AE%89%E8%A3%85MySQL%205.6/"/>
      <url>/2016/01/07/centos/CentOS%207.0%20%E5%AE%89%E8%A3%85MySQL%205.6/</url>
      
        <content type="html"><![CDATA[<h2 id="1-安装依赖"><a href="#1-安装依赖" class="headerlink" title="1. 安装依赖"></a>1. 安装依赖</h2><ul><li>使用yum安装一些依赖<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum -y install make gcc gcc-c++ cmake bison-devel ncurses-devel</span><br><span class="line">yum -y install kernel-devel readline-devel openssl-devel openssl</span><br></pre></td></tr></table></figure></li></ul><h2 id="2-设置MySQL用户和组"><a href="#2-设置MySQL用户和组" class="headerlink" title="2. 设置MySQL用户和组"></a>2. 设置MySQL用户和组</h2><ul><li><p>新增mysql用户组</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">groupadd mysql</span><br></pre></td></tr></table></figure></li><li><p>新增mysql用户</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">useradd -r -g mysql mysql</span><br></pre></td></tr></table></figure></li></ul><a id="more"></a><h2 id="3-新建MySQL所需要的目录"><a href="#3-新建MySQL所需要的目录" class="headerlink" title="3. 新建MySQL所需要的目录"></a>3. 新建MySQL所需要的目录</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/</span><br><span class="line">mkdir mysql</span><br><span class="line"><span class="built_in">cd</span> mysql/</span><br><span class="line">mkdir data</span><br></pre></td></tr></table></figure><h2 id="4-下载安装MySQL"><a href="#4-下载安装MySQL" class="headerlink" title="4. 下载安装MySQL"></a>4. 下载安装MySQL</h2><ul><li><p>下载mySQL安装包</p><ul><li>下载地址： <a href="http://dev.mysql.com/downloads/mysql/5.6.html#downloads" target="_blank" rel="noopener">http://dev.mysql.com/downloads/mysql/5.6.html#downloads</a></li><li>选择版本号，Platform选择Source Code，下载.tar.gz文件</li></ul></li><li><p>编译安装MySQL</p><ul><li><p>从MySQL 5.5起，MySQL源码安装开始使用cmake了，设置源码编译配置脚本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-DCMAKE_INSTALL_PREFIX=dir_name//设置MySQL安装目录</span><br><span class="line">-DMYSQL_UNIX_ADDR=file_name//设置监听套接字路径，这必须是一个绝对路径名，默认为/tmp/r</span><br><span class="line">-DDEFAULT_CHARSET=charset_name//设置服务器的字符集，缺省情况下，MySQL使用latin1的（CP1252西欧）字符集，cmake/character_sets.cmake文件包含允许的字符集名称列表</span><br><span class="line">-DDEFAULT_COLLATION=collation_name//设置服务器的排序规则</span><br><span class="line">-DMYSQL_DATADIR=dir_name//设置MySQL数据库文件目录</span><br><span class="line">-DMYSQL_TCP_PORT=port_num//设置MySQL服务器监听端口，默认为3306</span><br><span class="line">-DSYSCONFDIR=dir_name//配置文件 my.cnf 目录</span><br><span class="line">-DENABLED_LOCAL_INFILE=1//启用加载本地数据</span><br><span class="line">-DEXTRA_CHARSETS=all//扩展字符支持，默认值为all</span><br><span class="line">-DDEFAULT_COLLATION=utf8_general_ci//默认字符校对</span><br></pre></td></tr></table></figure></li><li><p>cmake编译指令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">cmake \</span><br><span class="line">-DCMAKE_INSTALL_PREFIX=/usr/<span class="built_in">local</span>/mysql \</span><br><span class="line">-DMYSQL_DATADIR=/usr/<span class="built_in">local</span>/mysql/data \</span><br><span class="line">-DSYSCONFDIR=/etc \</span><br><span class="line">-DWITH_MYISAM_STORAGE_ENGINE=1 \</span><br><span class="line">-DWITH_INNOBASE_STORAGE_ENGINE=1 \</span><br><span class="line">-DWITH_MEMORY_STORAGE_ENGINE=1 \</span><br><span class="line">-DWITH_READLINE=1 \</span><br><span class="line">-DMYSQL_UNIX_ADDR=/var/lib/mysql/mysql.sock \</span><br><span class="line">-DMYSQL_TCP_PORT=3306 \</span><br><span class="line">-DENABLED_LOCAL_INFILE=1 \</span><br><span class="line">-DWITH_PARTITION_STORAGE_ENGINE=1 \</span><br><span class="line">-DEXTRA_CHARSETS=all \</span><br><span class="line">-DDEFAULT_CHARSET=utf8 \</span><br><span class="line">-DDEFAULT_COLLATION=utf8_general_ci</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure></li></ul></li></ul><h2 id="5-修改安装目录所有者"><a href="#5-修改安装目录所有者" class="headerlink" title="5. 修改安装目录所有者"></a>5. 修改安装目录所有者</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/mysql</span><br><span class="line">chown -R mysql:mysql .</span><br></pre></td></tr></table></figure><h2 id="6-初始化和启动MySQL"><a href="#6-初始化和启动MySQL" class="headerlink" title="6. 初始化和启动MySQL"></a>6. 初始化和启动MySQL</h2><ul><li><p>进入安装目录执行脚本，启动服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/mysql</span><br><span class="line">scripts/mysql_install_db --bashdir=/usr/<span class="built_in">local</span>/mysql --datadir=/usr/<span class="built_in">local</span>/mysql/data --user=mysql</span><br><span class="line">cp support-files/mysql.server /etc/init.d/mysql</span><br><span class="line">rm /etc/my.cnf</span><br><span class="line">cp /usr/<span class="built_in">local</span>/mysql/support-files/my-default.cnf /etc/my.cnf</span><br><span class="line">chkconfig mysql on</span><br><span class="line">service mysql start</span><br><span class="line">chkconfig --level 35 mysql on//可选，设置后MySQL会开机自启动</span><br></pre></td></tr></table></figure></li><li><p>设置之前，需先设置PATH要不然不能直接调用mysql这个指令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /usr/<span class="built_in">local</span>/mysql/bin/mysql /usr/bin/</span><br></pre></td></tr></table></figure></li></ul><h2 id="7-检查MySQL服务是否启动"><a href="#7-检查MySQL服务是否启动" class="headerlink" title="7. 检查MySQL服务是否启动"></a>7. 检查MySQL服务是否启动</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p</span><br></pre></td></tr></table></figure><ul><li>密码为空，如果能登陆上，则安装成功</li><li>修改密码，登陆mysql，依次输入如下指令<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> mysql;</span><br><span class="line"><span class="keyword">update</span> <span class="keyword">user</span> <span class="keyword">set</span> <span class="keyword">password</span>=<span class="keyword">password</span>(<span class="string">'your_passward'</span>) <span class="keyword">where</span> <span class="keyword">user</span>=<span class="string">'root'</span>;</span><br><span class="line"><span class="keyword">flush</span> <span class="keyword">privileges</span>;</span><br></pre></td></tr></table></figure></li></ul><h2 id="8-可能会出现的问题"><a href="#8-可能会出现的问题" class="headerlink" title="8. 可能会出现的问题"></a>8. 可能会出现的问题</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">问题：</span><br><span class="line">Starting MySQL..The server quit without updating PID file ([FAILED]/mysql/Server03.mylinux.com.pid).</span><br><span class="line">解决：</span><br><span class="line">修改/etc/my.cnf 中datadir,指向正确的mysql数据库文件目录</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">问题：</span><br><span class="line">ERROR 2002 (HY000): Can<span class="string">'t connect to local MySQL server through socket '</span>/tmp/mysql.sock<span class="string">' (2)</span></span><br><span class="line"><span class="string">解决：</span></span><br><span class="line"><span class="string">新建一个链接或在mysql中加入-S参数，直接指出mysql.sock位置</span></span><br><span class="line"><span class="string">ln -s /usr/local/mysql/data/mysql.sock /tmp/mysql.sock</span></span><br><span class="line"><span class="string">/usr/local/mysql/bin/mysql -u root -S /usr/local/mysql/data/mysql.sock</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS 7.0 安装PHP 5.6</title>
      <link href="/2016/01/07/centos/CentOS%207.0%20%E5%AE%89%E8%A3%85PHP%205.6/"/>
      <url>/2016/01/07/centos/CentOS%207.0%20%E5%AE%89%E8%A3%85PHP%205.6/</url>
      
        <content type="html"><![CDATA[<h2 id="1-下载和安装PHP-5-6"><a href="#1-下载和安装PHP-5-6" class="headerlink" title="1. 下载和安装PHP 5.6"></a>1. 下载和安装PHP 5.6</h2><ul><li>下载地址： <a href="http://php.net/downloads.php" target="_blank" rel="noopener">http://php.net/downloads.php</a></li><li>解压之后使用如下指令进行安装<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">./configure \</span><br><span class="line">--prefix=/usr/<span class="built_in">local</span>/php \</span><br><span class="line">--with-curl \</span><br><span class="line">--with-gd \</span><br><span class="line">--<span class="built_in">enable</span>-sockets \</span><br><span class="line">--with-freetype-dir=/usr/<span class="built_in">local</span>/freetype \</span><br><span class="line">--<span class="built_in">enable</span>-mbstring \</span><br><span class="line">--<span class="built_in">enable</span>-bcmath \</span><br><span class="line">--<span class="built_in">enable</span>-gettext \</span><br><span class="line">--with-jpeg-dir=/usr/<span class="built_in">local</span>/jpeg \</span><br><span class="line">--with-config-file-path=/usr/<span class="built_in">local</span>/php/etc \</span><br><span class="line">--with-mysql=/usr/<span class="built_in">local</span>/mysql \</span><br><span class="line">--with-mysqli=/usr/<span class="built_in">local</span>/mysql/bin/mysql_config \</span><br><span class="line">--with-mysql-sock=/var/lib/mysql/mysql.sock \</span><br><span class="line">--with-pdo-mysql=/usr/<span class="built_in">local</span>/mysql \</span><br><span class="line">--<span class="built_in">enable</span>-fpm \</span><br><span class="line">--<span class="built_in">disable</span>-fileinfo</span><br><span class="line"></span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure></li></ul><a id="more"></a><ul><li><p>对于内存小于1G的电脑来说，make时可能会出现内存溢出的问题，解决方法为./configure加上选项–disable-fileinfo</p><h2 id="2-配置PHP"><a href="#2-配置PHP" class="headerlink" title="2. 配置PHP"></a>2. 配置PHP</h2></li><li><p>复制PHP配置文件到安装目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp php.in-production /usr/<span class="built_in">local</span>/php/etc/php.ini</span><br></pre></td></tr></table></figure></li><li><p>修改php.ini文件，将其中的date.timezone = PRC</p></li><li><p>删除系统自带的PHP配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf /etc/php.ini</span><br></pre></td></tr></table></figure></li><li><p>添加软连接到 /etc 目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /usr/<span class="built_in">local</span>/php/etc/php.ini /etc/php.ini</span><br></pre></td></tr></table></figure></li><li><p>拷贝模板文件为php-fpm配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /usr/<span class="built_in">local</span>/php/etc/php-fpm.conf.default /usr/<span class="built_in">local</span>/php/etc/php-fpm.conf</span><br></pre></td></tr></table></figure></li><li><p>添加软连接到 /etc 目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /usr/<span class="built_in">local</span>/php/etc/php-fpm.conf /etc/php-fpm.conf</span><br></pre></td></tr></table></figure></li><li><p>修改php-fpm.conf文件，在user和group处添加当前用户名和组，取消pid=run/php-fpm.pid前的分号</p><h2 id="3-启动、关闭和重启PHP"><a href="#3-启动、关闭和重启PHP" class="headerlink" title="3. 启动、关闭和重启PHP"></a>3. 启动、关闭和重启PHP</h2></li><li><p>启动PHP</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/php/sbin/php-fpm</span><br></pre></td></tr></table></figure></li><li><p>关闭PHP</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">kill</span> -INT `cat /usr/<span class="built_in">local</span>/php/var/run/php-fpm.pid`</span><br></pre></td></tr></table></figure></li><li><p>重启PHP</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">kill</span> -USR2 `cat /usr/<span class="built_in">local</span>/php/var/run/php-fpm.pid`</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PHP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS 7.0 安装Nginx</title>
      <link href="/2016/01/07/centos/CentOS%207.0%20%E5%AE%89%E8%A3%85Nginx/"/>
      <url>/2016/01/07/centos/CentOS%207.0%20%E5%AE%89%E8%A3%85Nginx/</url>
      
        <content type="html"><![CDATA[<h2 id="1-所需库的安装"><a href="#1-所需库的安装" class="headerlink" title="1. 所需库的安装"></a>1. 所需库的安装</h2><ul><li>pcre库<ul><li>下载地址： <a href="ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/" target="_blank" rel="noopener">ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/</a></li><li>安装指令：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure></li></ul></li></ul><a id="more"></a><ul><li>zlib库<ul><li>下载地址： <a href="http://www.zlib.net/" target="_blank" rel="noopener">http://www.zlib.net/</a></li><li>安装指令：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure></li></ul></li></ul><h2 id="2-安装nginx"><a href="#2-安装nginx" class="headerlink" title="2. 安装nginx"></a>2. 安装nginx</h2><ul><li><p>下载地址： <a href="http://nginx.org/en/download.html" target="_blank" rel="noopener">http://nginx.org/en/download.html</a></p></li><li><p>安装指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/nginx</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure></li><li><p>安装完毕后开启nginx服务器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/nginx/sbin/nginx</span><br></pre></td></tr></table></figure></li><li><p>启动之后在浏览器输入： <a href="http://localhost" target="_blank" rel="noopener">http://localhost</a> ，若能出现welcome to nginx！的界面则说明安装成功</p></li><li><p>重启、关闭nginx服务器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/nginx/sbin/nginx -s reload</span><br><span class="line">/usr/<span class="built_in">local</span>/nginx/sbin/nginx -s stop</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hadoop安装完成后50030页面能打开50070页面无法打开解决方法</title>
      <link href="/2015/12/25/hadoop/hadoop%E5%AE%89%E8%A3%85%E5%AE%8C%E6%88%90%E5%90%8E50030%E9%A1%B5%E9%9D%A2%E8%83%BD%E6%89%93%E5%BC%8050070%E9%A1%B5%E9%9D%A2%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"/>
      <url>/2015/12/25/hadoop/hadoop%E5%AE%89%E8%A3%85%E5%AE%8C%E6%88%90%E5%90%8E50030%E9%A1%B5%E9%9D%A2%E8%83%BD%E6%89%93%E5%BC%8050070%E9%A1%B5%E9%9D%A2%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>hadoop-1.2.1安装完毕之后，执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/hadoop/bin/hadoop namenode -format</span><br><span class="line">/usr/<span class="built_in">local</span>/hadoop/bin/start-all.sh</span><br></pre></td></tr></table></figure><p>在浏览器中输入 <a href="http://localhost:50030" target="_blank" rel="noopener">http://localhost:50030</a> 可以访问<br>在浏览器中输入 <a href="http://localhost:50070" target="_blank" rel="noopener">http://localhost:50070</a> 无法访问</p><a id="more"></a><p>原因是在执行<code>/usr/local/hadoop/bin/hadoop namenode -format</code>后要求输入”Y/N”时输入了小写的y，必须输入大写的Y，namenode才能正常启动，50070页面才能正常显示</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hadoop中YARN模块功能</title>
      <link href="/2015/12/24/hadoop/hadoop%E4%B8%ADYARN%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD/"/>
      <url>/2015/12/24/hadoop/hadoop%E4%B8%ADYARN%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD/</url>
      
        <content type="html"><![CDATA[<h3 id="ResourceManager"><a href="#ResourceManager" class="headerlink" title="ResourceManager"></a><strong>ResourceManager</strong></h3><ul><li>处理客户端请求</li><li>启动/监控ApplicationMaster</li><li>监控NodeManager</li><li>资源分配与调度</li></ul><h3 id="NodeManager"><a href="#NodeManager" class="headerlink" title="NodeManager"></a><strong>NodeManager</strong></h3><ul><li>单个节点上的资源管理</li><li>处理来自ResourceManager的命令</li><li>处理来自ApplicationMaster的命令<a id="more"></a><h3 id="ApplicationMaster"><a href="#ApplicationMaster" class="headerlink" title="ApplicationMaster"></a><strong>ApplicationMaster</strong></h3></li><li>数据切分</li><li>为应用程序申请资源，并分配给内部任务</li><li>任务监控与容错</li></ul><h3 id="Container"><a href="#Container" class="headerlink" title="Container"></a><strong>Container</strong></h3><ul><li>对任务运行环境的抽象，封装了CPU、内存等多维资源以及环境变量、启动命令等任务运行相关的信息</li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>导入hadoop源码至Eclipse</title>
      <link href="/2015/12/24/hadoop/%E5%AF%BC%E5%85%A5hadoop%E6%BA%90%E7%A0%81%E8%87%B3Eclipse/"/>
      <url>/2015/12/24/hadoop/%E5%AF%BC%E5%85%A5hadoop%E6%BA%90%E7%A0%81%E8%87%B3Eclipse/</url>
      
        <content type="html"><![CDATA[<p>从hadoop官网下载hadoop源码，解压后进入目录，阅读BUILDING.txt文件，文件中讲到了如何将hadoop源码工程文件导入到Eclipse中。首先需要给Eclipse安装hadoop-maven-plugins插件，进入hadoop-maven-plugins目录执行指令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> hadoop-maven-pligins</span><br><span class="line">mvn install</span><br><span class="line">mvn eclipse:eclipse -DskipTests</span><br></pre></td></tr></table></figure><p>最后，在Eclipse中点击[File] &gt; [Import] &gt; [Existing Projects into Workspace]</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hadoop目录结构</title>
      <link href="/2015/12/24/hadoop/hadoop%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/"/>
      <url>/2015/12/24/hadoop/hadoop%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h2 id="bin"><a href="#bin" class="headerlink" title="bin"></a><strong>bin</strong></h2><p>hadoop最基本的管理脚本和使用脚本所在的目录，这些脚本是sbin目录下管理脚本的基础实现，用户可以直接使用这些脚本管理和使用hadoop</p><h2 id="etc"><a href="#etc" class="headerlink" title="etc"></a><strong>etc</strong></h2><p>hadoop配置文件所在的目录，包括core-site.xml、hdfs-site.xml、mapred-site.xml等从hadoop 1.0继承而来的配置文件和yarn-site.xml等hadoop 2.0新增的配置文件</p><h2 id="include"><a href="#include" class="headerlink" title="include"></a><strong>include</strong></h2><p>对外提供的编程库头文件（具体动态库和静态库在lib目录中，这些头文件均是用C++定义的，通常用于C++程序访问HDFS或者编写MapReduce程序）</p><a id="more"></a><h2 id="lib"><a href="#lib" class="headerlink" title="lib"></a><strong>lib</strong></h2><p>该目录包含了hadoop对外提供的编程动态库和静态库，与include目录中的头文件结合使用</p><h2 id="libexec"><a href="#libexec" class="headerlink" title="libexec"></a><strong>libexec</strong></h2><p>各个服务对应的shell配置文件所在目录，可用于配置日志输出目录、启动参数（比如JVM参数）等基本信息</p><h2 id="sbin"><a href="#sbin" class="headerlink" title="sbin"></a><strong>sbin</strong></h2><p>hadoop管理脚本所在目录，主要包含HDFS和YARN中各类服务的启动/关闭脚本</p><h2 id="share"><a href="#share" class="headerlink" title="share"></a><strong>share</strong></h2><p>hadoop各个模块编译后的jar包所在目录</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop搭建single Node Cluster</title>
      <link href="/2015/12/16/hadoop/hadoop%E6%90%AD%E5%BB%BAsingle%20Node%20Cluster/"/>
      <url>/2015/12/16/hadoop/hadoop%E6%90%AD%E5%BB%BAsingle%20Node%20Cluster/</url>
      
        <content type="html"><![CDATA[<h3 id="1-添加Hadoop系统用户组和用户"><a href="#1-添加Hadoop系统用户组和用户" class="headerlink" title="1. 添加Hadoop系统用户组和用户"></a>1. 添加Hadoop系统用户组和用户</h3><ul><li><p>使用以下命令在终端中执行先来创建一个用户组：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo addgroup hadoop</span><br></pre></td></tr></table></figure></li><li><p>使用以下命令来添加用户</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo adduser --ingroup hadoop hadoop</span><br></pre></td></tr></table></figure></li></ul><a id="more"></a><h3 id="2-配置SSH"><a href="#2-配置SSH" class="headerlink" title="2. 配置SSH"></a>2. 配置SSH</h3><ul><li><p>首先需要切换到hadoop用户，输入以下命令</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">su hadoop</span><br></pre></td></tr></table></figure></li><li><p>创建一个新的秘钥</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -P <span class="string">""</span></span><br></pre></td></tr></table></figure></li><li><p>使用此秘钥启用SSH访问本地计算机</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure></li><li><p>也可以采用如下语句</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id hadoop@localhost</span><br></pre></td></tr></table></figure></li><li><p>测试是否配置正确</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh localhost</span><br></pre></td></tr></table></figure></li><li><p>若能正确连接localhost则说明SSH配置正确</p></li><li><p>若看到如下错误响应，可能SSH在此系统不可用，可以purge掉openssh-server之后重新进行安装</p></li></ul><h3 id="3-安装、配置Java"><a href="#3-安装、配置Java" class="headerlink" title="3. 安装、配置Java"></a>3. 安装、配置Java</h3><ul><li><p>在浏览器中打开网址： <a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a></p></li><li><p>下载最新的稳定的jdk(Java SE Developmet Kit)</p></li><li><p>将下载的文件解压到目录<code>/opt/java/jdk</code>，并改名为<code>jdk1.8</code>（我下载的是1.8版本的JDK）</p></li><li><p>修改<code>/etc/bash.bashrc</code>文件，在最后加上如下内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/java/jdk/jdk1.8</span><br><span class="line"><span class="built_in">export</span> CLASSPATH=<span class="variable">$&#123;JAVA_HOME&#125;</span>/lib</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$&#123;JAVA_HOME&#125;</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure></li><li><p>在终端中输入命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure></li><li><p>若输出如下内容，则说明安装、配置正确</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java version <span class="string">"1.8.0_65"</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_65-b17)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.65-b01, mixed mode)</span><br></pre></td></tr></table></figure></li></ul><h3 id="4-下载Hadoop"><a href="#4-下载Hadoop" class="headerlink" title="4. 下载Hadoop"></a>4. 下载Hadoop</h3><ul><li>在浏览器中打开网址：  <a href="http://hadoop.apache.org/releases.html" target="_blank" rel="noopener">http://hadoop.apache.org/releases.html</a></li><li>下载新版本的二进制包，下载完成后解压到目录<code>/usr/local</code>，并改名为<code>hadoop</code></li><li>更改文件权限，使hadoop用户能够拥有该文件夹的权限<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span></span><br><span class="line">sudo chown -R hadoop:hadoop hadoop</span><br></pre></td></tr></table></figure></li></ul><h3 id="5-配置Hadoop"><a href="#5-配置Hadoop" class="headerlink" title="5. 配置Hadoop"></a>5. 配置Hadoop</h3><ul><li><p>修改<code>/etc/bash.bashrc</code>文件，在最后加上如下内容</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Set HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="comment">#Set JAVA_HOME</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.8.0_60</span><br><span class="line"><span class="comment"># Add bin/ directory of Hadoop to PATH</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin</span><br></pre></td></tr></table></figure></li><li><p>在文件<code>/usr/local/hadoop/etc/hadoop/hadoop-env.sh</code>中加入JAVA_HOME的完整路径，如下所示</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/java/jdk/jdk1.8</span><br></pre></td></tr></table></figure></li><li><p>在<code>/usr/local/hadoop/etc/hadoop/core-site.xml</code>文件中还有两个参数需要设置：</p><ol><li>‘hadoop.tmp.dir’-用于制定目录让Hadoop来存储其数据文件</li><li>‘fs.default.name’-指定默认的文件系统<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/app/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>A base for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.default.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:54310<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>The name of the default file system.  A URI whose</span><br><span class="line">  scheme and authority determine the FileSystem implementation.  The</span><br><span class="line">  uri's scheme determines the config property (fs.SCHEME.impl) naming</span><br><span class="line">the FileSystem implementation class.  The uri's authority is used to</span><br><span class="line">determine the host, port, etc. for a filesystem.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ol></li><li><p>创建目录，如上面配置core-site.xml中使用的目录：<code>/app/hadoop/tmp</code>，并授予权限</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /app/hadoop/tmp</span><br><span class="line">sudo chown -R hadoop:hadoop /app/hadoop/tmp</span><br><span class="line">sudo chmod 750 /app/hadoop/tmp</span><br></pre></td></tr></table></figure></li><li><p>配置文件<code>/usr/local/hadoop/etc/hadoop/mapred-site.xml</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /usr/<span class="built_in">local</span>/hadoop/etc/hadoop/mapred-site.xml.template /usr/<span class="built_in">local</span>/hadoop/etc/hadoop/mapred-site.xml</span><br></pre></td></tr></table></figure></li><li><p>在mapred-site.xml文件中添加以下内容</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.job.tracker<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost:54311<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>The host and port that the MapReduce job tracker runs</span><br><span class="line">  at.  If "local", then jobs are run in-process as a single map</span><br><span class="line">  and reduce task.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>配置<code>/usr/local/hadoop/etc/hadoop/hdfs-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Default block replication.</span><br><span class="line">  The actual number of replications can be specified when the file is created.</span><br><span class="line">  The default is used if replication is not specified in create time.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/hdfs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="6-使用Hadoop"><a href="#6-使用Hadoop" class="headerlink" title="6. 使用Hadoop"></a>6. 使用Hadoop</h3><ul><li><p>在第一次使用Hadoop之前，需要先格式化HDFS，使用如下命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/hadoop/bin/hadoop namenode -format</span><br></pre></td></tr></table></figure></li><li><p>可能会遇到创建文件夹权限问题，可以自行使用sudo进行文件夹的创建，或使用sudo来执行上面的命令</p></li><li><p>使用以下命令启动Hadoop的单节点集群（使用hadoop用户来启动）</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/hadoop/sbin/start-dfs.sh</span><br><span class="line">/usr/<span class="built_in">local</span>/hadoop/sbin/start-yarn.sh</span><br></pre></td></tr></table></figure></li><li><p>也可以使用<code>/usr/local/hadoop/sbin/start-all.sh</code>来启动所有功能</p></li><li><p>使用jps验证是否所有Hadoop相关的Java进程正在运行<code>/opt/java/jdk/jdk1.8/bin/jps</code></p></li><li><p>关闭Hadoop相关功能使用<code>stop-*.sh</code>，具体可以参照<code>/usr/local/hadoop/sbin</code>中的文件内容</p></li><li><p>测试</p><ul><li>ALL Application: <a href="http://localhost:8088/" target="_blank" rel="noopener">http://localhost:8088/</a></li><li>DataNode: <a href="http://localhost:50070/" target="_blank" rel="noopener">http://localhost:50070/</a></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Hexo与Github搭建个人博客</title>
      <link href="/2015/12/09/hexo/%E4%BD%BF%E7%94%A8Hexo%E4%B8%8EGithub%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
      <url>/2015/12/09/hexo/%E4%BD%BF%E7%94%A8Hexo%E4%B8%8EGithub%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<h4 id="1-安装Hexo"><a href="#1-安装Hexo" class="headerlink" title="1. 安装Hexo"></a>1. 安装Hexo</h4><ul><li><p>安装git直接使用指令：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install git</span><br></pre></td></tr></table></figure></li><li><p>安装Node.js直接使用如下指令：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install -y python-software-properties software-properties-common</span><br><span class="line">sudo add-apt-repository ppa:chris-lea/node.js</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install nodejs</span><br></pre></td></tr></table></figure></li><li><p>安装好Git和Node.js之后，使用如下指令安装Hexo：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo npm install -g hexo-cli</span><br></pre></td></tr></table></figure></li></ul><a id="more"></a><h4 id="2-创建存放博文的文件夹"><a href="#2-创建存放博文的文件夹" class="headerlink" title="2. 创建存放博文的文件夹"></a>2. 创建存放博文的文件夹</h4><ul><li><p>在任意位置创建文件夹，例如在”~/文档/“目录下创建文件夹hexo：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir ~/文档/hexo</span><br></pre></td></tr></table></figure></li><li><p>执行下列命令，Hexo会在指定文件夹中新建所需要的文件：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo hexo init &lt;folder&gt;</span><br><span class="line">cd &lt;folder&gt;</span><br><span class="line">sudo npm install</span><br></pre></td></tr></table></figure></li><li><p>新建完成后，制定文件夹的目录如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── _config.yml</span><br><span class="line">├── package.json</span><br><span class="line">├── scaffolds</span><br><span class="line">├── source</span><br><span class="line">|   ├── _drafts</span><br><span class="line">|   └── _posts</span><br><span class="line">└── themes</span><br></pre></td></tr></table></figure></li><li><p>_config.yml存放配置信息</p></li><li><p>source/_posts/目录下存放博文markdown文件</p></li><li><p>theme/目录用于存放主题文件夹</p></li></ul><h4 id="3-配置"><a href="#3-配置" class="headerlink" title="3. 配置"></a>3. 配置</h4><ul><li>在_config.yml中修改大部分配置</li><li>title 网站标题</li><li>subtitle 网站副标题</li><li>author 你的名字</li><li>language 语言(默认为英文，简体中文为zh-CN，繁体中文为zh-TW)</li><li>具体参照 <a href="https://hexo.io/zh-cn/docs/configuration.html" target="_blank" rel="noopener">https://hexo.io/zh-cn/docs/configuration.html</a></li></ul><h4 id="4-主题使用"><a href="#4-主题使用" class="headerlink" title="4. 主题使用"></a>4. 主题使用</h4><ul><li>在 <a href="https://hexo.io/themes/" target="_blank" rel="noopener">https://hexo.io/themes/</a> 中找到想要使用的主题，进入其github主页，里面有主题的具体安装方法，一般是git到目录下的theme文件夹当中去，然后在配置文件中修改主题名称</li></ul><h4 id="5-部署到github"><a href="#5-部署到github" class="headerlink" title="5. 部署到github"></a>5. 部署到github</h4><ul><li><p>在github上new repository，名称为:[github用户名].github.io</p></li><li><p>在_config.yml添加如下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: https:<span class="comment">//github.com/liujiayi771/liujiayi771.github.io.git</span></span><br></pre></td></tr></table></figure></li><li><p>repo后为仓库的https地址</p></li><li><p>使用命令创建名称为title的博文markdown文件：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo hexo <span class="keyword">new</span> &lt;title&gt;</span><br></pre></td></tr></table></figure></li><li><p>在markdown文件中写好内容后，使用如下命令生成html文件：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo hexo g</span><br></pre></td></tr></table></figure></li><li><p>使用如下命令将生成的静态网页内容上传到github上去：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo hexo d</span><br></pre></td></tr></table></figure></li><li><p>可通过访问[github用户名].github.io来访问博客主页</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
